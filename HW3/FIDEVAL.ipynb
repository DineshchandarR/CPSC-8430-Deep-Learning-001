{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import inception_v3\n",
    "import cv2\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = 'cuda'\n",
    "# else:\n",
    "#     device = 'cpu'\n",
    "    \n",
    "# print(device)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, transform_input=True):\n",
    "        super().__init__()\n",
    "        self.InceptionNet = inception_v3(pretrained=True)\n",
    "        self.InceptionNet.Mixed_7c.register_forward_hook(self.output_hook)\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "    def output_hook(self, module, input, output):\n",
    "        # N x 2048 x 8 x 8\n",
    "        self.mixed_7c_output = output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: shape (N, 3, 299, 299) dtype: torch.float32 in range 0-1\n",
    "        Returns:\n",
    "            inception activations: torch.tensor, shape: (N, 2048), dtype: torch.float32\n",
    "        \"\"\"\n",
    "        assert x.shape[1:] == (3, 299, 299), \"Expected input shape to be: (N,3,299,299)\" +                                             \", but got {}\".format(x.shape)\n",
    "        x = x * 2 -1 # Normalize to [-1, 1]\n",
    "\n",
    "        # Trigger output hook\n",
    "        self.InceptionNet(x)\n",
    "\n",
    "        # Output: N x 2048 x 1 x 1 \n",
    "        activations = self.mixed_7c_output\n",
    "        activations = torch.nn.functional.adaptive_avg_pool2d(activations, (1,1))\n",
    "        activations = activations.view(x.shape[0], 2048)\n",
    "        return activations\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def getActivations(images, batchSize):\n",
    "    \n",
    "    assert images.shape[1:] == (3, 299, 299), \"Expected input shape to be: (N,3,299,299)\" +                                              \", but got {}\".format(images.shape)\n",
    "\n",
    "    noofImg = images.shape[0]\n",
    "    inceptionNet = InceptionNetwork()\n",
    "    inceptionNet = inceptionNet.to(device)\n",
    "    inceptionNet.eval()\n",
    "    n_batches = int(np.ceil(noofImg  / batchSize))\n",
    "    inceptionAct = np.zeros((noofImg, 2048), dtype=np.float32)\n",
    "    for batch_idx in range(batchSize):\n",
    "        start_idx = batchSize * batch_idx\n",
    "        end_idx = batchSize * (batch_idx + 1)\n",
    "\n",
    "        ims = images[start_idx:end_idx]\n",
    "        ims = ims.to(device)\n",
    "        activations = inceptionNet(ims)\n",
    "        activations = activations.detach().cpu().numpy()\n",
    "        assert activations.shape == (ims.shape[0], 2048), \"Expexted output shape to be: {}, but was: {}\".format((ims.shape[0], 2048), activations.shape)\n",
    "        inceptionAct[start_idx:end_idx, :] = activations\n",
    "    return inceptionAct\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def activationStatistics(images, batchSize):\n",
    "    \n",
    "    act = getActivations(images, batchSize)\n",
    "    mean = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mean, sigma\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def calFrechetDist(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n",
    "    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "    # product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n",
    "        warnings.warn(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "#             raise ValueError(\"Imaginary component {}\".format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def ImgPreprocessing(img):\n",
    "    \n",
    "    assert img.shape[2] == 3\n",
    "    assert len(img.shape) == 3\n",
    "    if img.dtype == np.uint8:\n",
    "        img = img.astype(np.float32) / 255\n",
    "    img = cv2.resize(img, (299, 299))\n",
    "    img = np.rollaxis(img, axis=2)\n",
    "    img = torch.from_numpy(img)\n",
    "    assert img.max() <= 1.0\n",
    "    assert img.min() >= 0.0\n",
    "    assert img.dtype == torch.float32\n",
    "    assert img.shape == (3, 299, 299)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def multiImgPreprocess(images, use_multiprocessing):\n",
    "    \n",
    "    if use_multiprocessing:\n",
    "        with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "            jobs = []\n",
    "            for img in images:\n",
    "                job = pool.apply_async(ImgPreprocessing, (img,))\n",
    "                jobs.append(job)\n",
    "            final_images = torch.zeros(images.shape[0], 3, 299, 299)\n",
    "            for idx, job in enumerate(jobs):\n",
    "                img = job.get()\n",
    "                final_images[idx] = img#job.get()\n",
    "    else:\n",
    "        final_images = torch.stack([ImgPreprocessing(img) for img in images], dim=0)\n",
    "    assert final_images.shape == (images.shape[0], 3, 299, 299)\n",
    "    assert final_images.max() <= 1.0\n",
    "    assert final_images.min() >= 0.0\n",
    "    assert final_images.dtype == torch.float32\n",
    "    return final_images\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def calFid(images1, images2, use_multiprocessing, batchSize):\n",
    "    \n",
    "    images1 = multiImgPreprocess(images1, use_multiprocessing)\n",
    "    images2 = multiImgPreprocess(images2, use_multiprocessing)\n",
    "    mean1, sigma1 = activationStatistics(images1, batchSize)\n",
    "    mean2, sigma2 = activationStatistics(images2, batchSize)\n",
    "    fid = calFrechetDist(mean1, sigma1,mean2, sigma2)\n",
    "    return fid\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def loadImages(path, iteration):\n",
    "    \n",
    "    image_paths = []\n",
    "    image_extensions = [\"png\"]\n",
    "    for ext in image_extensions:\n",
    "        #print(\"Looking for images in\", os.path.join(path, \"*.{}\".format(ext)))\n",
    "        for impath in glob.glob(os.path.join(path, \"*.{}\".format(ext))):\n",
    "            image_paths.append(impath)\n",
    "    #sort the images by name\n",
    "    image_paths = sorted(image_paths)\n",
    "    image_paths.sort(key = len)\n",
    "    #compare only the most recently generated fake and real image\n",
    "    image_paths = image_paths[0:iteration]\n",
    "    first_image = cv2.imread(image_paths[0])\n",
    "\n",
    "    H, W = first_image.shape[:2]\n",
    "    image_paths.sort()\n",
    "    image_paths = image_paths\n",
    "    final_images = np.zeros((len(image_paths), H, W, 3), dtype=first_image.dtype)\n",
    "    for idx, impath in enumerate(image_paths):\n",
    "        img = cv2.imread(impath)\n",
    "        img = img[:, :, ::-1] # Convert from BGR to RGB\n",
    "        assert img.dtype == final_images.dtype\n",
    "        final_images[idx] = img\n",
    "    return final_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidScore(path1,path2, iteration, batchSize=16): #, acgan=False):\n",
    "    \n",
    "    images1 = loadImages(path1, iteration) #, acgan)\n",
    "    images2 = loadImages(path2, iteration) #, acgan)\n",
    "    FID = calFid(images1, images2, False, batchSize)\n",
    "#     print('FID VALUE:',FID)\n",
    "    return FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40 and FID Score: 223.23960872214292\r"
     ]
    }
   ],
   "source": [
    "#FID SCORE FOR DC GAN\n",
    "DC_FIDScore = []\n",
    "for i in range(0,50):\n",
    "    i = i+1\n",
    "    DCFID = fidScore('Results/DCGAN_REAL','Results/DCGAN_FAKE',i,128)\n",
    "    print(f'Epoch:{i} and FID Score: {DCFID}', end = '\\r', flush=True)\n",
    "    DC_FIDScore.append(DCFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FID SCORE FOR WGAN\n",
    "W_FIDScore = []\n",
    "for i in range(0,50):\n",
    "    i = i+1\n",
    "    WFID = fidScore('Results/WGAN_REAL','Results/WGAN_FAKE',i,32)\n",
    "    print(f'Epoch:{i} and FID Score: {WFID}', end = '\\r', flush=True)\n",
    "    W_FIDScore.append(WFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_FIDScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"FID Scores for DCGAN and WGAN\")\n",
    "plt.plot(DC_FIDScore,label=\"DCGAN\")\n",
    "plt.plot(W_FIDScore,label=\"WGAN\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"FID\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FID SCORE FOR WGAN_GP\n",
    "W_FIDScore = []\n",
    "for i in range(0,50):\n",
    "    i = i+1\n",
    "    WFID = fidScore('Results/DCGAN_REAL','Results/DCGAN_FAKE',i,32)\n",
    "    W_FIDScore.append(WFID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DBT_pytorch)",
   "language": "python",
   "name": "dbt_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
