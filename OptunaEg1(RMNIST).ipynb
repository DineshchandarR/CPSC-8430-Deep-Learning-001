{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "   DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Randomizer\n",
    "\n",
    "randomLabel = torch.tensor(np.random.randint(0, 10, (len(train_dataset)),))\n",
    "train_dataset.targets = randomLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader func\n",
    "def train_loader(BATCHSIZE):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size = BATCHSIZE, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def test_loader(BATCHSIZE):\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=BATCHSIZE, \n",
    "                                          shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_load = train_loader(BATCHSIZE)\n",
    "    test_load = test_loader(BATCHSIZE)\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_load):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_load):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(test_load.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-11 10:39:18,819]\u001b[0m A new study created in memory with name: no-name-f1df3058-6934-4f05-9e2c-05107ea52f8e\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:23,920]\u001b[0m Trial 0 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.438361804231545, 'optimizer': 'SGD', 'lr': 3.903638349992392e-05}. Best is trial 0 with value: 0.05.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:30,374]\u001b[0m Trial 1 finished with value: 0.15859375 and parameters: {'n_layers': 2, 'n_units_l0': 92, 'dropout_l0': 0.2787431024701959, 'n_units_l1': 11, 'dropout_l1': 0.2569989755972666, 'optimizer': 'Adam', 'lr': 0.0002618605864525328}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:35,790]\u001b[0m Trial 2 finished with value: 0.06953125 and parameters: {'n_layers': 2, 'n_units_l0': 64, 'dropout_l0': 0.21604853955911038, 'n_units_l1': 49, 'dropout_l1': 0.2225280725994449, 'optimizer': 'Adam', 'lr': 0.00036061293401595205}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:41,107]\u001b[0m Trial 3 finished with value: 0.11953125 and parameters: {'n_layers': 1, 'n_units_l0': 59, 'dropout_l0': 0.44182363886115583, 'optimizer': 'SGD', 'lr': 0.058359310039261286}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:46,890]\u001b[0m Trial 4 finished with value: 0.07578125 and parameters: {'n_layers': 2, 'n_units_l0': 79, 'dropout_l0': 0.21193008111606373, 'n_units_l1': 71, 'dropout_l1': 0.3277615024938356, 'optimizer': 'SGD', 'lr': 0.0030819240204075834}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:47,416]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:52,029]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:52,657]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:39:56,681]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:01,590]\u001b[0m Trial 9 finished with value: 0.14609375 and parameters: {'n_layers': 1, 'n_units_l0': 22, 'dropout_l0': 0.49431217320877696, 'optimizer': 'Adam', 'lr': 0.00041480337155298076}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:05,508]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:06,019]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:06,563]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:11,822]\u001b[0m Trial 13 finished with value: 0.12421875 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.3292044436171134, 'optimizer': 'Adam', 'lr': 6.902180342061838e-05}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:12,349]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:12,873]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:16,054]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:16,576]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:17,135]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:17,652]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:18,245]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:18,789]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:23,105]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:23,634]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:24,167]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:29,331]\u001b[0m Trial 25 finished with value: 0.08828125 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'dropout_l0': 0.35907336447456883, 'optimizer': 'Adam', 'lr': 8.856805640978618e-05}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:34,961]\u001b[0m Trial 26 finished with value: 0.0265625 and parameters: {'n_layers': 2, 'n_units_l0': 115, 'dropout_l0': 0.27807644808134746, 'n_units_l1': 115, 'dropout_l1': 0.47850434510701545, 'optimizer': 'Adam', 'lr': 0.0015634502432546084}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:35,546]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:40,852]\u001b[0m Trial 28 finished with value: 0.15859375 and parameters: {'n_layers': 1, 'n_units_l0': 90, 'dropout_l0': 0.4136864801461404, 'optimizer': 'Adam', 'lr': 3.701639371961739e-05}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:41,402]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:41,921]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:47,291]\u001b[0m Trial 31 finished with value: 0.1109375 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.49772628619604575, 'optimizer': 'Adam', 'lr': 5.1952869535935185e-05}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:47,845]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:48,390]\u001b[0m Trial 33 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:53,783]\u001b[0m Trial 34 finished with value: 0.13671875 and parameters: {'n_layers': 1, 'n_units_l0': 110, 'dropout_l0': 0.34214219879990276, 'optimizer': 'Adam', 'lr': 5.95212340457814e-05}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:58,117]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:58,668]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:59,237]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:40:59,794]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:00,320]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:05,789]\u001b[0m Trial 40 finished with value: 0.11171875 and parameters: {'n_layers': 1, 'n_units_l0': 126, 'dropout_l0': 0.2033146886010632, 'optimizer': 'RMSprop', 'lr': 3.612272111457663e-05}. Best is trial 1 with value: 0.15859375.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:11,192]\u001b[0m Trial 41 finished with value: 0.1640625 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.3195759100801704, 'optimizer': 'Adam', 'lr': 6.729740042035753e-05}. Best is trial 41 with value: 0.1640625.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:11,749]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:12,304]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:12,883]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:13,536]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:14,104]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:19,465]\u001b[0m Trial 47 finished with value: 0.07109375 and parameters: {'n_layers': 1, 'n_units_l0': 64, 'dropout_l0': 0.47172587625275375, 'optimizer': 'Adam', 'lr': 0.0014190390293276748}. Best is trial 41 with value: 0.1640625.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:20,013]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:20,594]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:21,182]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:21,749]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:22,316]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:22,871]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:23,448]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:24,004]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:24,579]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:25,142]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:25,725]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:31,262]\u001b[0m Trial 59 finished with value: 0.1453125 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.31436203559717596, 'optimizer': 'Adam', 'lr': 0.00022779609116120779}. Best is trial 41 with value: 0.1640625.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:31,826]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:32,388]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:32,967]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:33,547]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:34,118]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:34,704]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:35,238]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:35,805]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:36,367]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:37,010]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:37,588]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:38,117]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:38,702]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:44,017]\u001b[0m Trial 73 finished with value: 0.1296875 and parameters: {'n_layers': 1, 'n_units_l0': 53, 'dropout_l0': 0.40902425893515776, 'optimizer': 'SGD', 'lr': 0.009370600600325294}. Best is trial 41 with value: 0.1640625.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:49,329]\u001b[0m Trial 74 finished with value: 0.1265625 and parameters: {'n_layers': 1, 'n_units_l0': 46, 'dropout_l0': 0.40418959371825813, 'optimizer': 'SGD', 'lr': 0.008563010821314903}. Best is trial 41 with value: 0.1640625.\u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:49,876]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:50,418]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:50,978]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:51,545]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:52,103]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:52,646]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:53,188]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:53,739]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:54,310]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:54,918]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:55,481]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:57,721]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:58,256]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:58,821]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:41:59,416]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:00,068]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:00,630]\u001b[0m Trial 91 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:01,211]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:01,754]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:02,292]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:02,851]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:03,444]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:04,036]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:04,636]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-11 10:42:05,213]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  82\n",
      "  Number of complete trials:  18\n",
      "Best trial:\n",
      "  Value:  0.1640625\n",
      "  Params: \n",
      "n_layers: 1\n",
      "n_units_l0: 96\n",
      "dropout_l0: 0.3195759100801704\n",
      "optimizer: Adam\n",
      "lr: 6.729740042035753e-05\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
