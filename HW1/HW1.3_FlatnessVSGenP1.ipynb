{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1eaeec8a870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader func\n",
    "def train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def test_loader(batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M1(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs,train_batch_size):\n",
    "    model.train()\n",
    "    print('strated')\n",
    "    train_load = train_loader(train_batch_size)\n",
    "    n_total_steps = len(train_load)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    not_converged =True\n",
    "    epoch = 0\n",
    "    while not_converged:\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_load):  \n",
    "            \n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            train_epoch.append(epoch)\n",
    "\n",
    "            if (i+1) % 60 == 0:\n",
    "                print (f'Train O/P: Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "   \n",
    "                if epoch == num_epochs:\n",
    "                        print(\"Max Epoch Reached\")\n",
    "                        not_converged = False\n",
    "                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n",
    "                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n",
    "                        print(\"Convergeance reached for loss:\",train_losses[-1])\n",
    "                        not_converged = False\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model with batch_size=64 is:44426\n"
     ]
    }
   ],
   "source": [
    "# Training Model with batch size=64\n",
    "torch.manual_seed(1)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "mBatch1 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mBatch1.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in mBatch1.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print(f'Total no of parameters in Model with batch_size={64} is:{np.sum(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/15], Step [60/938], Loss: 0.7895\n",
      "120\n",
      "Train O/P: Epoch [1/15], Step [120/938], Loss: 0.4790\n",
      "180\n",
      "Train O/P: Epoch [1/15], Step [180/938], Loss: 0.3199\n",
      "240\n",
      "Train O/P: Epoch [1/15], Step [240/938], Loss: 0.3646\n",
      "300\n",
      "Train O/P: Epoch [1/15], Step [300/938], Loss: 0.2332\n",
      "360\n",
      "Train O/P: Epoch [1/15], Step [360/938], Loss: 0.1718\n",
      "420\n",
      "Train O/P: Epoch [1/15], Step [420/938], Loss: 0.2433\n",
      "480\n",
      "Train O/P: Epoch [1/15], Step [480/938], Loss: 0.1388\n",
      "540\n",
      "Train O/P: Epoch [1/15], Step [540/938], Loss: 0.0672\n",
      "600\n",
      "Train O/P: Epoch [1/15], Step [600/938], Loss: 0.0961\n",
      "660\n",
      "Train O/P: Epoch [1/15], Step [660/938], Loss: 0.2539\n",
      "720\n",
      "Train O/P: Epoch [1/15], Step [720/938], Loss: 0.0967\n",
      "780\n",
      "Train O/P: Epoch [1/15], Step [780/938], Loss: 0.0556\n",
      "840\n",
      "Train O/P: Epoch [1/15], Step [840/938], Loss: 0.1883\n",
      "900\n",
      "Train O/P: Epoch [1/15], Step [900/938], Loss: 0.0545\n",
      "60\n",
      "Train O/P: Epoch [2/15], Step [60/938], Loss: 0.2019\n",
      "120\n",
      "Train O/P: Epoch [2/15], Step [120/938], Loss: 0.2731\n",
      "180\n",
      "Train O/P: Epoch [2/15], Step [180/938], Loss: 0.0402\n",
      "240\n",
      "Train O/P: Epoch [2/15], Step [240/938], Loss: 0.0880\n",
      "300\n",
      "Train O/P: Epoch [2/15], Step [300/938], Loss: 0.0390\n",
      "360\n",
      "Train O/P: Epoch [2/15], Step [360/938], Loss: 0.0371\n",
      "420\n",
      "Train O/P: Epoch [2/15], Step [420/938], Loss: 0.0478\n",
      "480\n",
      "Train O/P: Epoch [2/15], Step [480/938], Loss: 0.1654\n",
      "540\n",
      "Train O/P: Epoch [2/15], Step [540/938], Loss: 0.0444\n",
      "600\n",
      "Train O/P: Epoch [2/15], Step [600/938], Loss: 0.0416\n",
      "660\n",
      "Train O/P: Epoch [2/15], Step [660/938], Loss: 0.0287\n",
      "720\n",
      "Train O/P: Epoch [2/15], Step [720/938], Loss: 0.0393\n",
      "780\n",
      "Train O/P: Epoch [2/15], Step [780/938], Loss: 0.1042\n",
      "840\n",
      "Train O/P: Epoch [2/15], Step [840/938], Loss: 0.2215\n",
      "900\n",
      "Train O/P: Epoch [2/15], Step [900/938], Loss: 0.3220\n",
      "60\n",
      "Train O/P: Epoch [3/15], Step [60/938], Loss: 0.0310\n",
      "120\n",
      "Train O/P: Epoch [3/15], Step [120/938], Loss: 0.0112\n",
      "180\n",
      "Train O/P: Epoch [3/15], Step [180/938], Loss: 0.1115\n",
      "240\n",
      "Train O/P: Epoch [3/15], Step [240/938], Loss: 0.0412\n",
      "300\n",
      "Train O/P: Epoch [3/15], Step [300/938], Loss: 0.0798\n",
      "360\n",
      "Train O/P: Epoch [3/15], Step [360/938], Loss: 0.0411\n",
      "420\n",
      "Train O/P: Epoch [3/15], Step [420/938], Loss: 0.0734\n",
      "480\n",
      "Train O/P: Epoch [3/15], Step [480/938], Loss: 0.1395\n",
      "540\n",
      "Train O/P: Epoch [3/15], Step [540/938], Loss: 0.0237\n",
      "600\n",
      "Train O/P: Epoch [3/15], Step [600/938], Loss: 0.1174\n",
      "660\n",
      "Train O/P: Epoch [3/15], Step [660/938], Loss: 0.0340\n",
      "720\n",
      "Train O/P: Epoch [3/15], Step [720/938], Loss: 0.0346\n",
      "780\n",
      "Train O/P: Epoch [3/15], Step [780/938], Loss: 0.0826\n",
      "840\n",
      "Train O/P: Epoch [3/15], Step [840/938], Loss: 0.0064\n",
      "900\n",
      "Train O/P: Epoch [3/15], Step [900/938], Loss: 0.0055\n",
      "60\n",
      "Train O/P: Epoch [4/15], Step [60/938], Loss: 0.0103\n",
      "120\n",
      "Train O/P: Epoch [4/15], Step [120/938], Loss: 0.0210\n",
      "180\n",
      "Train O/P: Epoch [4/15], Step [180/938], Loss: 0.0871\n",
      "240\n",
      "Train O/P: Epoch [4/15], Step [240/938], Loss: 0.0137\n",
      "300\n",
      "Train O/P: Epoch [4/15], Step [300/938], Loss: 0.0063\n",
      "360\n",
      "Train O/P: Epoch [4/15], Step [360/938], Loss: 0.0018\n",
      "420\n",
      "Train O/P: Epoch [4/15], Step [420/938], Loss: 0.0147\n",
      "480\n",
      "Train O/P: Epoch [4/15], Step [480/938], Loss: 0.0722\n",
      "540\n",
      "Train O/P: Epoch [4/15], Step [540/938], Loss: 0.0084\n",
      "600\n",
      "Train O/P: Epoch [4/15], Step [600/938], Loss: 0.0814\n",
      "660\n",
      "Train O/P: Epoch [4/15], Step [660/938], Loss: 0.0112\n",
      "720\n",
      "Train O/P: Epoch [4/15], Step [720/938], Loss: 0.0178\n",
      "780\n",
      "Train O/P: Epoch [4/15], Step [780/938], Loss: 0.0131\n",
      "840\n",
      "Train O/P: Epoch [4/15], Step [840/938], Loss: 0.0522\n",
      "900\n",
      "Train O/P: Epoch [4/15], Step [900/938], Loss: 0.0448\n",
      "60\n",
      "Train O/P: Epoch [5/15], Step [60/938], Loss: 0.1037\n",
      "120\n",
      "Train O/P: Epoch [5/15], Step [120/938], Loss: 0.0624\n",
      "180\n",
      "Train O/P: Epoch [5/15], Step [180/938], Loss: 0.0563\n",
      "240\n",
      "Train O/P: Epoch [5/15], Step [240/938], Loss: 0.0709\n",
      "300\n",
      "Train O/P: Epoch [5/15], Step [300/938], Loss: 0.2606\n",
      "360\n",
      "Train O/P: Epoch [5/15], Step [360/938], Loss: 0.0096\n",
      "420\n",
      "Train O/P: Epoch [5/15], Step [420/938], Loss: 0.0738\n",
      "480\n",
      "Train O/P: Epoch [5/15], Step [480/938], Loss: 0.0078\n",
      "540\n",
      "Train O/P: Epoch [5/15], Step [540/938], Loss: 0.0900\n",
      "600\n",
      "Train O/P: Epoch [5/15], Step [600/938], Loss: 0.0163\n",
      "660\n",
      "Train O/P: Epoch [5/15], Step [660/938], Loss: 0.0182\n",
      "720\n",
      "Train O/P: Epoch [5/15], Step [720/938], Loss: 0.0536\n",
      "780\n",
      "Train O/P: Epoch [5/15], Step [780/938], Loss: 0.0298\n",
      "840\n",
      "Train O/P: Epoch [5/15], Step [840/938], Loss: 0.0934\n",
      "900\n",
      "Train O/P: Epoch [5/15], Step [900/938], Loss: 0.0037\n",
      "60\n",
      "Train O/P: Epoch [6/15], Step [60/938], Loss: 0.0432\n",
      "120\n",
      "Train O/P: Epoch [6/15], Step [120/938], Loss: 0.0493\n",
      "180\n",
      "Train O/P: Epoch [6/15], Step [180/938], Loss: 0.0052\n",
      "240\n",
      "Train O/P: Epoch [6/15], Step [240/938], Loss: 0.0074\n",
      "300\n",
      "Train O/P: Epoch [6/15], Step [300/938], Loss: 0.0137\n",
      "360\n",
      "Train O/P: Epoch [6/15], Step [360/938], Loss: 0.0034\n",
      "420\n",
      "Train O/P: Epoch [6/15], Step [420/938], Loss: 0.0209\n",
      "480\n",
      "Train O/P: Epoch [6/15], Step [480/938], Loss: 0.0236\n",
      "540\n",
      "Train O/P: Epoch [6/15], Step [540/938], Loss: 0.0338\n",
      "600\n",
      "Train O/P: Epoch [6/15], Step [600/938], Loss: 0.0317\n",
      "660\n",
      "Train O/P: Epoch [6/15], Step [660/938], Loss: 0.0477\n",
      "720\n",
      "Train O/P: Epoch [6/15], Step [720/938], Loss: 0.1277\n",
      "780\n",
      "Train O/P: Epoch [6/15], Step [780/938], Loss: 0.0993\n",
      "840\n",
      "Train O/P: Epoch [6/15], Step [840/938], Loss: 0.1365\n",
      "900\n",
      "Train O/P: Epoch [6/15], Step [900/938], Loss: 0.0386\n",
      "60\n",
      "Train O/P: Epoch [7/15], Step [60/938], Loss: 0.0573\n",
      "120\n",
      "Train O/P: Epoch [7/15], Step [120/938], Loss: 0.0024\n",
      "180\n",
      "Train O/P: Epoch [7/15], Step [180/938], Loss: 0.0518\n",
      "240\n",
      "Train O/P: Epoch [7/15], Step [240/938], Loss: 0.0020\n",
      "300\n",
      "Train O/P: Epoch [7/15], Step [300/938], Loss: 0.0907\n",
      "360\n",
      "Train O/P: Epoch [7/15], Step [360/938], Loss: 0.0133\n",
      "420\n",
      "Train O/P: Epoch [7/15], Step [420/938], Loss: 0.0109\n",
      "480\n",
      "Train O/P: Epoch [7/15], Step [480/938], Loss: 0.0054\n",
      "540\n",
      "Train O/P: Epoch [7/15], Step [540/938], Loss: 0.0092\n",
      "600\n",
      "Train O/P: Epoch [7/15], Step [600/938], Loss: 0.0023\n",
      "660\n",
      "Train O/P: Epoch [7/15], Step [660/938], Loss: 0.0027\n",
      "720\n",
      "Train O/P: Epoch [7/15], Step [720/938], Loss: 0.0506\n",
      "780\n",
      "Train O/P: Epoch [7/15], Step [780/938], Loss: 0.0377\n",
      "840\n",
      "Train O/P: Epoch [7/15], Step [840/938], Loss: 0.0048\n",
      "900\n",
      "Train O/P: Epoch [7/15], Step [900/938], Loss: 0.0014\n",
      "60\n",
      "Train O/P: Epoch [8/15], Step [60/938], Loss: 0.0728\n",
      "120\n",
      "Train O/P: Epoch [8/15], Step [120/938], Loss: 0.0363\n",
      "180\n",
      "Train O/P: Epoch [8/15], Step [180/938], Loss: 0.0306\n",
      "240\n",
      "Train O/P: Epoch [8/15], Step [240/938], Loss: 0.0107\n",
      "300\n",
      "Train O/P: Epoch [8/15], Step [300/938], Loss: 0.0790\n",
      "360\n",
      "Train O/P: Epoch [8/15], Step [360/938], Loss: 0.0506\n",
      "420\n",
      "Train O/P: Epoch [8/15], Step [420/938], Loss: 0.0345\n",
      "480\n",
      "Train O/P: Epoch [8/15], Step [480/938], Loss: 0.0007\n",
      "540\n",
      "Train O/P: Epoch [8/15], Step [540/938], Loss: 0.0232\n",
      "600\n",
      "Train O/P: Epoch [8/15], Step [600/938], Loss: 0.0303\n",
      "660\n",
      "Train O/P: Epoch [8/15], Step [660/938], Loss: 0.0060\n",
      "720\n",
      "Train O/P: Epoch [8/15], Step [720/938], Loss: 0.0716\n",
      "780\n",
      "Train O/P: Epoch [8/15], Step [780/938], Loss: 0.0049\n",
      "840\n",
      "Train O/P: Epoch [8/15], Step [840/938], Loss: 0.0158\n",
      "900\n",
      "Train O/P: Epoch [8/15], Step [900/938], Loss: 0.0619\n",
      "60\n",
      "Train O/P: Epoch [9/15], Step [60/938], Loss: 0.0004\n",
      "120\n",
      "Train O/P: Epoch [9/15], Step [120/938], Loss: 0.0013\n",
      "180\n",
      "Train O/P: Epoch [9/15], Step [180/938], Loss: 0.0127\n",
      "240\n",
      "Train O/P: Epoch [9/15], Step [240/938], Loss: 0.0329\n",
      "300\n",
      "Train O/P: Epoch [9/15], Step [300/938], Loss: 0.0043\n",
      "360\n",
      "Train O/P: Epoch [9/15], Step [360/938], Loss: 0.0121\n",
      "420\n",
      "Train O/P: Epoch [9/15], Step [420/938], Loss: 0.0174\n",
      "480\n",
      "Train O/P: Epoch [9/15], Step [480/938], Loss: 0.0005\n",
      "540\n",
      "Train O/P: Epoch [9/15], Step [540/938], Loss: 0.0017\n",
      "600\n",
      "Train O/P: Epoch [9/15], Step [600/938], Loss: 0.0042\n",
      "660\n",
      "Train O/P: Epoch [9/15], Step [660/938], Loss: 0.0019\n",
      "720\n",
      "Train O/P: Epoch [9/15], Step [720/938], Loss: 0.0050\n",
      "780\n",
      "Train O/P: Epoch [9/15], Step [780/938], Loss: 0.0399\n",
      "840\n",
      "Train O/P: Epoch [9/15], Step [840/938], Loss: 0.0376\n",
      "900\n",
      "Train O/P: Epoch [9/15], Step [900/938], Loss: 0.0166\n",
      "60\n",
      "Train O/P: Epoch [10/15], Step [60/938], Loss: 0.0658\n",
      "120\n",
      "Train O/P: Epoch [10/15], Step [120/938], Loss: 0.0320\n",
      "180\n",
      "Train O/P: Epoch [10/15], Step [180/938], Loss: 0.0034\n",
      "240\n",
      "Train O/P: Epoch [10/15], Step [240/938], Loss: 0.0002\n",
      "300\n",
      "Train O/P: Epoch [10/15], Step [300/938], Loss: 0.0061\n",
      "360\n",
      "Train O/P: Epoch [10/15], Step [360/938], Loss: 0.0012\n",
      "420\n",
      "Train O/P: Epoch [10/15], Step [420/938], Loss: 0.0007\n",
      "480\n",
      "Train O/P: Epoch [10/15], Step [480/938], Loss: 0.0424\n",
      "540\n",
      "Train O/P: Epoch [10/15], Step [540/938], Loss: 0.0529\n",
      "600\n",
      "Train O/P: Epoch [10/15], Step [600/938], Loss: 0.0030\n",
      "660\n",
      "Train O/P: Epoch [10/15], Step [660/938], Loss: 0.0010\n",
      "720\n",
      "Train O/P: Epoch [10/15], Step [720/938], Loss: 0.0089\n",
      "780\n",
      "Train O/P: Epoch [10/15], Step [780/938], Loss: 0.0221\n",
      "840\n",
      "Train O/P: Epoch [10/15], Step [840/938], Loss: 0.1321\n",
      "900\n",
      "Train O/P: Epoch [10/15], Step [900/938], Loss: 0.0032\n",
      "60\n",
      "Train O/P: Epoch [11/15], Step [60/938], Loss: 0.0026\n",
      "120\n",
      "Train O/P: Epoch [11/15], Step [120/938], Loss: 0.0091\n",
      "180\n",
      "Train O/P: Epoch [11/15], Step [180/938], Loss: 0.0262\n",
      "240\n",
      "Train O/P: Epoch [11/15], Step [240/938], Loss: 0.0005\n",
      "300\n",
      "Train O/P: Epoch [11/15], Step [300/938], Loss: 0.0051\n",
      "360\n",
      "Train O/P: Epoch [11/15], Step [360/938], Loss: 0.0091\n",
      "420\n",
      "Train O/P: Epoch [11/15], Step [420/938], Loss: 0.0023\n",
      "480\n",
      "Train O/P: Epoch [11/15], Step [480/938], Loss: 0.0012\n",
      "540\n",
      "Train O/P: Epoch [11/15], Step [540/938], Loss: 0.0009\n",
      "600\n",
      "Train O/P: Epoch [11/15], Step [600/938], Loss: 0.0213\n",
      "660\n",
      "Train O/P: Epoch [11/15], Step [660/938], Loss: 0.0012\n",
      "720\n",
      "Train O/P: Epoch [11/15], Step [720/938], Loss: 0.0554\n",
      "780\n",
      "Train O/P: Epoch [11/15], Step [780/938], Loss: 0.0324\n",
      "840\n",
      "Train O/P: Epoch [11/15], Step [840/938], Loss: 0.0560\n",
      "900\n",
      "Train O/P: Epoch [11/15], Step [900/938], Loss: 0.0158\n",
      "60\n",
      "Train O/P: Epoch [12/15], Step [60/938], Loss: 0.0004\n",
      "120\n",
      "Train O/P: Epoch [12/15], Step [120/938], Loss: 0.0015\n",
      "180\n",
      "Train O/P: Epoch [12/15], Step [180/938], Loss: 0.1148\n",
      "240\n",
      "Train O/P: Epoch [12/15], Step [240/938], Loss: 0.1218\n",
      "300\n",
      "Train O/P: Epoch [12/15], Step [300/938], Loss: 0.0573\n",
      "360\n",
      "Train O/P: Epoch [12/15], Step [360/938], Loss: 0.0045\n",
      "420\n",
      "Train O/P: Epoch [12/15], Step [420/938], Loss: 0.0117\n",
      "480\n",
      "Train O/P: Epoch [12/15], Step [480/938], Loss: 0.0060\n",
      "540\n",
      "Train O/P: Epoch [12/15], Step [540/938], Loss: 0.0512\n",
      "600\n",
      "Train O/P: Epoch [12/15], Step [600/938], Loss: 0.0175\n",
      "660\n",
      "Train O/P: Epoch [12/15], Step [660/938], Loss: 0.0106\n",
      "720\n",
      "Train O/P: Epoch [12/15], Step [720/938], Loss: 0.0046\n",
      "780\n",
      "Train O/P: Epoch [12/15], Step [780/938], Loss: 0.0047\n",
      "840\n",
      "Train O/P: Epoch [12/15], Step [840/938], Loss: 0.0267\n",
      "900\n",
      "Train O/P: Epoch [12/15], Step [900/938], Loss: 0.0241\n",
      "60\n",
      "Train O/P: Epoch [13/15], Step [60/938], Loss: 0.0018\n",
      "120\n",
      "Train O/P: Epoch [13/15], Step [120/938], Loss: 0.0073\n",
      "180\n",
      "Train O/P: Epoch [13/15], Step [180/938], Loss: 0.0012\n",
      "240\n",
      "Train O/P: Epoch [13/15], Step [240/938], Loss: 0.0020\n",
      "300\n",
      "Train O/P: Epoch [13/15], Step [300/938], Loss: 0.0036\n",
      "360\n",
      "Train O/P: Epoch [13/15], Step [360/938], Loss: 0.0512\n",
      "420\n",
      "Train O/P: Epoch [13/15], Step [420/938], Loss: 0.0522\n",
      "480\n",
      "Train O/P: Epoch [13/15], Step [480/938], Loss: 0.0003\n",
      "540\n",
      "Train O/P: Epoch [13/15], Step [540/938], Loss: 0.0413\n",
      "600\n",
      "Train O/P: Epoch [13/15], Step [600/938], Loss: 0.0108\n",
      "660\n",
      "Train O/P: Epoch [13/15], Step [660/938], Loss: 0.0273\n",
      "720\n",
      "Train O/P: Epoch [13/15], Step [720/938], Loss: 0.0029\n",
      "780\n",
      "Train O/P: Epoch [13/15], Step [780/938], Loss: 0.0011\n",
      "840\n",
      "Train O/P: Epoch [13/15], Step [840/938], Loss: 0.0115\n",
      "900\n",
      "Train O/P: Epoch [13/15], Step [900/938], Loss: 0.0030\n",
      "60\n",
      "Train O/P: Epoch [14/15], Step [60/938], Loss: 0.0049\n",
      "120\n",
      "Train O/P: Epoch [14/15], Step [120/938], Loss: 0.0071\n",
      "180\n",
      "Train O/P: Epoch [14/15], Step [180/938], Loss: 0.0573\n",
      "240\n",
      "Train O/P: Epoch [14/15], Step [240/938], Loss: 0.0216\n",
      "300\n",
      "Train O/P: Epoch [14/15], Step [300/938], Loss: 0.0013\n",
      "360\n",
      "Train O/P: Epoch [14/15], Step [360/938], Loss: 0.0126\n",
      "420\n",
      "Train O/P: Epoch [14/15], Step [420/938], Loss: 0.0270\n",
      "480\n",
      "Train O/P: Epoch [14/15], Step [480/938], Loss: 0.0008\n",
      "540\n",
      "Train O/P: Epoch [14/15], Step [540/938], Loss: 0.0173\n",
      "600\n",
      "Train O/P: Epoch [14/15], Step [600/938], Loss: 0.0159\n",
      "660\n",
      "Train O/P: Epoch [14/15], Step [660/938], Loss: 0.0014\n",
      "720\n",
      "Train O/P: Epoch [14/15], Step [720/938], Loss: 0.0030\n",
      "780\n",
      "Train O/P: Epoch [14/15], Step [780/938], Loss: 0.0001\n",
      "840\n",
      "Train O/P: Epoch [14/15], Step [840/938], Loss: 0.0092\n",
      "900\n",
      "Train O/P: Epoch [14/15], Step [900/938], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [15/15], Step [60/938], Loss: 0.0109\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [15/15], Step [120/938], Loss: 0.0082\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [15/15], Step [180/938], Loss: 0.0129\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [15/15], Step [240/938], Loss: 0.0224\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [15/15], Step [300/938], Loss: 0.0025\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [15/15], Step [360/938], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [15/15], Step [420/938], Loss: 0.0001\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [15/15], Step [480/938], Loss: 0.0563\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [15/15], Step [540/938], Loss: 0.0069\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [15/15], Step [600/938], Loss: 0.1180\n",
      "Max Epoch Reached\n",
      "660\n",
      "Train O/P: Epoch [15/15], Step [660/938], Loss: 0.0409\n",
      "Max Epoch Reached\n",
      "720\n",
      "Train O/P: Epoch [15/15], Step [720/938], Loss: 0.0176\n",
      "Max Epoch Reached\n",
      "780\n",
      "Train O/P: Epoch [15/15], Step [780/938], Loss: 0.0330\n",
      "Max Epoch Reached\n",
      "840\n",
      "Train O/P: Epoch [15/15], Step [840/938], Loss: 0.0027\n",
      "Max Epoch Reached\n",
      "900\n",
      "Train O/P: Epoch [15/15], Step [900/938], Loss: 0.0018\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 15\n",
    "train_batch_size = 64\n",
    "B1_train_epoch,B1_train_losses,B1_train_acc = trainFunc(mBatch1,max_epochs,train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model with batch_size=1000 is:44426\n"
     ]
    }
   ],
   "source": [
    "# Training Model with batch size=1000\n",
    "torch.manual_seed(1)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "mBatch2 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mBatch2.parameters(), lr=learning_rate) \n",
    "\n",
    "a=[]\n",
    "for i in mBatch2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print(f'Total no of parameters in Model with batch_size={1000} is:{np.sum(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/15], Step [60/60], Loss: 0.4068\n",
      "60\n",
      "Train O/P: Epoch [2/15], Step [60/60], Loss: 0.2528\n",
      "60\n",
      "Train O/P: Epoch [3/15], Step [60/60], Loss: 0.1980\n",
      "60\n",
      "Train O/P: Epoch [4/15], Step [60/60], Loss: 0.1600\n",
      "60\n",
      "Train O/P: Epoch [5/15], Step [60/60], Loss: 0.0876\n",
      "60\n",
      "Train O/P: Epoch [6/15], Step [60/60], Loss: 0.0854\n",
      "60\n",
      "Train O/P: Epoch [7/15], Step [60/60], Loss: 0.0776\n",
      "60\n",
      "Train O/P: Epoch [8/15], Step [60/60], Loss: 0.0991\n",
      "60\n",
      "Train O/P: Epoch [9/15], Step [60/60], Loss: 0.0736\n",
      "60\n",
      "Train O/P: Epoch [10/15], Step [60/60], Loss: 0.0955\n",
      "60\n",
      "Train O/P: Epoch [11/15], Step [60/60], Loss: 0.0578\n",
      "60\n",
      "Train O/P: Epoch [12/15], Step [60/60], Loss: 0.0493\n",
      "60\n",
      "Train O/P: Epoch [13/15], Step [60/60], Loss: 0.0492\n",
      "60\n",
      "Train O/P: Epoch [14/15], Step [60/60], Loss: 0.0379\n",
      "60\n",
      "Train O/P: Epoch [15/15], Step [60/60], Loss: 0.0436\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 15\n",
    "train_batch_size = 1000\n",
    "B2_train_epoch,B2_train_losses,B2_train_acc = trainFunc(mBatch2,max_epochs,train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14070"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(B1_train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Loss plot for both Batch 1 and Batch 2 models\n",
    "#B2_train_epoch,B2_train_losses,B2_train_acc\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(B1_train_epoch,B1_train_losses,color=\"blue\")\n",
    "plt.plot(B2_train_epoch,B2_train_losses,color=\"orange\")\n",
    "plt.title('Batch1 & Bathc2 Loss VS Epoch')\n",
    "plt.legend(['Batch 1','Batch 2'])\n",
    "plt.xlabel ('Epoch')\n",
    "plt.ylabel ('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.761238637409406e-06 0.029463745653629303\n"
     ]
    }
   ],
   "source": [
    "print(np.min(B1_train_losses),np.min(B2_train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1452, -0.0717, -0.1808,  ..., -0.1341,  0.2035, -0.1281],\n",
      "       grad_fn=<CatBackward0>) \n",
      "len: 44426\n"
     ]
    }
   ],
   "source": [
    "batch1_param = torch.nn.utils.parameters_to_vector(mBatch1.parameters())\n",
    "print(batch1_param,'\\nlen:',len(batch1_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0721,  0.1232,  0.0316,  ..., -0.1095,  0.0069,  0.0353],\n",
      "       grad_fn=<CatBackward0>) \n",
      "len: 44426\n"
     ]
    }
   ],
   "source": [
    "batch2_param = torch.nn.utils.parameters_to_vector(mBatch2.parameters())\n",
    "print(batch2_param,'\\nlen:',len(batch2_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.  -1.8 -1.6 -1.4 -1.2 -1.  -0.8 -0.6 -0.4 -0.2  0.   0.2  0.4  0.6\n",
      "  0.8  1.   1.2  1.4  1.6  1.8  2. ]\n"
     ]
    }
   ],
   "source": [
    "alpha = np.linspace(-2.0, 2.0, num=21)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaArr =[]\n",
    "for i in range (len(alpha)):\n",
    "    theta = (1-alpha[i])*batch1_param + alpha[i]*batch2_param\n",
    "    thetaArr.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThetaModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(ThetaModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFunction(model,loss_func,test_batch_size): \n",
    "    test_load = test_loader(test_batch_size)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        for images, labels in test_load:\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            prediction = model(images.view(-1,784))\n",
    "            testLoss += loss_func(prediction,labels).item()\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "    netTest_loss = testLoss/n_samples\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {netTest_acc1} & Test Loss: {netTest_loss} %')\n",
    "    return netTest_acc1, netTest_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model Theta 0 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 7.7941\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.1293\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.1146\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.3483\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0512\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.4781\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.2974\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "Accuracy of the network: 98.82 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.38325991189427 %\n",
      "Accuracy of 2: 99.12790697674419 %\n",
      "Accuracy of 3: 98.41584158415841 %\n",
      "Accuracy of 4: 99.28716904276986 %\n",
      "Accuracy of 5: 98.54260089686099 %\n",
      "Accuracy of 6: 98.43423799582463 %\n",
      "Accuracy of 7: 98.24902723735408 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 98.1169474727453 %\n",
      "Total no of parameters in Model Theta 1 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 4.5116\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.8587\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 1.3781\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.5554\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.2072\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.2842\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "Accuracy of the network: 98.79 %\n",
      "Accuracy of 0: 99.38775510204081 %\n",
      "Accuracy of 1: 99.55947136563877 %\n",
      "Accuracy of 2: 99.03100775193798 %\n",
      "Accuracy of 3: 98.41584158415841 %\n",
      "Accuracy of 4: 99.38900203665987 %\n",
      "Accuracy of 5: 98.65470852017937 %\n",
      "Accuracy of 6: 98.32985386221294 %\n",
      "Accuracy of 7: 98.44357976653697 %\n",
      "Accuracy of 8: 98.870636550308 %\n",
      "Accuracy of 9: 97.7205153617443 %\n",
      "Total no of parameters in Model Theta 2 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 3.0211\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.2060\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.1652\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0608\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0357\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.2805\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.79 %\n",
      "Accuracy of 0: 99.38775510204081 %\n",
      "Accuracy of 1: 99.38325991189427 %\n",
      "Accuracy of 2: 99.03100775193798 %\n",
      "Accuracy of 3: 98.7128712871287 %\n",
      "Accuracy of 4: 99.28716904276986 %\n",
      "Accuracy of 5: 98.87892376681614 %\n",
      "Accuracy of 6: 98.43423799582463 %\n",
      "Accuracy of 7: 98.24902723735408 %\n",
      "Accuracy of 8: 98.56262833675565 %\n",
      "Accuracy of 9: 97.9187314172448 %\n",
      "Total no of parameters in Model Theta 3 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.6288\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.1152\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0529\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0003\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0018\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0101\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0252\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.87 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.20704845814979 %\n",
      "Accuracy of 2: 98.93410852713178 %\n",
      "Accuracy of 3: 98.91089108910892 %\n",
      "Accuracy of 4: 99.08350305498982 %\n",
      "Accuracy of 5: 98.87892376681614 %\n",
      "Accuracy of 6: 98.64300626304802 %\n",
      "Accuracy of 7: 98.05447470817121 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 98.41427155599604 %\n",
      "Total no of parameters in Model Theta 4 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.3658\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.1947\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0223\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0007\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0144\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.95 %\n",
      "Accuracy of 0: 99.48979591836735 %\n",
      "Accuracy of 1: 99.38325991189427 %\n",
      "Accuracy of 2: 99.12790697674419 %\n",
      "Accuracy of 3: 98.7128712871287 %\n",
      "Accuracy of 4: 99.18533604887983 %\n",
      "Accuracy of 5: 99.10313901345292 %\n",
      "Accuracy of 6: 98.74739039665971 %\n",
      "Accuracy of 7: 98.44357976653697 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 98.31516352824579 %\n",
      "Total no of parameters in Model Theta 5 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0289\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.1293\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0306\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "Accuracy of the network: 98.96 %\n",
      "Accuracy of 0: 99.48979591836735 %\n",
      "Accuracy of 1: 99.55947136563877 %\n",
      "Accuracy of 2: 99.12790697674419 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 99.4908350305499 %\n",
      "Accuracy of 5: 98.65470852017937 %\n",
      "Accuracy of 6: 98.74739039665971 %\n",
      "Accuracy of 7: 98.15175097276264 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 98.21605550049554 %\n",
      "Total no of parameters in Model Theta 6 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.3225\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0444\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0267\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0205\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0118\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.0 %\n",
      "Accuracy of 0: 99.48979591836735 %\n",
      "Accuracy of 1: 99.47136563876651 %\n",
      "Accuracy of 2: 99.2248062015504 %\n",
      "Accuracy of 3: 99.00990099009901 %\n",
      "Accuracy of 4: 99.28716904276986 %\n",
      "Accuracy of 5: 98.4304932735426 %\n",
      "Accuracy of 6: 98.8517745302714 %\n",
      "Accuracy of 7: 98.5408560311284 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 98.61248761149653 %\n",
      "Total no of parameters in Model Theta 7 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0370\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0012\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0029\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0071\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0003\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.02 %\n",
      "Accuracy of 0: 99.48979591836735 %\n",
      "Accuracy of 1: 99.38325991189427 %\n",
      "Accuracy of 2: 99.32170542635659 %\n",
      "Accuracy of 3: 99.20792079207921 %\n",
      "Accuracy of 4: 99.18533604887983 %\n",
      "Accuracy of 5: 98.76681614349776 %\n",
      "Accuracy of 6: 98.53862212943632 %\n",
      "Accuracy of 7: 98.63813229571984 %\n",
      "Accuracy of 8: 98.870636550308 %\n",
      "Accuracy of 9: 98.71159563924678 %\n",
      "Total no of parameters in Model Theta 8 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0109\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0010\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0018\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0003\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0043\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0046\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0031\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0057\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.01 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.55947136563877 %\n",
      "Accuracy of 2: 99.4186046511628 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 98.98167006109979 %\n",
      "Accuracy of 5: 98.76681614349776 %\n",
      "Accuracy of 6: 98.22546972860125 %\n",
      "Accuracy of 7: 99.22178988326849 %\n",
      "Accuracy of 8: 98.76796714579055 %\n",
      "Accuracy of 9: 98.31516352824579 %\n",
      "Total no of parameters in Model Theta 9 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0020\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0004\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0028\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0095\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0077\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0190\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0141\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0217\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0128\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0225\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.85 %\n",
      "Accuracy of 0: 99.48979591836735 %\n",
      "Accuracy of 1: 99.20704845814979 %\n",
      "Accuracy of 2: 98.83720930232558 %\n",
      "Accuracy of 3: 99.4059405940594 %\n",
      "Accuracy of 4: 99.69450101832994 %\n",
      "Accuracy of 5: 98.87892376681614 %\n",
      "Accuracy of 6: 97.18162839248434 %\n",
      "Accuracy of 7: 98.92996108949416 %\n",
      "Accuracy of 8: 98.35728952772074 %\n",
      "Accuracy of 9: 98.41427155599604 %\n",
      "Total no of parameters in Model Theta 10 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0045\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0229\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0082\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0198\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0239\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0164\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0055\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0151\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0215\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0179\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.02 %\n",
      "Accuracy of 0: 99.6938775510204 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 99.51550387596899 %\n",
      "Accuracy of 3: 98.81188118811882 %\n",
      "Accuracy of 4: 99.89816700610999 %\n",
      "Accuracy of 5: 99.43946188340807 %\n",
      "Accuracy of 6: 98.01670146137788 %\n",
      "Accuracy of 7: 99.31906614785993 %\n",
      "Accuracy of 8: 97.74127310061601 %\n",
      "Accuracy of 9: 97.7205153617443 %\n",
      "Total no of parameters in Model Theta 11 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0090\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0089\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0171\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0135\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0127\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0080\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0089\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0133\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0198\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0163\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.96 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 99.4186046511628 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 99.89816700610999 %\n",
      "Accuracy of 5: 97.6457399103139 %\n",
      "Accuracy of 6: 98.95615866388309 %\n",
      "Accuracy of 7: 99.22178988326849 %\n",
      "Accuracy of 8: 98.04928131416838 %\n",
      "Accuracy of 9: 97.52229930624381 %\n",
      "Total no of parameters in Model Theta 12 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0342\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0528\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0471\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0211\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0180\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0236\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0220\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0075\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0184\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0188\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.11 %\n",
      "Accuracy of 0: 99.38775510204081 %\n",
      "Accuracy of 1: 99.8237885462555 %\n",
      "Accuracy of 2: 98.54651162790698 %\n",
      "Accuracy of 3: 98.81188118811882 %\n",
      "Accuracy of 4: 99.38900203665987 %\n",
      "Accuracy of 5: 99.32735426008969 %\n",
      "Accuracy of 6: 99.58246346555323 %\n",
      "Accuracy of 7: 99.41634241245136 %\n",
      "Accuracy of 8: 99.07597535934292 %\n",
      "Accuracy of 9: 97.7205153617443 %\n",
      "Total no of parameters in Model Theta 13 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.1211\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0896\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0771\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0922\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0552\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0623\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0451\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0336\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0342\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0459\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.78 %\n",
      "Accuracy of 0: 99.48979591836735 %\n",
      "Accuracy of 1: 99.64757709251101 %\n",
      "Accuracy of 2: 98.44961240310077 %\n",
      "Accuracy of 3: 99.3069306930693 %\n",
      "Accuracy of 4: 99.18533604887983 %\n",
      "Accuracy of 5: 97.98206278026906 %\n",
      "Accuracy of 6: 98.22546972860125 %\n",
      "Accuracy of 7: 98.24902723735408 %\n",
      "Accuracy of 8: 98.4599589322382 %\n",
      "Accuracy of 9: 98.61248761149653 %\n",
      "Total no of parameters in Model Theta 14 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0590\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0548\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0496\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0586\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0514\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0533\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0454\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0542\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0267\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0245\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.61 %\n",
      "Accuracy of 0: 98.87755102040816 %\n",
      "Accuracy of 1: 99.8237885462555 %\n",
      "Accuracy of 2: 98.06201550387597 %\n",
      "Accuracy of 3: 98.31683168316832 %\n",
      "Accuracy of 4: 99.69450101832994 %\n",
      "Accuracy of 5: 99.2152466367713 %\n",
      "Accuracy of 6: 99.26931106471817 %\n",
      "Accuracy of 7: 99.22178988326849 %\n",
      "Accuracy of 8: 95.89322381930185 %\n",
      "Accuracy of 9: 97.62140733399406 %\n",
      "Total no of parameters in Model Theta 15 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0485\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0467\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0490\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0462\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0276\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0339\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0322\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0777\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0421\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0577\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.83 %\n",
      "Accuracy of 0: 99.38775510204081 %\n",
      "Accuracy of 1: 99.55947136563877 %\n",
      "Accuracy of 2: 99.2248062015504 %\n",
      "Accuracy of 3: 98.61386138613861 %\n",
      "Accuracy of 4: 99.59266802443992 %\n",
      "Accuracy of 5: 98.87892376681614 %\n",
      "Accuracy of 6: 99.16492693110648 %\n",
      "Accuracy of 7: 98.92996108949416 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 95.93657086223985 %\n",
      "Total no of parameters in Model Theta 16 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.0497\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0253\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0429\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0478\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0259\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0418\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0272\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0314\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0384\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0592\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.75 %\n",
      "Accuracy of 0: 99.28571428571429 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 98.83720930232558 %\n",
      "Accuracy of 3: 98.7128712871287 %\n",
      "Accuracy of 4: 99.38900203665987 %\n",
      "Accuracy of 5: 98.31838565022422 %\n",
      "Accuracy of 6: 98.74739039665971 %\n",
      "Accuracy of 7: 99.5136186770428 %\n",
      "Accuracy of 8: 97.84394250513347 %\n",
      "Accuracy of 9: 96.72943508424183 %\n",
      "Total no of parameters in Model Theta 17 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.2918\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.0733\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.0972\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.0308\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0592\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.0241\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.0656\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.0390\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.0195\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.0394\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.43 %\n",
      "Accuracy of 0: 98.6734693877551 %\n",
      "Accuracy of 1: 99.73568281938326 %\n",
      "Accuracy of 2: 98.54651162790698 %\n",
      "Accuracy of 3: 97.92079207920793 %\n",
      "Accuracy of 4: 99.38900203665987 %\n",
      "Accuracy of 5: 97.98206278026906 %\n",
      "Accuracy of 6: 98.22546972860125 %\n",
      "Accuracy of 7: 98.83268482490273 %\n",
      "Accuracy of 8: 98.35728952772074 %\n",
      "Accuracy of 9: 96.43211100099109 %\n",
      "Total no of parameters in Model Theta 18 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 0.6186\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.5263\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.4018\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.2611\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.0246\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.1500\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.1896\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.1486\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.1232\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.1540\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.23 %\n",
      "Accuracy of 0: 97.85714285714286 %\n",
      "Accuracy of 1: 99.20704845814979 %\n",
      "Accuracy of 2: 98.25581395348837 %\n",
      "Accuracy of 3: 98.31683168316832 %\n",
      "Accuracy of 4: 99.08350305498982 %\n",
      "Accuracy of 5: 98.65470852017937 %\n",
      "Accuracy of 6: 98.22546972860125 %\n",
      "Accuracy of 7: 97.95719844357977 %\n",
      "Accuracy of 8: 97.02258726899385 %\n",
      "Accuracy of 9: 97.62140733399406 %\n",
      "Total no of parameters in Model Theta 19 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 2.0486\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 0.9638\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 0.5787\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.4549\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.5180\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 0.3559\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 0.1857\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.5196\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.4313\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.2713\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.88 %\n",
      "Accuracy of 0: 98.87755102040816 %\n",
      "Accuracy of 1: 99.38325991189427 %\n",
      "Accuracy of 2: 96.80232558139535 %\n",
      "Accuracy of 3: 98.21782178217822 %\n",
      "Accuracy of 4: 98.37067209775968 %\n",
      "Accuracy of 5: 98.65470852017937 %\n",
      "Accuracy of 6: 98.01670146137788 %\n",
      "Accuracy of 7: 97.95719844357977 %\n",
      "Accuracy of 8: 96.50924024640658 %\n",
      "Accuracy of 9: 95.93657086223985 %\n",
      "Total no of parameters in Model Theta 20 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/100], Loss: 3.0622\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/100], Loss: 1.6922\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/100], Loss: 1.5624\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/100], Loss: 0.8311\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/100], Loss: 0.9747\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/100], Loss: 1.2087\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/100], Loss: 1.2952\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/100], Loss: 0.3811\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/100], Loss: 0.7610\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/100], Loss: 0.5957\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.86 %\n",
      "Accuracy of 0: 98.87755102040816 %\n",
      "Accuracy of 1: 99.55947136563877 %\n",
      "Accuracy of 2: 96.51162790697674 %\n",
      "Accuracy of 3: 98.21782178217822 %\n",
      "Accuracy of 4: 98.77800407331975 %\n",
      "Accuracy of 5: 97.6457399103139 %\n",
      "Accuracy of 6: 98.43423799582463 %\n",
      "Accuracy of 7: 97.76264591439688 %\n",
      "Accuracy of 8: 96.61190965092402 %\n",
      "Accuracy of 9: 96.0356788899901 %\n"
     ]
    }
   ],
   "source": [
    "modelsTrainEpochArr = []\n",
    "modelsTrainLossArr = []\n",
    "modelsTrainAccArr = []\n",
    "modelsTestLossArr = []\n",
    "modelsTestAccArr = []\n",
    "\n",
    "for i in range (len(thetaArr)):\n",
    "    torch.manual_seed(1)\n",
    "    j=copy.deepcopy(i) \n",
    "    theta = (1-alpha[i])*batch1_param + alpha[i]*batch2_param\n",
    "    j = ThetaModel()\n",
    "    torch.nn.utils.vector_to_parameters(theta,j.parameters())\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(j.parameters(), lr=1e-3, weight_decay = 1e-3)\n",
    "\n",
    "    a=[]\n",
    "    for k in j.parameters():\n",
    "        a.append(torch.numel(k))\n",
    "    print(f'Total no of parameters in Model Theta {i} is:{np.sum(a)}')\n",
    "\n",
    "    print(j.parameters)\n",
    "\n",
    "    max_epochs = 10\n",
    "    train_batch_size = 600\n",
    "    T_train_epoch,T_train_losses,T_train_acc = trainFunc(j,max_epochs,train_batch_size)\n",
    "    \n",
    "    \n",
    "    modelsTrainEpochArr.append(T_train_epoch)\n",
    "    modelsTrainLossArr.append(T_train_losses)\n",
    "    modelsTrainAccArr.append(T_train_acc)\n",
    "    \n",
    "    test_batch_size=100\n",
    "    T_acc, T_testLoss = testFunction(j,loss_func,test_batch_size)\n",
    "    modelsTestAccArr.append(T_acc)\n",
    "    modelsTestLossArr.append(T_testLoss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modelsTrainAccArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanScore(dataArr):\n",
    "    meanModelData = []\n",
    "    for i in range (len(dataArr)):\n",
    "        meanScore = np.mean(dataArr[i])\n",
    "        meanModelData.append(meanScore)\n",
    "    return meanModelData\n",
    "\n",
    "def minScore(dataArr):\n",
    "    minModelScore = []\n",
    "    for i in range (len(dataArr)):\n",
    "        minScore = np.mean(dataArr[i])\n",
    "        minModelScore.append(minScore)\n",
    "    return minModelScore\n",
    "\n",
    "def maxScore(dataArr):\n",
    "    maxModelScore = []\n",
    "    for i in range (len(dataArr)):\n",
    "        maxScore = np.max(dataArr[i])\n",
    "        maxModelScore.append(maxScore)\n",
    "    return maxModelScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(alpha,minScore(modelsTrainLossArr),color=\"Blue\",linestyle='dashed', marker=\"o\")\n",
    "ax.plot(alpha,modelsTestLossArr,color=\"Blue\", marker=\"v\")\n",
    "ax.legend(['Train Loss','Test Loss'],loc=\"center left\")\n",
    "ax.set_xlabel(\"Alpha\",color=\"Green\")\n",
    "ax.set_ylabel(\"CrossEntropy Loss\",color = \"blue\")\n",
    "\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(alpha,meanScore(modelsTrainAccArr),color=\"red\",linestyle='dashed', marker=\"o\")\n",
    "ax2.plot(alpha,modelsTestAccArr,color=\"red\", marker=\"v\")\n",
    "ax2.set_xlabel(\"Alpha\",color=\"Green\")\n",
    "ax2.set_ylabel(\"Accuracy\",color = \"red\")\n",
    "ax2.legend(['Train Acc','Test Acc'],loc=\"upper right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/Diff Batch Graph HW1_3.1-2.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=100,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model with batch_size=600 is:44426\n"
     ]
    }
   ],
   "source": [
    "# Training Model with batch size=600 and Lr 1e-3\n",
    "torch.manual_seed(1)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "mLr1 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mLr1.parameters(), lr=learning_rate) \n",
    "\n",
    "a=[]\n",
    "for i in mLr1.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print(f'Total no of parameters in Model with batch_size={600} is:{np.sum(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/15], Step [60/100], Loss: 0.4467\n",
      "60\n",
      "Train O/P: Epoch [2/15], Step [60/100], Loss: 0.2091\n",
      "60\n",
      "Train O/P: Epoch [3/15], Step [60/100], Loss: 0.1739\n",
      "60\n",
      "Train O/P: Epoch [4/15], Step [60/100], Loss: 0.1380\n",
      "60\n",
      "Train O/P: Epoch [5/15], Step [60/100], Loss: 0.0962\n",
      "60\n",
      "Train O/P: Epoch [6/15], Step [60/100], Loss: 0.0940\n",
      "60\n",
      "Train O/P: Epoch [7/15], Step [60/100], Loss: 0.0603\n",
      "60\n",
      "Train O/P: Epoch [8/15], Step [60/100], Loss: 0.0595\n",
      "60\n",
      "Train O/P: Epoch [9/15], Step [60/100], Loss: 0.0451\n",
      "60\n",
      "Train O/P: Epoch [10/15], Step [60/100], Loss: 0.0813\n",
      "60\n",
      "Train O/P: Epoch [11/15], Step [60/100], Loss: 0.0764\n",
      "60\n",
      "Train O/P: Epoch [12/15], Step [60/100], Loss: 0.0654\n",
      "60\n",
      "Train O/P: Epoch [13/15], Step [60/100], Loss: 0.0282\n",
      "60\n",
      "Train O/P: Epoch [14/15], Step [60/100], Loss: 0.0254\n",
      "60\n",
      "Train O/P: Epoch [15/15], Step [60/100], Loss: 0.0519\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 15\n",
    "train_batch_size = 600\n",
    "L1_train_epoch,L1_train_losses,L1_train_acc = trainFunc(mLr1,max_epochs,train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2162, -0.0055,  0.1604,  ...,  0.0580,  0.0107,  0.0287],\n",
      "       grad_fn=<CatBackward0>) \n",
      "len: 44426\n"
     ]
    }
   ],
   "source": [
    "Lr1_param = torch.nn.utils.parameters_to_vector(mLr1.parameters())\n",
    "print(Lr1_param,'\\nlen:',len(Lr1_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model with batch_size=600 is:44426\n"
     ]
    }
   ],
   "source": [
    "# Training Model with batch size=600 and Lr 1e-2\n",
    "torch.manual_seed(1)\n",
    "learning_rate = 1e-2\n",
    "mLr2 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mLr2.parameters(), lr=learning_rate) \n",
    "\n",
    "a=[]\n",
    "for i in mLr2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print(f'Total no of parameters in Model with batch_size={600} is:{np.sum(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/15], Step [60/100], Loss: 0.1449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/2359820831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mL2_train_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL2_train_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL2_train_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmLr2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/4268376742.py\u001b[0m in \u001b[0;36mtrainFunc\u001b[1;34m(model, num_epochs, train_batch_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mn_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_load\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 15\n",
    "train_batch_size = 600\n",
    "L2_train_epoch,L2_train_losses,L2_train_acc = trainFunc(mLr2,max_epochs,train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Loss plot for both Batch 1 and Batch 2 models\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(L1_train_epoch,L1_train_losses,color=\"blue\")\n",
    "plt.plot(L2_train_epoch,L2_train_losses,color=\"orange\")\n",
    "plt.title('Lr1 & Lr2 Loss VS Epoch',color=\"green\")\n",
    "plt.legend(['LR1:1e-3 1','LR2:1e-2'])\n",
    "plt.xlabel ('Epoch')\n",
    "plt.ylabel ('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1537,  0.0506, -0.1578,  ..., -0.0158,  0.2174,  0.1149],\n",
      "       grad_fn=<CatBackward0>) \n",
      "len: 44426\n"
     ]
    }
   ],
   "source": [
    "Lr2_param = torch.nn.utils.parameters_to_vector(mLr2.parameters())\n",
    "print(Lr2_param,'\\nlen:',len(Lr2_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model Theta 0 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 1637.4631\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 418.1249\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 368.0636\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 300.8780\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 230.1769\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 171.9456\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 201.8221\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 105.0604\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 127.8167\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 85.1975\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 124.0965\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 43.9560\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 101.7330\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 80.7401\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 112.2103\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 52.1100\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 178.5645\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 117.5863\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 82.4428\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 85.2541\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 39.4827\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 62.9782\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 88.1673\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 46.2566\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 37.1272\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 64.3851\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 107.6067\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 38.1119\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 78.5086\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 46.4278\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 25.8208\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 28.8639\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 35.9537\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 41.3247\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 37.6592\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 45.1445\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 22.7970\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 74.3839\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 75.8918\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 115.4057\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 20.2938\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 3.5737\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 32.0681\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 30.9982\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 29.0143\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 75.1869\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 39.4067\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 29.6111\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 14.6509\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 50.1706\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 5.9199\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 4.0345\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 1.8407\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 62.4719\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 18.4797\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 109.5254\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 55.9966\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 61.5062\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 65.3548\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 9.9576\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 65.9334\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 3.8359\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 74.0795\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 15.5685\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.4230\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 9.3300\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 53.3368\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 41.4273\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 14.6729\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 2.7953\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 9.1791\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 49.2302\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 59.3948\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 34.6467\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 45.2364\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 23.6196\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 21.7049\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 62.2113\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 3.7622\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 1.4826\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 25.4612\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 30.1722\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 51.0748\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 20.0138\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 5.9426\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 3.5915\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 15.9226\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 16.0981\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 5.2320\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 15.0854\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 14.3291\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 33.0401\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 4.7131\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 28.5236\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 33.2906\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 31.3660\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 4.9627\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 20.4537\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 2.5845\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 6.0176\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.12 %\n",
      "Accuracy of 0: 98.77551020408163 %\n",
      "Accuracy of 1: 97.70925110132158 %\n",
      "Accuracy of 2: 96.12403100775194 %\n",
      "Accuracy of 3: 97.02970297029702 %\n",
      "Accuracy of 4: 98.16700610997964 %\n",
      "Accuracy of 5: 96.52466367713005 %\n",
      "Accuracy of 6: 97.49478079331942 %\n",
      "Accuracy of 7: 96.01167315175097 %\n",
      "Accuracy of 8: 98.4599589322382 %\n",
      "Accuracy of 9: 94.94549058473736 %\n",
      "Total no of parameters in Model Theta 1 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 1002.4482\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 206.2471\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 215.6941\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 178.6972\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 115.9449\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 89.0575\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 128.4196\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 67.5831\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 68.1221\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 48.9597\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 67.6125\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 26.4570\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 69.1311\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 36.2942\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 63.5875\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 24.7267\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 85.2298\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 67.2852\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 56.8910\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 54.5602\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 21.9451\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 23.2653\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 43.5986\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 17.9012\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 33.8899\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 29.3414\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 63.1593\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 28.5721\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 51.4140\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 27.5958\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 16.5541\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 10.9595\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 24.0562\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 33.7830\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 30.0491\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 16.2744\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 5.2065\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 48.4770\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 37.7155\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 61.1830\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 7.1991\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 1.2209\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 13.5619\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 18.8767\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 15.6806\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 43.3696\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 23.1336\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 13.1826\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 7.4607\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 26.8865\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 3.8414\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 3.9350\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 3.8051\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 41.7792\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 20.7296\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 64.9518\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 33.8306\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 43.6988\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 31.8871\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 1.5861\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 32.4013\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.4385\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 58.1090\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 9.2671\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.6936\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 5.4416\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 30.7279\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 24.9760\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 8.7919\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0226\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 4.4704\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 36.8102\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 38.3726\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 24.1749\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 25.3690\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 13.1222\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 8.6949\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 36.6002\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 6.1978\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 3.9860\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 13.9778\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 17.2011\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 29.7700\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 9.2738\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 1.1106\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 5.5198\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 9.2929\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 6.1341\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 3.6706\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 4.3656\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 5.2121\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 18.4601\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.8237\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 13.5372\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 14.7019\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 17.1859\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 1.3590\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 13.0382\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 1.8754\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 3.2512\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.46 %\n",
      "Accuracy of 0: 98.57142857142857 %\n",
      "Accuracy of 1: 98.14977973568281 %\n",
      "Accuracy of 2: 97.18992248062015 %\n",
      "Accuracy of 3: 98.91089108910892 %\n",
      "Accuracy of 4: 96.84317718940937 %\n",
      "Accuracy of 5: 97.53363228699551 %\n",
      "Accuracy of 6: 98.12108559498957 %\n",
      "Accuracy of 7: 97.27626459143968 %\n",
      "Accuracy of 8: 96.50924024640658 %\n",
      "Accuracy of 9: 95.44103072348861 %\n",
      "Total no of parameters in Model Theta 2 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 421.6077\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 100.8999\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 96.4173\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 99.9551\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 44.4016\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 41.9013\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 77.7291\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 24.4021\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 34.5997\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 20.7265\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 44.7754\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 13.6560\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 37.4827\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 15.5193\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 41.4097\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 10.2504\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 57.6478\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 25.3679\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 45.9743\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 31.1679\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 15.7311\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 10.1877\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 17.1243\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 8.5122\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 12.6199\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 15.2075\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 29.2816\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 13.1937\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 25.1041\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 10.7400\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 6.1675\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 4.4589\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 4.1902\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 16.8991\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 15.6863\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 12.5929\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 2.8961\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 27.9062\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 23.3838\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 37.3521\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 5.5816\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 1.6628\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 10.7041\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 11.9765\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 7.4738\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 20.8200\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 15.8078\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 7.9638\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 6.5812\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 13.0602\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 1.3992\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.1382\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 1.6499\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 27.1987\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 12.2464\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 37.8658\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 13.7676\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 39.5956\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 15.6037\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 1.9781\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 18.1977\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0145\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 35.8035\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 3.4754\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 2.9612\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 18.8152\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 10.5090\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 3.9183\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 1.0771\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 4.4192\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 17.2355\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 18.9229\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 12.6065\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 9.9089\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 5.7220\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 4.4702\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 19.1158\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 2.2474\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 1.2099\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 9.7094\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 13.0132\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 10.1584\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 6.6715\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.5008\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 2.7112\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 6.3433\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 3.1251\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 1.3305\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 3.2222\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 3.2143\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 5.9391\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 2.3195\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 7.4009\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 9.4631\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 13.2069\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.6609\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 8.9623\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.7484\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 2.4170\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.66 %\n",
      "Accuracy of 0: 99.08163265306122 %\n",
      "Accuracy of 1: 98.8546255506608 %\n",
      "Accuracy of 2: 97.28682170542636 %\n",
      "Accuracy of 3: 98.51485148514851 %\n",
      "Accuracy of 4: 97.45417515274949 %\n",
      "Accuracy of 5: 97.6457399103139 %\n",
      "Accuracy of 6: 98.32985386221294 %\n",
      "Accuracy of 7: 96.49805447470817 %\n",
      "Accuracy of 8: 96.91991786447639 %\n",
      "Accuracy of 9: 95.93657086223985 %\n",
      "Total no of parameters in Model Theta 3 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 166.5583\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 47.4568\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 45.6533\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 49.8051\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 22.2823\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 21.5687\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 37.5312\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 5.9680\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 21.3210\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 8.9552\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 27.1074\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 7.8650\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 19.9340\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 10.2407\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 20.7330\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 3.5922\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 31.0399\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 13.4088\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 19.5377\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 14.2500\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 7.4000\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 4.3273\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 9.1305\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 2.8398\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 2.3721\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 6.0738\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 15.1658\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 5.8969\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 14.3280\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 6.6026\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 4.9233\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 1.2716\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 5.0082\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 7.6099\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 14.2458\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 6.1223\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 2.0845\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 16.2816\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 12.2575\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 22.0574\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 2.4841\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.5866\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 3.3597\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 3.6503\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 1.4215\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 10.5554\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 9.8665\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 6.1045\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 2.5246\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 5.3763\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 1.7126\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.4654\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 11.1935\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 3.2985\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 16.9477\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 6.5777\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 13.4673\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 8.4991\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.2242\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 9.9264\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0947\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 13.5803\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 1.9862\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.2871\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 1.8145\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 10.4899\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 4.6556\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.6951\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.2435\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 1.0209\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 9.5223\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 6.0113\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 5.5105\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 6.3072\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 4.1231\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.2729\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 9.8172\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 1.5117\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0961\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 5.5713\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 5.5665\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 5.2225\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 2.3144\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 3.4107\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 1.9672\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 3.2145\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 1.4103\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0031\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 1.7809\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 4.5690\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.2425\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 4.0095\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 3.6186\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 4.0992\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.4406\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 2.2948\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.4794\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0001\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.39 %\n",
      "Accuracy of 0: 98.9795918367347 %\n",
      "Accuracy of 1: 98.76651982378854 %\n",
      "Accuracy of 2: 96.99612403100775 %\n",
      "Accuracy of 3: 99.20792079207921 %\n",
      "Accuracy of 4: 95.010183299389 %\n",
      "Accuracy of 5: 95.85201793721973 %\n",
      "Accuracy of 6: 98.43423799582463 %\n",
      "Accuracy of 7: 97.08171206225681 %\n",
      "Accuracy of 8: 96.20123203285421 %\n",
      "Accuracy of 9: 97.02675916749257 %\n",
      "Total no of parameters in Model Theta 4 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 64.3966\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 17.7800\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 17.7933\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 22.0359\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 8.6347\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 6.9505\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 15.3807\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.4961\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 8.0166\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 3.9343\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 11.3095\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 6.2601\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 10.9931\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 4.0569\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 10.0151\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.1864\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 15.4766\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 6.2421\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 8.5743\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 7.3444\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 3.3416\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 2.2722\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 4.9621\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 2.8159\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 2.4192\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 6.9934\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 3.6856\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 8.2931\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 3.6960\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 2.2077\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 2.3651\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.7232\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 2.7667\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 4.4471\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 1.4518\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 1.4875\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 9.1164\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 4.9524\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 8.7787\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 1.8090\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.7840\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.6944\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 3.9819\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 2.1228\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 8.3270\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 4.6268\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 3.6721\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 1.5902\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 2.7804\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0109\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.8294\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.6096\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 5.5822\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 2.0532\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 9.4850\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 3.4277\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 7.9530\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 4.1137\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 6.2049\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0284\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 4.9362\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 1.5262\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.3642\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0816\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 3.4545\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 1.9352\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 1.1305\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.5828\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.4530\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 5.3361\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 2.8352\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 2.5053\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 2.7915\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 2.0216\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.1757\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 5.4838\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 1.1060\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 3.0378\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 2.7854\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 4.8427\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 1.5427\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.7905\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 1.3238\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.9714\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.4137\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.3698\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 1.1703\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 2.0821\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 2.1281\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 2.3929\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 2.1888\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 1.2729\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.5965\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0358\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.25 %\n",
      "Accuracy of 0: 98.26530612244898 %\n",
      "Accuracy of 1: 98.32599118942731 %\n",
      "Accuracy of 2: 95.83333333333333 %\n",
      "Accuracy of 3: 98.7128712871287 %\n",
      "Accuracy of 4: 95.010183299389 %\n",
      "Accuracy of 5: 96.8609865470852 %\n",
      "Accuracy of 6: 98.64300626304802 %\n",
      "Accuracy of 7: 95.91439688715953 %\n",
      "Accuracy of 8: 96.91991786447639 %\n",
      "Accuracy of 9: 97.9187314172448 %\n",
      "Total no of parameters in Model Theta 5 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 13.9601\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 6.3642\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 5.4830\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 7.4314\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 2.9023\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 3.8221\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 6.8953\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.2268\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 3.2784\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 1.7243\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 6.0584\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 2.7760\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 5.4753\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 1.6784\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 3.5776\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.6473\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 5.9008\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 2.8159\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 2.4028\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 4.5549\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 1.5074\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.9517\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 1.4507\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0312\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.3274\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 3.0022\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 1.2009\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 3.0769\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 1.2167\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 1.0687\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 1.4374\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.1877\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.3589\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 2.2172\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 1.1441\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.9721\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 3.9746\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 2.1309\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 3.1686\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.3744\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.7922\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0966\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 1.8583\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 1.1722\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 3.3319\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 2.2114\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 1.8028\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.2289\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 1.0969\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0776\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.8382\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.2886\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 2.3087\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.8574\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 4.0062\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 1.3910\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 2.5832\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 2.1716\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 3.8202\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0678\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 2.7714\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.3272\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.1038\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.1551\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 1.7666\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.7814\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.5566\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.3204\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0001\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 1.6088\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 1.0365\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.6188\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 1.1603\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.9396\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0830\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 2.4408\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.5167\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.2536\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 1.2493\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.9408\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 1.4755\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.6959\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.4924\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.6411\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.5955\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.1411\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.3585\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 1.4498\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.3984\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.7562\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 1.0736\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.1911\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.8916\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.3381\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.3533\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.08 %\n",
      "Accuracy of 0: 98.26530612244898 %\n",
      "Accuracy of 1: 96.2114537444934 %\n",
      "Accuracy of 2: 94.0891472868217 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 95.41751527494908 %\n",
      "Accuracy of 5: 97.30941704035874 %\n",
      "Accuracy of 6: 98.64300626304802 %\n",
      "Accuracy of 7: 96.98443579766537 %\n",
      "Accuracy of 8: 98.04928131416838 %\n",
      "Accuracy of 9: 97.02675916749257 %\n",
      "Total no of parameters in Model Theta 6 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 4.4089\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 1.4764\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 1.3684\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 2.2054\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.8121\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 1.7538\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 3.0042\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0818\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 1.3322\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.6385\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 3.1760\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 1.3332\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 1.4928\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.7985\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 2.0554\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.3133\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 2.5815\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 1.1432\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 1.1984\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 2.2118\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.6443\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0635\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.6590\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.1033\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.2492\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 1.4977\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.5406\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.7517\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.2824\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.5714\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.4291\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0031\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.4513\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.7240\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.3699\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.4909\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 1.8683\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.5022\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 1.0239\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.2713\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0281\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.2399\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.4225\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.9920\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 1.2001\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.6877\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.1827\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.3977\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.2399\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.1583\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.5059\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.4757\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 1.3328\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.4510\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 1.3818\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.4824\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.9862\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.1507\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 1.0043\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.1369\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0850\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0335\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.5326\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.1060\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0578\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0272\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.2315\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.1644\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.1894\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.5185\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.2732\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.4216\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0592\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.8271\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.2173\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0224\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.3872\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.2254\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.4795\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.2937\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.1082\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.1324\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.2822\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0509\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0132\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0006\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0021\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.3034\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0026\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.1198\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.2917\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.3699\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0245\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.3353\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0487\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0105\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 97.79 %\n",
      "Accuracy of 0: 98.6734693877551 %\n",
      "Accuracy of 1: 98.59030837004406 %\n",
      "Accuracy of 2: 97.28682170542636 %\n",
      "Accuracy of 3: 99.3069306930693 %\n",
      "Accuracy of 4: 93.78818737270876 %\n",
      "Accuracy of 5: 97.30941704035874 %\n",
      "Accuracy of 6: 98.53862212943632 %\n",
      "Accuracy of 7: 97.95719844357977 %\n",
      "Accuracy of 8: 98.25462012320328 %\n",
      "Accuracy of 9: 98.01783944499505 %\n",
      "Total no of parameters in Model Theta 7 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.9386\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.3790\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.4446\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.8729\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.5036\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.9683\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 1.5429\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0001\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.5057\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.3545\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 1.6543\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.1928\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.5089\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.3414\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.9001\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.1078\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.7657\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.2195\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.3804\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.9653\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.2838\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0266\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.3570\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0285\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0582\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.4592\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.1360\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.2233\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0105\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.1262\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.1842\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0351\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.1504\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.2136\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0325\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.2104\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.7178\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.1946\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.1541\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.1215\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0001\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0071\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0448\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.3939\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.3625\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.1508\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0115\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0963\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0094\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0716\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0003\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.1114\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0928\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.4429\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.2460\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.4027\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.1509\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0004\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.4022\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0471\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.2495\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0682\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0029\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0081\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0480\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0283\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0201\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0481\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0041\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0555\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0618\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.2184\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.1148\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0090\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0030\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.2829\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0540\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0098\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0465\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0813\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.1215\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0857\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0662\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0482\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0819\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0161\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0228\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0007\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0160\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0628\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0001\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0387\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.1274\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0721\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0320\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.1287\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0047\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0079\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.3 %\n",
      "Accuracy of 0: 99.28571428571429 %\n",
      "Accuracy of 1: 98.6784140969163 %\n",
      "Accuracy of 2: 97.77131782945736 %\n",
      "Accuracy of 3: 99.20792079207921 %\n",
      "Accuracy of 4: 96.84317718940937 %\n",
      "Accuracy of 5: 97.19730941704036 %\n",
      "Accuracy of 6: 98.01670146137788 %\n",
      "Accuracy of 7: 98.24902723735408 %\n",
      "Accuracy of 8: 98.76796714579055 %\n",
      "Accuracy of 9: 98.81070366699703 %\n",
      "Total no of parameters in Model Theta 8 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0626\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0427\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.2459\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.2861\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.2461\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.3983\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.6864\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0005\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0478\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.1713\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.2841\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0567\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.1197\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.1364\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.1602\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0291\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.1307\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0004\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0775\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.2017\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0687\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0545\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0001\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0183\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0679\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.1490\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0115\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0747\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0147\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0084\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.1119\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0073\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0313\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0323\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0074\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0394\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.1818\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0581\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0120\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0440\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0093\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0075\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0097\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0452\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0564\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0975\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0400\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0126\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0431\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0034\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0123\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0040\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0735\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0319\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.1419\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0315\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.2336\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0274\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0071\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.1407\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0156\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0669\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0206\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0109\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0119\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0255\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0584\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0173\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0074\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0025\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0214\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0111\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0619\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0522\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0051\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0074\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.1051\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0398\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0019\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0391\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0332\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0394\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0439\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0105\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0114\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0654\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0183\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0024\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0038\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0325\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0115\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0077\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0506\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0314\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0386\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0020\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0423\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0188\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0498\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.79 %\n",
      "Accuracy of 0: 99.38775510204081 %\n",
      "Accuracy of 1: 99.38325991189427 %\n",
      "Accuracy of 2: 98.64341085271317 %\n",
      "Accuracy of 3: 99.00990099009901 %\n",
      "Accuracy of 4: 98.06517311608961 %\n",
      "Accuracy of 5: 98.31838565022422 %\n",
      "Accuracy of 6: 99.16492693110648 %\n",
      "Accuracy of 7: 98.15175097276264 %\n",
      "Accuracy of 8: 98.97330595482546 %\n",
      "Accuracy of 9: 98.71159563924678 %\n",
      "Total no of parameters in Model Theta 9 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.1289\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0042\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0088\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0863\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0553\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.1365\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.1401\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0173\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0141\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0557\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0433\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0108\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0445\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0435\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0210\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0145\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0264\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0019\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.1357\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0569\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0263\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0012\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0618\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0011\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0190\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0220\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0737\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0049\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0801\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0098\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0092\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.1227\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0057\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0115\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0564\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0041\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0104\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.1250\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0179\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0264\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0428\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0243\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0166\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0197\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0329\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0202\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0521\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0153\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0064\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0272\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0075\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0159\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0053\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0527\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0164\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0678\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0087\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.1363\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0273\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0030\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.0551\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0105\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0359\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0097\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0041\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0026\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0127\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0477\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0431\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0049\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0045\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0547\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0117\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0321\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0071\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0122\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0298\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0689\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0212\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0054\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0096\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0198\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0090\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0269\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0016\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0205\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0873\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0170\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0019\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0031\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0100\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0021\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0056\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0511\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0160\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0104\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0033\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0543\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0196\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0198\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.68 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 97.79735682819383 %\n",
      "Accuracy of 2: 99.51550387596899 %\n",
      "Accuracy of 3: 99.20792079207921 %\n",
      "Accuracy of 4: 97.35234215885947 %\n",
      "Accuracy of 5: 98.99103139013452 %\n",
      "Accuracy of 6: 98.53862212943632 %\n",
      "Accuracy of 7: 98.92996108949416 %\n",
      "Accuracy of 8: 99.28131416837782 %\n",
      "Accuracy of 9: 97.7205153617443 %\n",
      "Total no of parameters in Model Theta 10 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0362\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0129\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0327\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0409\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0468\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0520\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.1092\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0199\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0197\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0939\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0449\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0169\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0335\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0572\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0590\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0136\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0432\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0097\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.1059\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0597\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0267\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0049\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0819\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0017\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0331\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0317\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0489\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0025\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0811\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0142\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0168\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.1053\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0134\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0142\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0438\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0048\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0102\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.1049\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0255\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0286\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0507\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0165\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0311\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0270\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0236\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0365\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0442\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0203\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0031\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0124\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0024\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0108\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0020\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0460\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0036\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0348\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0114\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0865\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0333\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0016\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.1019\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0215\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0458\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0077\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0029\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0028\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0051\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0683\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0245\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0256\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0009\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0844\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0109\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0118\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0179\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0476\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0211\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0592\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0071\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0078\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0400\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0105\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0184\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0255\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0033\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0111\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0644\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0168\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0021\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0010\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0051\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0051\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0016\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0295\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0377\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0113\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0010\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0358\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0107\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0306\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.42 %\n",
      "Accuracy of 0: 98.77551020408163 %\n",
      "Accuracy of 1: 99.03083700440529 %\n",
      "Accuracy of 2: 94.96124031007751 %\n",
      "Accuracy of 3: 99.70297029702971 %\n",
      "Accuracy of 4: 98.4725050916497 %\n",
      "Accuracy of 5: 99.2152466367713 %\n",
      "Accuracy of 6: 98.01670146137788 %\n",
      "Accuracy of 7: 98.63813229571984 %\n",
      "Accuracy of 8: 98.4599589322382 %\n",
      "Accuracy of 9: 99.00891972249752 %\n",
      "Total no of parameters in Model Theta 11 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0422\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0234\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0359\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0584\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0448\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0795\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.1117\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0448\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0213\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.1000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0637\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0376\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0440\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0833\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0531\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0144\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0485\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0074\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0824\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0702\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0224\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0060\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0913\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0045\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0262\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0175\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0381\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0047\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0889\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0329\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0073\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.1020\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0185\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0336\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0361\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0055\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0174\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.1383\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0359\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0215\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0558\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0075\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0306\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0160\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0181\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0397\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0414\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0204\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0054\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0092\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0019\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0053\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0036\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0404\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0118\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0606\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0075\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0572\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0205\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0031\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.0657\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0317\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0566\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0045\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0055\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0015\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0102\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0762\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0125\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0098\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0029\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0389\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0070\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0283\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0126\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0241\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0614\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0547\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0080\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0018\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0110\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0086\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0063\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0602\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0018\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0042\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0735\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0164\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0024\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0021\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0239\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0017\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0048\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0245\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0073\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0036\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0020\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0179\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0257\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0049\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.68 %\n",
      "Accuracy of 0: 99.18367346938776 %\n",
      "Accuracy of 1: 99.73568281938326 %\n",
      "Accuracy of 2: 97.28682170542636 %\n",
      "Accuracy of 3: 99.8019801980198 %\n",
      "Accuracy of 4: 98.16700610997964 %\n",
      "Accuracy of 5: 98.76681614349776 %\n",
      "Accuracy of 6: 98.32985386221294 %\n",
      "Accuracy of 7: 99.0272373540856 %\n",
      "Accuracy of 8: 98.35728952772074 %\n",
      "Accuracy of 9: 98.01783944499505 %\n",
      "Total no of parameters in Model Theta 12 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.1027\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0454\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0456\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0347\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0411\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.1144\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0640\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0343\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0329\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0533\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0285\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0248\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0086\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0219\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0323\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0041\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0111\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0038\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0559\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0442\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0045\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0015\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0625\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0011\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0206\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0123\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0222\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0031\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0320\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0016\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0050\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0115\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0012\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0069\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0026\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0047\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0006\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0223\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0265\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0134\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0166\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0030\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0015\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0138\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0036\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0200\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0267\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0314\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0126\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0017\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0179\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0015\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0006\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0032\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0028\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0317\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0019\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0223\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0272\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0170\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.0332\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0077\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0065\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0061\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0029\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0048\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0091\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0073\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0009\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0019\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0035\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0007\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0008\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0010\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0242\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0067\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0021\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0408\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0040\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0017\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0064\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0104\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0019\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0585\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0076\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0003\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0048\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0107\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0011\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0001\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0040\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0323\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0063\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0058\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0160\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0009\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.14 %\n",
      "Accuracy of 0: 99.08163265306122 %\n",
      "Accuracy of 1: 99.8237885462555 %\n",
      "Accuracy of 2: 98.74031007751938 %\n",
      "Accuracy of 3: 99.70297029702971 %\n",
      "Accuracy of 4: 98.67617107942974 %\n",
      "Accuracy of 5: 98.54260089686099 %\n",
      "Accuracy of 6: 99.26931106471817 %\n",
      "Accuracy of 7: 99.12451361867704 %\n",
      "Accuracy of 8: 98.76796714579055 %\n",
      "Accuracy of 9: 99.50445986124876 %\n",
      "Total no of parameters in Model Theta 13 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0195\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0244\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0106\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0035\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0094\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0311\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0328\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0040\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0154\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0179\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0096\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0063\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0031\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0009\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0090\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0016\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0033\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0025\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0155\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0174\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0024\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0005\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0269\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0001\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0005\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0036\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0042\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0009\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0112\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0006\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0003\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0094\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0002\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0051\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0002\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0351\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0002\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0156\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0002\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0043\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0031\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0001\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0002\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0020\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0018\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0061\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0013\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0216\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0002\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0003\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0001\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0005\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0004\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0005\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0197\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0112\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0012\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0003\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0186\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0089\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.0069\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0053\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0234\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0053\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0019\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0052\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0009\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0008\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0024\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0010\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0098\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0008\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0014\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0005\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0157\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0039\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0041\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0003\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0015\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0034\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0004\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0002\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0314\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0002\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0003\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0675\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0001\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0327\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0003\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0024\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 98.94 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 98.44961240310077 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 97.86150712830957 %\n",
      "Accuracy of 5: 98.87892376681614 %\n",
      "Accuracy of 6: 98.74739039665971 %\n",
      "Accuracy of 7: 99.0272373540856 %\n",
      "Accuracy of 8: 98.66529774127311 %\n",
      "Accuracy of 9: 99.00891972249752 %\n",
      "Total no of parameters in Model Theta 14 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0072\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0176\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0038\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0006\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0009\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0101\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0140\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0011\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0012\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0005\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0034\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0024\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0007\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0002\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0057\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0004\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0037\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0001\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0023\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0008\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0002\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0012\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0019\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0007\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0018\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0017\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0001\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0031\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0003\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0011\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0034\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0001\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0001\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0180\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0033\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0010\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0006\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0001\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0002\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0031\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0024\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0200\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0004\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0011\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0049\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0148\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0034\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0056\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0003\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0012\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.0019\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0007\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0004\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0016\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0011\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0046\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0003\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0009\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0004\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0334\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0008\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0129\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [9/10], Step [60/600], Loss: 0.0008\n",
      "120\n",
      "Train O/P: Epoch [9/10], Step [120/600], Loss: 0.0018\n",
      "180\n",
      "Train O/P: Epoch [9/10], Step [180/600], Loss: 0.0007\n",
      "240\n",
      "Train O/P: Epoch [9/10], Step [240/600], Loss: 0.0008\n",
      "300\n",
      "Train O/P: Epoch [9/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [9/10], Step [360/600], Loss: 0.0001\n",
      "420\n",
      "Train O/P: Epoch [9/10], Step [420/600], Loss: 0.0152\n",
      "480\n",
      "Train O/P: Epoch [9/10], Step [480/600], Loss: 0.0096\n",
      "540\n",
      "Train O/P: Epoch [9/10], Step [540/600], Loss: 0.0002\n",
      "600\n",
      "Train O/P: Epoch [9/10], Step [600/600], Loss: 0.0022\n",
      "60\n",
      "Train O/P: Epoch [10/10], Step [60/600], Loss: 0.0017\n",
      "Max Epoch Reached\n",
      "120\n",
      "Train O/P: Epoch [10/10], Step [120/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "180\n",
      "Train O/P: Epoch [10/10], Step [180/600], Loss: 0.0000\n",
      "Max Epoch Reached\n",
      "240\n",
      "Train O/P: Epoch [10/10], Step [240/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "300\n",
      "Train O/P: Epoch [10/10], Step [300/600], Loss: 0.0003\n",
      "Max Epoch Reached\n",
      "360\n",
      "Train O/P: Epoch [10/10], Step [360/600], Loss: 0.0001\n",
      "Max Epoch Reached\n",
      "420\n",
      "Train O/P: Epoch [10/10], Step [420/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "480\n",
      "Train O/P: Epoch [10/10], Step [480/600], Loss: 0.0003\n",
      "Max Epoch Reached\n",
      "540\n",
      "Train O/P: Epoch [10/10], Step [540/600], Loss: 0.0002\n",
      "Max Epoch Reached\n",
      "600\n",
      "Train O/P: Epoch [10/10], Step [600/600], Loss: 0.0003\n",
      "Max Epoch Reached\n",
      "Accuracy of the network: 99.11 %\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.73568281938326 %\n",
      "Accuracy of 2: 98.54651162790698 %\n",
      "Accuracy of 3: 99.4059405940594 %\n",
      "Accuracy of 4: 98.87983706720978 %\n",
      "Accuracy of 5: 98.99103139013452 %\n",
      "Accuracy of 6: 98.64300626304802 %\n",
      "Accuracy of 7: 99.22178988326849 %\n",
      "Accuracy of 8: 99.38398357289527 %\n",
      "Accuracy of 9: 98.61248761149653 %\n",
      "Total no of parameters in Model Theta 15 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0026\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0019\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0063\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0001\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0007\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0464\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0041\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0022\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0005\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0040\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0010\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0043\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0002\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0084\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0005\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0013\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0003\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0053\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0018\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0054\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0018\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0005\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0022\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0003\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0212\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0010\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0010\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0006\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0001\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0001\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0004\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0002\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0042\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0043\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0004\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0004\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0028\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0003\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0015\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0010\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0003\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0007\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0003\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0866\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0003\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [7/10], Step [60/600], Loss: 0.0009\n",
      "120\n",
      "Train O/P: Epoch [7/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [7/10], Step [180/600], Loss: 0.0013\n",
      "240\n",
      "Train O/P: Epoch [7/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [7/10], Step [300/600], Loss: 0.0013\n",
      "360\n",
      "Train O/P: Epoch [7/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [7/10], Step [420/600], Loss: 0.0006\n",
      "480\n",
      "Train O/P: Epoch [7/10], Step [480/600], Loss: 0.0006\n",
      "540\n",
      "Train O/P: Epoch [7/10], Step [540/600], Loss: 0.0005\n",
      "600\n",
      "Train O/P: Epoch [7/10], Step [600/600], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [8/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [8/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [8/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [8/10], Step [240/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 6.355587174766697e-06\n",
      "300\n",
      "Train O/P: Epoch [8/10], Step [300/600], Loss: 0.0001\n",
      "360\n",
      "Train O/P: Epoch [8/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [8/10], Step [420/600], Loss: 0.0001\n",
      "480\n",
      "Train O/P: Epoch [8/10], Step [480/600], Loss: 0.0004\n",
      "540\n",
      "Train O/P: Epoch [8/10], Step [540/600], Loss: 0.0031\n",
      "600\n",
      "Train O/P: Epoch [8/10], Step [600/600], Loss: 0.0000\n",
      "Accuracy of the network: 98.93 %\n",
      "Accuracy of 0: 99.38775510204081 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 99.03100775193798 %\n",
      "Accuracy of 3: 99.20792079207921 %\n",
      "Accuracy of 4: 99.28716904276986 %\n",
      "Accuracy of 5: 98.76681614349776 %\n",
      "Accuracy of 6: 98.43423799582463 %\n",
      "Accuracy of 7: 98.63813229571984 %\n",
      "Accuracy of 8: 98.76796714579055 %\n",
      "Accuracy of 9: 97.7205153617443 %\n",
      "Total no of parameters in Model Theta 16 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0009\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0073\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0001\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0001\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0465\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0006\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0025\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0064\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0001\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0009\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0005\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0005\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0010\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0001\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0001\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0085\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0151\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0004\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0003\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0003\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0001\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0016\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0006\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0001\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0010\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0107\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 5.131324087415123e-06\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0001\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0005\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0003\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0018\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0455\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0146\n",
      "Accuracy of the network: 98.87 %\n",
      "Accuracy of 0: 99.18367346938776 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 99.03100775193798 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 99.4908350305499 %\n",
      "Accuracy of 5: 98.31838565022422 %\n",
      "Accuracy of 6: 98.22546972860125 %\n",
      "Accuracy of 7: 99.12451361867704 %\n",
      "Accuracy of 8: 98.15195071868582 %\n",
      "Accuracy of 9: 97.9187314172448 %\n",
      "Total no of parameters in Model Theta 17 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0218\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.0288\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0001\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.0088\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0268\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0397\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0099\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0006\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0021\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0003\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0043\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0001\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0004\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0002\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0002\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0004\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0066\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0006\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0001\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0003\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0198\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 1.2587969422384049e-06\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0009\n",
      "Accuracy of the network: 98.83 %\n",
      "Accuracy of 0: 98.87755102040816 %\n",
      "Accuracy of 1: 99.64757709251101 %\n",
      "Accuracy of 2: 97.96511627906976 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 98.87983706720978 %\n",
      "Accuracy of 5: 99.10313901345292 %\n",
      "Accuracy of 6: 98.74739039665971 %\n",
      "Accuracy of 7: 99.12451361867704 %\n",
      "Accuracy of 8: 98.4599589322382 %\n",
      "Accuracy of 9: 98.31516352824579 %\n",
      "Total no of parameters in Model Theta 18 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.0479\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.3912\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.0002\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0379\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.2913\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.0635\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.0004\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0002\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.2247\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0092\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0002\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0010\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0026\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0001\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 3.57627816249817e-09\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0002\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 4.76837103136063e-09\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0000\n",
      "Accuracy of the network: 98.83 %\n",
      "Accuracy of 0: 99.18367346938776 %\n",
      "Accuracy of 1: 99.91189427312776 %\n",
      "Accuracy of 2: 98.93410852713178 %\n",
      "Accuracy of 3: 98.61386138613861 %\n",
      "Accuracy of 4: 99.4908350305499 %\n",
      "Accuracy of 5: 99.2152466367713 %\n",
      "Accuracy of 6: 98.43423799582463 %\n",
      "Accuracy of 7: 98.5408560311284 %\n",
      "Accuracy of 8: 98.4599589322382 %\n",
      "Accuracy of 9: 97.42319127849356 %\n",
      "Total no of parameters in Model Theta 19 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.1728\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.1518\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 0.8799\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.1777\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.0009\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.5764\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.2985\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.3680\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.1234\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0569\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.1197\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.1272\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0003\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.0910\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0509\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.1238\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.2552\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 7.15255499272871e-09\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0224\n",
      "Accuracy of the network: 98.9 %\n",
      "Accuracy of 0: 99.28571428571429 %\n",
      "Accuracy of 1: 99.8237885462555 %\n",
      "Accuracy of 2: 98.35271317829458 %\n",
      "Accuracy of 3: 99.10891089108911 %\n",
      "Accuracy of 4: 99.38900203665987 %\n",
      "Accuracy of 5: 98.87892376681614 %\n",
      "Accuracy of 6: 98.74739039665971 %\n",
      "Accuracy of 7: 98.83268482490273 %\n",
      "Accuracy of 8: 98.35728952772074 %\n",
      "Accuracy of 9: 98.1169474727453 %\n",
      "Total no of parameters in Model Theta 20 is:44426\n",
      "<bound method Module.parameters of ThetaModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "strated\n",
      "60\n",
      "Train O/P: Epoch [1/10], Step [60/600], Loss: 0.5561\n",
      "120\n",
      "Train O/P: Epoch [1/10], Step [120/600], Loss: 0.4424\n",
      "180\n",
      "Train O/P: Epoch [1/10], Step [180/600], Loss: 1.3519\n",
      "240\n",
      "Train O/P: Epoch [1/10], Step [240/600], Loss: 0.5426\n",
      "300\n",
      "Train O/P: Epoch [1/10], Step [300/600], Loss: 0.1193\n",
      "360\n",
      "Train O/P: Epoch [1/10], Step [360/600], Loss: 0.6776\n",
      "420\n",
      "Train O/P: Epoch [1/10], Step [420/600], Loss: 0.7998\n",
      "480\n",
      "Train O/P: Epoch [1/10], Step [480/600], Loss: 0.2532\n",
      "540\n",
      "Train O/P: Epoch [1/10], Step [540/600], Loss: 0.8934\n",
      "600\n",
      "Train O/P: Epoch [1/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [2/10], Step [60/600], Loss: 0.8595\n",
      "120\n",
      "Train O/P: Epoch [2/10], Step [120/600], Loss: 0.0517\n",
      "180\n",
      "Train O/P: Epoch [2/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [2/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [2/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [2/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [2/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [2/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [2/10], Step [540/600], Loss: 0.0004\n",
      "600\n",
      "Train O/P: Epoch [2/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [3/10], Step [60/600], Loss: 0.0905\n",
      "120\n",
      "Train O/P: Epoch [3/10], Step [120/600], Loss: 0.0944\n",
      "180\n",
      "Train O/P: Epoch [3/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [3/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [3/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [3/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [3/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [3/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [3/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [3/10], Step [600/600], Loss: 0.0000\n",
      "60\n",
      "Train O/P: Epoch [4/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [4/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [4/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [4/10], Step [240/600], Loss: 0.0001\n",
      "300\n",
      "Train O/P: Epoch [4/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [4/10], Step [360/600], Loss: 0.0440\n",
      "420\n",
      "Train O/P: Epoch [4/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [4/10], Step [480/600], Loss: 0.0000\n",
      "540\n",
      "Train O/P: Epoch [4/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [4/10], Step [600/600], Loss: 0.0001\n",
      "60\n",
      "Train O/P: Epoch [5/10], Step [60/600], Loss: 0.0000\n",
      "120\n",
      "Train O/P: Epoch [5/10], Step [120/600], Loss: 0.0000\n",
      "180\n",
      "Train O/P: Epoch [5/10], Step [180/600], Loss: 0.0000\n",
      "240\n",
      "Train O/P: Epoch [5/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [5/10], Step [300/600], Loss: 0.0000\n",
      "360\n",
      "Train O/P: Epoch [5/10], Step [360/600], Loss: 0.3040\n",
      "420\n",
      "Train O/P: Epoch [5/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [5/10], Step [480/600], Loss: 0.0240\n",
      "540\n",
      "Train O/P: Epoch [5/10], Step [540/600], Loss: 0.0000\n",
      "600\n",
      "Train O/P: Epoch [5/10], Step [600/600], Loss: 0.0002\n",
      "60\n",
      "Train O/P: Epoch [6/10], Step [60/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "120\n",
      "Train O/P: Epoch [6/10], Step [120/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "180\n",
      "Train O/P: Epoch [6/10], Step [180/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 0.0\n",
      "240\n",
      "Train O/P: Epoch [6/10], Step [240/600], Loss: 0.0000\n",
      "300\n",
      "Train O/P: Epoch [6/10], Step [300/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 1.8034738786809612e-06\n",
      "360\n",
      "Train O/P: Epoch [6/10], Step [360/600], Loss: 0.0000\n",
      "420\n",
      "Train O/P: Epoch [6/10], Step [420/600], Loss: 0.0000\n",
      "480\n",
      "Train O/P: Epoch [6/10], Step [480/600], Loss: 0.0000\n",
      "Convergeance reached for loss: 2.384185515680315e-09\n",
      "540\n",
      "Train O/P: Epoch [6/10], Step [540/600], Loss: 0.1894\n",
      "600\n",
      "Train O/P: Epoch [6/10], Step [600/600], Loss: 0.0000\n",
      "Accuracy of the network: 98.81 %\n",
      "Accuracy of 0: 99.28571428571429 %\n",
      "Accuracy of 1: 99.64757709251101 %\n",
      "Accuracy of 2: 98.25581395348837 %\n",
      "Accuracy of 3: 99.4059405940594 %\n",
      "Accuracy of 4: 99.18533604887983 %\n",
      "Accuracy of 5: 98.76681614349776 %\n",
      "Accuracy of 6: 98.12108559498957 %\n",
      "Accuracy of 7: 98.83268482490273 %\n",
      "Accuracy of 8: 98.56262833675565 %\n",
      "Accuracy of 9: 97.9187314172448 %\n"
     ]
    }
   ],
   "source": [
    "modelsTrainEpochArr2 = []\n",
    "modelsTrainLossArr2 = []\n",
    "modelsTrainAccArr2 = []\n",
    "modelsTestLossArr2 = []\n",
    "modelsTestAccArr2 = []\n",
    "\n",
    "for i in range (len(thetaArr)):\n",
    "    torch.manual_seed(1)\n",
    "    j=copy.deepcopy(i) \n",
    "    theta = (1-alpha[i])*Lr1_param + alpha[i]*Lr2_param\n",
    "    j = ThetaModel()\n",
    "    torch.nn.utils.vector_to_parameters(theta,j.parameters())\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(j.parameters(), lr=1e-3) #,weight_decay = 0.025)\n",
    "\n",
    "    a=[]\n",
    "    for k in j.parameters():\n",
    "        a.append(torch.numel(k))\n",
    "    print(f'Total no of parameters in Model Theta {i} is:{np.sum(a)}')\n",
    "\n",
    "    print(j.parameters)\n",
    "\n",
    "    max_epochs = 10\n",
    "    train_batch_size = 100\n",
    "    T2_train_epoch,T2_train_losses,T2_train_acc = trainFunc(j,max_epochs,train_batch_size)\n",
    "    \n",
    "    \n",
    "    modelsTrainEpochArr2.append(T2_train_epoch)\n",
    "    modelsTrainLossArr2.append(T2_train_losses)\n",
    "    modelsTrainAccArr2.append(T2_train_acc)\n",
    "    \n",
    "    test_batch_size=100\n",
    "    T2_acc,T2_testLoss = testFunction(j,loss_func,test_batch_size)\n",
    "    modelsTestAccArr2.append(T2_acc)\n",
    "    modelsTestLossArr2.append(T2_testLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[310.1402684374017,\n",
       " 172.59364071225968,\n",
       " 89.17589414596391,\n",
       " 42.78788178806028,\n",
       " 18.62020404238436,\n",
       " 6.873967383569505,\n",
       " 2.131608360368283,\n",
       " 0.4933437744478459,\n",
       " 0.09109144894537377,\n",
       " 0.03394285839404377,\n",
       " 0.028886959449934996,\n",
       " 0.03331263043906559,\n",
       " 0.02082007058689184,\n",
       " 0.008260503195342144,\n",
       " 0.004136263995554228,\n",
       " 0.0034190745792683033,\n",
       " 0.004794595348309028,\n",
       " 0.00991937046009258,\n",
       " 0.029298394115174452,\n",
       " 0.10251386178016751,\n",
       " 0.2812579852127412]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minScore(modelsTrainLossArr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[91.22106366204012,\n",
       " 91.92085143539865,\n",
       " 92.60466792681208,\n",
       " 93.32766679830172,\n",
       " 94.21690440118134,\n",
       " 95.19674251867532,\n",
       " 96.18443179571901,\n",
       " 97.21484278329571,\n",
       " 98.35542627233791,\n",
       " 98.94332274667612,\n",
       " 99.08626264149595,\n",
       " 98.90442268149577,\n",
       " 99.18195146041214,\n",
       " 99.71884746556238,\n",
       " 99.87382572256621,\n",
       " 99.89638332909288,\n",
       " 99.87554672531694,\n",
       " 99.81411822392091,\n",
       " 99.66834303004914,\n",
       " 99.36680332772698,\n",
       " 99.04475320249861]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanScore(modelsTrainAccArr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(alpha,minScore(modelsTrainLossArr2),color=\"Blue\",linestyle='dashed', marker=\"o\")\n",
    "ax.plot(alpha,modelsTestLossArr2,color=\"Blue\", marker=\"v\")\n",
    "ax.legend(['Train Loss','Test Loss'],loc=\"center left\")\n",
    "ax.set_xlabel(\"Alpha\",color=\"Green\")\n",
    "ax.set_ylabel(\"CrossEntropy Loss\",color = \"blue\")\n",
    "ax.set_title(\"learning rate 1e-3 vs. 1e-2\",color = \"green\")\n",
    "\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(alpha,maxScore(modelsTrainAccArr2),color=\"red\",linestyle='dashed', marker=\"o\")\n",
    "ax2.plot(alpha,modelsTestAccArr2,color=\"red\", marker=\"v\")\n",
    "ax2.set_xlabel(\"Alpha\",color=\"Green\")\n",
    "ax2.set_ylabel(\"Accuracy\",color = \"red\")\n",
    "ax2.legend(['Train Acc','Test Acc'],loc=\"upper right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/Diff Batch Graph HW1_3.1Lr.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=100,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
