{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cf28a588b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader func\n",
    "def train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def test_loader(batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs,train_batch_size,status_interval):\n",
    "    model.train()\n",
    "    print('strated')\n",
    "    train_load = train_loader(train_batch_size)\n",
    "    n_total_steps = len(train_load)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    epoch = 0\n",
    "    modelParamWgt={}\n",
    "    for epoch in range (num_epochs):\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        lossSum =0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_load):  \n",
    "            #if (i+1)% 60 == 0 : print(i+1)\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "\n",
    "            images.requires_grad = True\n",
    "\n",
    "            loss = loss_func(prediction, labels)\n",
    "            lossSum += loss\n",
    "\n",
    "            # Backward and optimize\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            train_epoch.append(epoch)\n",
    "\n",
    "            #print(epoch,i)\n",
    "            \n",
    "            #Weight Collection\n",
    "            if epoch % 3 == 0:\n",
    "                for name, parameter in model.named_parameters():\n",
    "                    #print(name)\n",
    "                    if'weight' in name:\n",
    "                        modelParamWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "                        #print(modelParamWgt)\n",
    "\n",
    "            #Print Status\n",
    "            if (i+1) % status_interval == 0:\n",
    "                print (f'Train O/P: Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}',end= '\\r',flush = True)\n",
    "               \n",
    "                        \n",
    "    trainAvgLoss = lossSum/train_batch_size\n",
    "    print(\"Train Avg loss:\",trainAvgLoss)\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc,trainAvgLoss, modelParamWgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFunction(model,loss_func,test_batch_size): \n",
    "    test_load = test_loader(test_batch_size)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        count = 0\n",
    "        for images, labels in test_load:\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            prediction = model(images)\n",
    "            testLoss += loss_func(prediction,labels).item()\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            count += 1\n",
    "    netTest_loss = testLoss/count\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {netTest_acc1}% & Test Loss: {netTest_loss}',end= '\\r',flush = True)\n",
    "    return netTest_acc1, netTest_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaOps(paramDF,itr):\n",
    "    pcaOperation =  PCA(n_components=2)\n",
    "\n",
    "    scale = StandardScaler()\n",
    "\n",
    "    sData = scale.fit_transform(paramDF)\n",
    "\n",
    "    pcaVal = pcaOperation.fit_transform(sData)\n",
    "\n",
    "    itrData = np.full((pcaVal.shape[0],1),itr)\n",
    "\n",
    "    #pcaDf = pd.DataFrame(data = pcaVal, columns = ['x','y'])\n",
    "\n",
    "    pcaDf = pd.DataFrame(np.append(pcaVal,itrData,axis=1),columns=['x','y','Itr No.'])\n",
    "\n",
    "    return pcaDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 0\n",
      "strated\n",
      "Train Avg loss: tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Accuracy of the network on the test images: 96.61% & Test Loss: 0.11178956017829478\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12724/900306675.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mtempDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcaVal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitrData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Itr No.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mpcaDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpcaDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#pcaDf = pd.DataFrame(np.append(pcaVal,itrData,axis=1),columns=['x','y','Itr No.'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   8963\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8964\u001b[0m         return (\n\u001b[1;32m-> 8965\u001b[1;33m             concat(\n\u001b[0m\u001b[0;32m   8966\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8967\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 )\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mndims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "#Main Implementation\n",
    "\n",
    "modelParamArr = []\n",
    "pcaDf = pd.DataFrame(columns=['x','y','Itr No.'])\n",
    "\n",
    "\n",
    "for itr in range(2):\n",
    "    print('Iteration No:', itr)\n",
    "    j = copy.deepcopy(itr) \n",
    "    j = Model()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(j.parameters(), lr=0.0015, weight_decay = 1e-4)\n",
    "\n",
    "    max_epochs = 15\n",
    "    train_batch_size = int(6000)\n",
    "    test_batch_size = int(100)\n",
    "    status_interval = 10\n",
    "\n",
    "    train_epoch,train_losses,train_acc,trainAvgLoss, modelParamWgt = trainFunc(j,max_epochs,train_batch_size,status_interval)\n",
    "\n",
    "    testAcc, testLoss = testFunction(j,loss_func,test_batch_size)\n",
    "\n",
    "    #modelParamArr.append(modelParamWgt.values())\n",
    "\n",
    "    paramDF = pd.DataFrame.from_dict(data=modelParamWgt,orient='index')\n",
    "\n",
    "    \n",
    "    #PCA Dim Reduction.\n",
    "    pcaOperation =  PCA(n_components=2)\n",
    "\n",
    "    scale = StandardScaler()\n",
    "\n",
    "    sData = scale.fit_transform(paramDF)\n",
    "\n",
    "    pcaVal = pcaOperation.fit_transform(sData)\n",
    "\n",
    "    itrData = np.full((pcaVal.shape[0],1),itr)\n",
    "\n",
    "    #pcaDf = pd.DataFrame(data = pcaVal, columns = ['x','y'])\n",
    "\n",
    "    tempDf = pd.DataFrame(np.append(pcaVal,itrData,axis=1),columns=['x','y','Itr No.'])\n",
    "\n",
    "    pcaDf = pcaDf.append(tempDf, ignore_index=True)\n",
    "\n",
    "    #pcaDf = pd.DataFrame(np.append(pcaVal,itrData,axis=1),columns=['x','y','Itr No.'])\n",
    "\n",
    "    #resultDf = pcaOps(paramDF,itr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the Optimization Process\n",
    "\n",
    "plt.scatter(pcaDf['x'],pcaDf['y'],color=\"Blue\")\n",
    "plt.title(\"PCA for model\",color=\"g\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 52.34460831, -14.32252502,   0.        ],\n",
       "       [  8.18269444,  23.91380692,   0.        ],\n",
       "       [ -8.30943966,  12.75551414,   0.        ],\n",
       "       [-20.90570831,  -3.81560445,   0.        ],\n",
       "       [-31.31209564, -18.53119278,   0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1190</th>\n",
       "      <th>1191</th>\n",
       "      <th>1192</th>\n",
       "      <th>1193</th>\n",
       "      <th>1194</th>\n",
       "      <th>1195</th>\n",
       "      <th>1196</th>\n",
       "      <th>1197</th>\n",
       "      <th>1198</th>\n",
       "      <th>1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117564</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>-0.075532</td>\n",
       "      <td>0.076026</td>\n",
       "      <td>-0.067839</td>\n",
       "      <td>-0.052811</td>\n",
       "      <td>-0.110147</td>\n",
       "      <td>-0.034520</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>-0.035932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006191</td>\n",
       "      <td>-0.124151</td>\n",
       "      <td>0.048117</td>\n",
       "      <td>0.122245</td>\n",
       "      <td>-0.123885</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.068712</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>-0.118104</td>\n",
       "      <td>0.053652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122224</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>-0.063526</td>\n",
       "      <td>0.076529</td>\n",
       "      <td>-0.079562</td>\n",
       "      <td>-0.050047</td>\n",
       "      <td>-0.107680</td>\n",
       "      <td>-0.014998</td>\n",
       "      <td>0.040480</td>\n",
       "      <td>-0.009068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004734</td>\n",
       "      <td>-0.110660</td>\n",
       "      <td>0.067423</td>\n",
       "      <td>0.120205</td>\n",
       "      <td>-0.161034</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>-0.053685</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>-0.132502</td>\n",
       "      <td>0.050665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.126328</td>\n",
       "      <td>0.012067</td>\n",
       "      <td>-0.056330</td>\n",
       "      <td>0.077770</td>\n",
       "      <td>-0.081589</td>\n",
       "      <td>-0.047198</td>\n",
       "      <td>-0.104539</td>\n",
       "      <td>-0.019767</td>\n",
       "      <td>0.039037</td>\n",
       "      <td>-0.012085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>-0.111702</td>\n",
       "      <td>0.079076</td>\n",
       "      <td>0.118276</td>\n",
       "      <td>-0.194864</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>-0.038436</td>\n",
       "      <td>0.064421</td>\n",
       "      <td>-0.131541</td>\n",
       "      <td>0.047479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.127561</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>-0.050411</td>\n",
       "      <td>0.077413</td>\n",
       "      <td>-0.080743</td>\n",
       "      <td>-0.044032</td>\n",
       "      <td>-0.107599</td>\n",
       "      <td>-0.019042</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>-0.018347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.115866</td>\n",
       "      <td>0.087569</td>\n",
       "      <td>0.116077</td>\n",
       "      <td>-0.223273</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>-0.025667</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>-0.129104</td>\n",
       "      <td>0.043955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.128591</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>-0.045130</td>\n",
       "      <td>0.077372</td>\n",
       "      <td>-0.078854</td>\n",
       "      <td>-0.040668</td>\n",
       "      <td>-0.110636</td>\n",
       "      <td>-0.017943</td>\n",
       "      <td>0.034705</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.120453</td>\n",
       "      <td>0.092560</td>\n",
       "      <td>0.114321</td>\n",
       "      <td>-0.247307</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>-0.016050</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>-0.126885</td>\n",
       "      <td>0.040239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "3   0.117564  0.014307 -0.075532  0.076026 -0.067839 -0.052811 -0.110147   \n",
       "6   0.122224  0.013080 -0.063526  0.076529 -0.079562 -0.050047 -0.107680   \n",
       "9   0.126328  0.012067 -0.056330  0.077770 -0.081589 -0.047198 -0.104539   \n",
       "12  0.127561  0.010979 -0.050411  0.077413 -0.080743 -0.044032 -0.107599   \n",
       "15  0.128591  0.009852 -0.045130  0.077372 -0.078854 -0.040668 -0.110636   \n",
       "\n",
       "        7         8         9     ...      1190      1191      1192      1193  \\\n",
       "3  -0.034520  0.046511 -0.035932  ... -0.006191 -0.124151  0.048117  0.122245   \n",
       "6  -0.014998  0.040480 -0.009068  ... -0.004734 -0.110660  0.067423  0.120205   \n",
       "9  -0.019767  0.039037 -0.012085  ... -0.010970 -0.111702  0.079076  0.118276   \n",
       "12 -0.019042  0.037173 -0.018347  ... -0.016896 -0.115866  0.087569  0.116077   \n",
       "15 -0.017943  0.034705 -0.020888  ... -0.020674 -0.120453  0.092560  0.114321   \n",
       "\n",
       "        1194      1195      1196      1197      1198      1199  \n",
       "3  -0.123885  0.026735 -0.068712  0.068010 -0.118104  0.053652  \n",
       "6  -0.161034  0.038831 -0.053685  0.065366 -0.132502  0.050665  \n",
       "9  -0.194864  0.033695 -0.038436  0.064421 -0.131541  0.047479  \n",
       "12 -0.223273  0.025398 -0.025667  0.065067 -0.129104  0.043955  \n",
       "15 -0.247307  0.016488 -0.016050  0.066087 -0.126885  0.040239  \n",
       "\n",
       "[5 rows x 1200 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
