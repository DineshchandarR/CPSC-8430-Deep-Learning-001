{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7606a1-8326-4f14-8a0b-b56b85ca2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac104ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28f1b4abaf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c108c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4497617b-aa3e-45bf-9225-0908be3cc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67450546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomLabelsTrain = torch.tensor(np.random.randint(0,10, (len(train_dataset)),))\n",
    "# print(len(randomLabelsTrain))\n",
    "# randomLabelsTest = torch.tensor(np.random.randint(0,10, (len(test_dataset)),))\n",
    "# print(len(randomLabelsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4270434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.targets = randomLabelsTrain\n",
    "# test_dataset.targets = randomLabelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb887d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef45032-4873-469d-8fed-c88b8095b1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "    plt.title(\"Actual Val: {}\".format(example_targets[i]),color='white')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762ab56d-6dbb-40cd-97b6-91a5c8eae46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "max_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "kernel_size = 4\n",
    "weight_decay_val = 1e-4\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47473b54-b57c-4650-a6fa-57af14833660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN1(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super(CNN1, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "#         self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "#         self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.fc2 = nn.Linear(50, 100)\n",
    "#         self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # -> n, 3, 32, 32\n",
    "#         x = self.pool(F.relu(self.conv1(x)))  \n",
    "#         x = self.pool(F.relu(self.conv2(x)))  \n",
    "#         x = x.view(-1, 320)            #Flattening \n",
    "#         x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "#         x = self.dropout(x)   \n",
    "#         x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "#         x = self.fc3(x)                #O/P Layer       \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c220f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandMnist (nn.Module):\n",
    "    def __init__(self,) :\n",
    "        super(RandMnist,self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 100) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.fc2(x)               #O/P Layer                   \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a1720a-be73-4af6-9f12-7c84e0b48c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 1: 79510\n"
     ]
    }
   ],
   "source": [
    "rmnist = RandMnist()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rmnist.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in rmnist.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print('Total no of parameters in Model 1:', np.sum(a),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0820f1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21600/299264109.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'images'"
     ]
    }
   ],
   "source": [
    "test_loader.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbeb313e-f7e2-4ed3-b059-190a1d63819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = []\n",
    "# train_epoch = []\n",
    "# train_acc = []\n",
    "# test_losses = []\n",
    "# test_epoch = []\n",
    "# not_converged =True\n",
    "# epoch = 0\n",
    "# Train the model\n",
    "\n",
    "#for epoch in range(num_epochs):\n",
    "def testFunc(model,num_epochs):\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    test_losses = []\n",
    "    test_epoch = []\n",
    "    netTest_acc1Arr = []\n",
    "    #not_converged =True\n",
    "    \n",
    "    epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            labels_rand = labels.detach().numpy()\n",
    "            np.random.shuffle(labels_rand)\n",
    "            labels_rand = torch.from_numpy(labels_rand)\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = model(images.view(-1,784))\n",
    "            #prediction = model(images)\n",
    "            loss = loss_func(prediction, labels_rand)\n",
    "            #loss = F.nll_loss(prediction, labels_rand)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels_rand).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            # if (i+1) % 100 == 0:\n",
    "            #     print (f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], TrainLoss: {loss.item():.4f}')#,TestLoss: {test_loss.item():.4f}')\n",
    "            #     train_epoch.append(epoch)\n",
    "            #     train_losses.append(loss.item())\n",
    "            #     print(f'Epoch [{epoch}/{num_epochs}], TrainAccuracy : {acc} %') #, TestAccuracy : {netTest_acc1}%')\n",
    "            #     train_acc.append(acc)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                n_correct = 0\n",
    "                n_samples = 0\n",
    "                n_class_correct = [0 for j in range(10)]\n",
    "                n_class_samples = [0 for j in range(10)]\n",
    "                for test_images, test_labels in test_loader:\n",
    "                    outputs = model(test_images.view(-1,784))\n",
    "                    test_loss = loss_func(outputs, test_labels)\n",
    "                    test_losses.append(test_loss)\n",
    "                    # max returns (value ,index)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    n_samples += test_labels.size(0)\n",
    "                    n_correct += (predicted == test_labels).sum().item()\n",
    "                    \n",
    "                    for j in range(100):\n",
    "                        label = test_labels[j]\n",
    "                        pred = predicted[j]\n",
    "                        if (label == pred):\n",
    "                            n_class_correct[label] += 1\n",
    "                        n_class_samples[label] += 1\n",
    "                netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "                netTest_acc1Arr.append(netTest_acc1)\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print (f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], TrainLoss: {loss.item():.4f},TestLoss: {test_loss.item():.4f}')\n",
    "                train_epoch.append(epoch)\n",
    "                train_losses.append(loss.item())\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], TrainAccuracy : {acc} %, TestAccuracy : {netTest_acc1}%')\n",
    "\n",
    "    \n",
    "            \n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc,test_losses,netTest_acc1Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb54c942-f483-4ae5-916b-de2467da80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [100/100], TrainLoss: 2.3028,TestLoss: 2.2970\n",
      "Epoch [1/1000], TrainAccuracy : 11.367924528301886 %, TestAccuracy : 11.35%\n",
      "Epoch [2/1000], Step [100/100], TrainLoss: 2.3015,TestLoss: 2.2964\n",
      "Epoch [2/1000], TrainAccuracy : 11.320754716981131 %, TestAccuracy : 11.35%\n",
      "Epoch [3/1000], Step [100/100], TrainLoss: 2.2967,TestLoss: 2.3003\n",
      "Epoch [3/1000], TrainAccuracy : 11.556603773584905 %, TestAccuracy : 11.35%\n",
      "Epoch [4/1000], Step [100/100], TrainLoss: 2.3059,TestLoss: 2.2981\n",
      "Epoch [4/1000], TrainAccuracy : 11.40566037735849 %, TestAccuracy : 11.35%\n",
      "Epoch [5/1000], Step [100/100], TrainLoss: 2.3008,TestLoss: 2.2981\n",
      "Epoch [5/1000], TrainAccuracy : 11.367924528301886 %, TestAccuracy : 11.35%\n",
      "Epoch [6/1000], Step [100/100], TrainLoss: 2.2979,TestLoss: 2.2965\n",
      "Epoch [6/1000], TrainAccuracy : 11.339622641509434 %, TestAccuracy : 11.35%\n",
      "Epoch [7/1000], Step [100/100], TrainLoss: 2.3021,TestLoss: 2.2985\n",
      "Epoch [7/1000], TrainAccuracy : 11.38679245283019 %, TestAccuracy : 11.35%\n",
      "Epoch [8/1000], Step [100/100], TrainLoss: 2.2966,TestLoss: 2.2977\n",
      "Epoch [8/1000], TrainAccuracy : 11.452830188679245 %, TestAccuracy : 11.35%\n",
      "Epoch [9/1000], Step [100/100], TrainLoss: 2.3041,TestLoss: 2.2993\n",
      "Epoch [9/1000], TrainAccuracy : 11.245283018867925 %, TestAccuracy : 11.35%\n",
      "Epoch [10/1000], Step [100/100], TrainLoss: 2.3015,TestLoss: 2.2985\n",
      "Epoch [10/1000], TrainAccuracy : 11.38679245283019 %, TestAccuracy : 11.35%\n",
      "Epoch [11/1000], Step [100/100], TrainLoss: 2.3033,TestLoss: 2.2972\n",
      "Epoch [11/1000], TrainAccuracy : 11.349056603773585 %, TestAccuracy : 11.35%\n",
      "Epoch [12/1000], Step [100/100], TrainLoss: 2.2978,TestLoss: 2.2977\n",
      "Epoch [12/1000], TrainAccuracy : 11.5 %, TestAccuracy : 11.35%\n",
      "Epoch [13/1000], Step [100/100], TrainLoss: 2.3015,TestLoss: 2.2982\n",
      "Epoch [13/1000], TrainAccuracy : 11.320754716981131 %, TestAccuracy : 11.35%\n",
      "Epoch [14/1000], Step [100/100], TrainLoss: 2.2981,TestLoss: 2.2981\n",
      "Epoch [14/1000], TrainAccuracy : 11.39622641509434 %, TestAccuracy : 11.35%\n",
      "Epoch [15/1000], Step [100/100], TrainLoss: 2.3021,TestLoss: 2.2988\n",
      "Epoch [15/1000], TrainAccuracy : 11.349056603773585 %, TestAccuracy : 11.35%\n",
      "Epoch [16/1000], Step [100/100], TrainLoss: 2.3058,TestLoss: 2.2979\n",
      "Epoch [16/1000], TrainAccuracy : 11.358490566037736 %, TestAccuracy : 11.35%\n",
      "Epoch [17/1000], Step [100/100], TrainLoss: 2.3011,TestLoss: 2.2997\n",
      "Epoch [17/1000], TrainAccuracy : 11.367924528301886 %, TestAccuracy : 11.35%\n",
      "Epoch [18/1000], Step [100/100], TrainLoss: 2.2999,TestLoss: 2.2975\n",
      "Epoch [18/1000], TrainAccuracy : 11.320754716981131 %, TestAccuracy : 11.35%\n",
      "Epoch [19/1000], Step [100/100], TrainLoss: 2.3039,TestLoss: 2.2983\n",
      "Epoch [19/1000], TrainAccuracy : 11.235849056603774 %, TestAccuracy : 11.35%\n",
      "Epoch [20/1000], Step [100/100], TrainLoss: 2.3044,TestLoss: 2.2983\n",
      "Epoch [20/1000], TrainAccuracy : 11.273584905660377 %, TestAccuracy : 11.35%\n",
      "Epoch [21/1000], Step [100/100], TrainLoss: 2.3016,TestLoss: 2.2986\n",
      "Epoch [21/1000], TrainAccuracy : 11.40566037735849 %, TestAccuracy : 11.35%\n",
      "Epoch [22/1000], Step [100/100], TrainLoss: 2.2997,TestLoss: 2.2968\n",
      "Epoch [22/1000], TrainAccuracy : 11.349056603773585 %, TestAccuracy : 11.35%\n",
      "Epoch [23/1000], Step [100/100], TrainLoss: 2.3032,TestLoss: 2.2994\n",
      "Epoch [23/1000], TrainAccuracy : 11.367924528301886 %, TestAccuracy : 11.35%\n",
      "Epoch [24/1000], Step [100/100], TrainLoss: 2.2968,TestLoss: 2.2980\n",
      "Epoch [24/1000], TrainAccuracy : 11.433962264150944 %, TestAccuracy : 11.35%\n",
      "Epoch [25/1000], Step [100/100], TrainLoss: 2.3010,TestLoss: 2.2988\n",
      "Epoch [25/1000], TrainAccuracy : 11.38679245283019 %, TestAccuracy : 11.35%\n",
      "Epoch [26/1000], Step [100/100], TrainLoss: 2.3014,TestLoss: 2.2996\n",
      "Epoch [26/1000], TrainAccuracy : 11.433962264150944 %, TestAccuracy : 11.35%\n",
      "Epoch [27/1000], Step [100/100], TrainLoss: 2.2991,TestLoss: 2.2990\n",
      "Epoch [27/1000], TrainAccuracy : 11.5 %, TestAccuracy : 11.35%\n",
      "Epoch [28/1000], Step [100/100], TrainLoss: 2.3037,TestLoss: 2.2981\n",
      "Epoch [28/1000], TrainAccuracy : 11.330188679245284 %, TestAccuracy : 11.35%\n",
      "Epoch [29/1000], Step [100/100], TrainLoss: 2.2994,TestLoss: 2.2985\n",
      "Epoch [29/1000], TrainAccuracy : 11.377358490566039 %, TestAccuracy : 11.35%\n",
      "Epoch [30/1000], Step [100/100], TrainLoss: 2.3019,TestLoss: 2.2974\n",
      "Epoch [30/1000], TrainAccuracy : 11.216981132075471 %, TestAccuracy : 11.35%\n",
      "Epoch [31/1000], Step [100/100], TrainLoss: 2.3019,TestLoss: 2.2994\n",
      "Epoch [31/1000], TrainAccuracy : 11.30188679245283 %, TestAccuracy : 11.35%\n",
      "Epoch [32/1000], Step [100/100], TrainLoss: 2.3015,TestLoss: 2.2981\n",
      "Epoch [32/1000], TrainAccuracy : 11.283018867924529 %, TestAccuracy : 11.35%\n",
      "Epoch [33/1000], Step [100/100], TrainLoss: 2.3009,TestLoss: 2.2974\n",
      "Epoch [33/1000], TrainAccuracy : 11.462264150943396 %, TestAccuracy : 11.35%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30528/3590259851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnetTest_acc1Arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmnist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30528/3596132080.py\u001b[0m in \u001b[0;36mtestFunc\u001b[1;34m(model, num_epochs)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mn_class_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mn_class_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\CPSC-8430-DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch,train_losses,train_acc,test_losses,netTest_acc1Arr = testFunc(rmnist,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79b98761-1265-4a21-aab4-80ed56d8ca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plt.plot(train_epoch,train_losses,color=\"blue\")\n",
    "plt.title('CNN Loss VS Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6d1fb57-ceac-44ed-bf8c-6b897a911cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plt.plot(train_epoch,train_acc,color=\"red\")\n",
    "plt.title('CNN Accuracy VS Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176bdbc3-0e7e-4ac4-be00-dc6c294a3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 11.35 %\n",
      "Accuracy of 0: 0.0 %\n",
      "Accuracy of 1: 100.0 %\n",
      "Accuracy of 2: 0.0 %\n",
      "Accuracy of 3: 0.0 %\n",
      "Accuracy of 4: 0.0 %\n",
      "Accuracy of 5: 0.0 %\n",
      "Accuracy of 6: 0.0 %\n",
      "Accuracy of 7: 0.0 %\n",
      "Accuracy of 8: 0.0 %\n",
      "Accuracy of 9: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for test_images, test_labels in test_loader:\n",
    "        outputs = rmnist(test_images.view(-1,784))\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += test_labels.size(0)\n",
    "        n_correct += (predicted == test_labels).sum().item()\n",
    "        \n",
    "        for i in range(100):\n",
    "            label = test_labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {netTest_acc1} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {i}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0e9af7-9e56-43dd-93f5-dc5117563836",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21600/1161770327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# max returns (value ,index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        prediction = cnn1(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(prediction.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {netTest_acc1} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf257baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6934e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmnist2(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 10))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d040048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = rmnist2(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        N_TRAIN_EXAMPLES = 600*90\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * 600 >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            #target randomizer\n",
    "            target_rand = target.detach().numpy()\n",
    "            np.random.shuffle(target_rand)\n",
    "            target_rand = torch.from_numpy(target_rand)\n",
    "\n",
    "            #Forward Pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            #loss = F.nll_loss(output, target)\n",
    "            loss = F.nll_loss(output, target_rand)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Get the index of the max log-probability.\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        # # Validation of the model.\n",
    "        # model.eval()\n",
    "        # correct = 0\n",
    "        # with torch.no_grad():\n",
    "        #     for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        #         # Limiting validation data.\n",
    "        #         if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "        #             break\n",
    "        #         data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "        #         output = model(data)\n",
    "        #         # Get the index of the max log-probability.\n",
    "        #         pred = output.argmax(dim=1, keepdim=True)\n",
    "        #         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TRAIN_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2d3ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 15:48:33,658]\u001b[0m A new study created in memory with name: no-name-6e38e5ac-11bf-405c-b77e-dc7a3965f57f\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:49:58,809]\u001b[0m Trial 0 finished with value: 0.5737 and parameters: {'n_layers': 2, 'n_units_l0': 80, 'dropout_l0': 0.3147000482390166, 'n_units_l1': 83, 'dropout_l1': 0.3755580390141433, 'optimizer': 'RMSprop', 'lr': 1.5571614629193746e-05}. Best is trial 0 with value: 0.5737.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:51:22,560]\u001b[0m Trial 1 finished with value: 0.5813 and parameters: {'n_layers': 2, 'n_units_l0': 81, 'dropout_l0': 0.47559396076741306, 'n_units_l1': 54, 'dropout_l1': 0.24763114371031042, 'optimizer': 'RMSprop', 'lr': 0.08011318942978086}. Best is trial 1 with value: 0.5813.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:52:48,902]\u001b[0m Trial 2 finished with value: 0.5858 and parameters: {'n_layers': 1, 'n_units_l0': 78, 'dropout_l0': 0.2256706585427175, 'optimizer': 'RMSprop', 'lr': 6.993744344468027e-05}. Best is trial 2 with value: 0.5858.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:54:23,002]\u001b[0m Trial 3 finished with value: 0.6062 and parameters: {'n_layers': 2, 'n_units_l0': 119, 'dropout_l0': 0.37593694029285274, 'n_units_l1': 22, 'dropout_l1': 0.4837147507853665, 'optimizer': 'RMSprop', 'lr': 0.01110369406935113}. Best is trial 3 with value: 0.6062.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:55:50,644]\u001b[0m Trial 4 finished with value: 0.6037 and parameters: {'n_layers': 3, 'n_units_l0': 62, 'dropout_l0': 0.42725002310316396, 'n_units_l1': 6, 'dropout_l1': 0.2356999625572307, 'n_units_l2': 46, 'dropout_l2': 0.43383963974639195, 'optimizer': 'RMSprop', 'lr': 0.011602815703484495}. Best is trial 3 with value: 0.6062.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:55:56,556]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:56:02,429]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:56:08,154]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:56:14,081]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:56:19,789]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:56:26,085]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:57:54,687]\u001b[0m Trial 11 finished with value: 0.6047 and parameters: {'n_layers': 3, 'n_units_l0': 104, 'dropout_l0': 0.4156969013607894, 'n_units_l1': 6, 'dropout_l1': 0.4935680044375971, 'n_units_l2': 4, 'dropout_l2': 0.4532677546699614, 'optimizer': 'RMSprop', 'lr': 0.011305041480782737}. Best is trial 3 with value: 0.6062.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 15:59:33,967]\u001b[0m Trial 12 finished with value: 0.5982 and parameters: {'n_layers': 3, 'n_units_l0': 105, 'dropout_l0': 0.37857148217634434, 'n_units_l1': 31, 'dropout_l1': 0.4811217388864311, 'n_units_l2': 10, 'dropout_l2': 0.33426008540314156, 'optimizer': 'RMSprop', 'lr': 0.016364236551611303}. Best is trial 3 with value: 0.6062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  13\n",
      "  Number of pruned trials:  6\n",
      "  Number of complete trials:  7\n",
      "Best trial:\n",
      "  Value:  0.6062\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 119\n",
      "    dropout_l0: 0.37593694029285274\n",
      "    n_units_l1: 22\n",
      "    dropout_l1: 0.4837147507853665\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.01110369406935113\n"
     ]
    }
   ],
   "source": [
    "best_pram = []\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "best_pram.append(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e629f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c8d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandMnist3 (nn.Module):\n",
    "    def __init__(self,) :\n",
    "        super(RandMnist3,self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 45) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout1 = nn.Dropout(0.24608164624582957)\n",
    "        self.fc2 = nn.Linear(45, 13)\n",
    "        self.dropout2 = nn.Dropout(0.37326854044559243)\n",
    "        self.fc3 = nn.Linear(13, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN \n",
    "        x = self.dropout1(x)  \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)               #O/P Layer                   \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14cfc3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 1: 36063\n"
     ]
    }
   ],
   "source": [
    "rmnist3 = RandMnist3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rmnist3.parameters(), lr=0.005325277529448175)\n",
    "\n",
    "a=[]\n",
    "for i in rmnist3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print('Total no of parameters in Model 1:', np.sum(a),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b514e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [1/1500], Accuracy : 10.636666666666667 %\n",
      "Epoch [2/1500], Step [100/100], Loss: 2.3054\n",
      "Epoch [2/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [3/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [3/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [4/1500], Step [100/100], Loss: 2.3038\n",
      "Epoch [4/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [5/1500], Step [100/100], Loss: 2.3043\n",
      "Epoch [5/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [6/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [6/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [7/1500], Step [100/100], Loss: 2.3000\n",
      "Epoch [7/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [8/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [8/1500], Accuracy : 11.24 %\n",
      "Epoch [9/1500], Step [100/100], Loss: 2.2985\n",
      "Epoch [9/1500], Accuracy : 11.24 %\n",
      "Epoch [10/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [10/1500], Accuracy : 11.126666666666667 %\n",
      "Epoch [11/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [11/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [12/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [12/1500], Accuracy : 11.238333333333333 %\n",
      "Epoch [13/1500], Step [100/100], Loss: 2.3046\n",
      "Epoch [13/1500], Accuracy : 11.231666666666667 %\n",
      "Epoch [14/1500], Step [100/100], Loss: 2.2979\n",
      "Epoch [14/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [15/1500], Step [100/100], Loss: 2.3002\n",
      "Epoch [15/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [16/1500], Step [100/100], Loss: 2.3031\n",
      "Epoch [16/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [17/1500], Step [100/100], Loss: 2.3018\n",
      "Epoch [17/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [18/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [18/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [19/1500], Step [100/100], Loss: 2.2988\n",
      "Epoch [19/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [20/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [20/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [21/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [21/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [22/1500], Step [100/100], Loss: 2.2995\n",
      "Epoch [22/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [23/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [23/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [24/1500], Step [100/100], Loss: 2.3035\n",
      "Epoch [24/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [25/1500], Step [100/100], Loss: 2.3018\n",
      "Epoch [25/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [26/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [26/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [27/1500], Step [100/100], Loss: 2.3019\n",
      "Epoch [27/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [28/1500], Step [100/100], Loss: 2.2993\n",
      "Epoch [28/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [29/1500], Step [100/100], Loss: 2.3022\n",
      "Epoch [29/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [30/1500], Step [100/100], Loss: 2.3070\n",
      "Epoch [30/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [31/1500], Step [100/100], Loss: 2.3008\n",
      "Epoch [31/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [32/1500], Step [100/100], Loss: 2.3071\n",
      "Epoch [32/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [33/1500], Step [100/100], Loss: 2.3001\n",
      "Epoch [33/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [34/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [34/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [35/1500], Step [100/100], Loss: 2.2994\n",
      "Epoch [35/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [36/1500], Step [100/100], Loss: 2.3052\n",
      "Epoch [36/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [37/1500], Step [100/100], Loss: 2.3060\n",
      "Epoch [37/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [38/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [38/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [39/1500], Step [100/100], Loss: 2.2994\n",
      "Epoch [39/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [40/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [40/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [41/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [41/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [42/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [42/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [43/1500], Step [100/100], Loss: 2.3044\n",
      "Epoch [43/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [44/1500], Step [100/100], Loss: 2.2969\n",
      "Epoch [44/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [45/1500], Step [100/100], Loss: 2.3000\n",
      "Epoch [45/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [46/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [46/1500], Accuracy : 11.241666666666667 %\n",
      "Epoch [47/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [47/1500], Accuracy : 11.238333333333333 %\n",
      "Epoch [48/1500], Step [100/100], Loss: 2.3052\n",
      "Epoch [48/1500], Accuracy : 11.235 %\n",
      "Epoch [49/1500], Step [100/100], Loss: 2.3048\n",
      "Epoch [49/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [50/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [50/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [51/1500], Step [100/100], Loss: 2.3031\n",
      "Epoch [51/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [52/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [52/1500], Accuracy : 11.238333333333333 %\n",
      "Epoch [53/1500], Step [100/100], Loss: 2.3002\n",
      "Epoch [53/1500], Accuracy : 11.218333333333334 %\n",
      "Epoch [54/1500], Step [100/100], Loss: 2.2994\n",
      "Epoch [54/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [55/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [55/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [56/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [56/1500], Accuracy : 11.235 %\n",
      "Epoch [57/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [57/1500], Accuracy : 11.225 %\n",
      "Epoch [58/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [58/1500], Accuracy : 11.25 %\n",
      "Epoch [59/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [59/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [60/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [60/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [61/1500], Step [100/100], Loss: 2.3002\n",
      "Epoch [61/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [62/1500], Step [100/100], Loss: 2.3025\n",
      "Epoch [62/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [63/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [63/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [64/1500], Step [100/100], Loss: 2.3038\n",
      "Epoch [64/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [65/1500], Step [100/100], Loss: 2.2993\n",
      "Epoch [65/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [66/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [66/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [67/1500], Step [100/100], Loss: 2.2985\n",
      "Epoch [67/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [68/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [68/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [69/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [69/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [70/1500], Step [100/100], Loss: 2.2974\n",
      "Epoch [70/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [71/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [71/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [72/1500], Step [100/100], Loss: 2.2991\n",
      "Epoch [72/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [73/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [73/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [74/1500], Step [100/100], Loss: 2.3051\n",
      "Epoch [74/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [75/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [75/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [76/1500], Step [100/100], Loss: 2.2990\n",
      "Epoch [76/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [77/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [77/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [78/1500], Step [100/100], Loss: 2.3036\n",
      "Epoch [78/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [79/1500], Step [100/100], Loss: 2.2973\n",
      "Epoch [79/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [80/1500], Step [100/100], Loss: 2.2997\n",
      "Epoch [80/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [81/1500], Step [100/100], Loss: 2.3005\n",
      "Epoch [81/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [82/1500], Step [100/100], Loss: 2.2964\n",
      "Epoch [82/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [83/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [83/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [84/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [84/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [85/1500], Step [100/100], Loss: 2.2981\n",
      "Epoch [85/1500], Accuracy : 11.235 %\n",
      "Epoch [86/1500], Step [100/100], Loss: 2.3047\n",
      "Epoch [86/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [87/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [87/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [88/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [88/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [89/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [89/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [90/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [90/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [91/1500], Step [100/100], Loss: 2.2995\n",
      "Epoch [91/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [92/1500], Step [100/100], Loss: 2.3008\n",
      "Epoch [92/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [93/1500], Step [100/100], Loss: 2.3052\n",
      "Epoch [93/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [94/1500], Step [100/100], Loss: 2.3063\n",
      "Epoch [94/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [95/1500], Step [100/100], Loss: 2.3034\n",
      "Epoch [95/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [96/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [96/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [97/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [97/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [98/1500], Step [100/100], Loss: 2.3085\n",
      "Epoch [98/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [99/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [99/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [100/1500], Step [100/100], Loss: 2.2999\n",
      "Epoch [100/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [101/1500], Step [100/100], Loss: 2.3020\n",
      "Epoch [101/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [102/1500], Step [100/100], Loss: 2.2991\n",
      "Epoch [102/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [103/1500], Step [100/100], Loss: 2.2977\n",
      "Epoch [103/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [104/1500], Step [100/100], Loss: 2.2994\n",
      "Epoch [104/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [105/1500], Step [100/100], Loss: 2.3022\n",
      "Epoch [105/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [106/1500], Step [100/100], Loss: 2.2995\n",
      "Epoch [106/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [107/1500], Step [100/100], Loss: 2.3039\n",
      "Epoch [107/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [108/1500], Step [100/100], Loss: 2.2991\n",
      "Epoch [108/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [109/1500], Step [100/100], Loss: 2.2979\n",
      "Epoch [109/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [110/1500], Step [100/100], Loss: 2.3016\n",
      "Epoch [110/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [111/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [111/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [112/1500], Step [100/100], Loss: 2.3037\n",
      "Epoch [112/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [113/1500], Step [100/100], Loss: 2.3007\n",
      "Epoch [113/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [114/1500], Step [100/100], Loss: 2.2985\n",
      "Epoch [114/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [115/1500], Step [100/100], Loss: 2.3005\n",
      "Epoch [115/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [116/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [116/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [117/1500], Step [100/100], Loss: 2.2999\n",
      "Epoch [117/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [118/1500], Step [100/100], Loss: 2.2993\n",
      "Epoch [118/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [119/1500], Step [100/100], Loss: 2.3048\n",
      "Epoch [119/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [120/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [120/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [121/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [121/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [122/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [122/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [123/1500], Step [100/100], Loss: 2.2993\n",
      "Epoch [123/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [124/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [124/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [125/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [125/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [126/1500], Step [100/100], Loss: 2.3007\n",
      "Epoch [126/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [127/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [127/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [128/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [128/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [129/1500], Step [100/100], Loss: 2.2986\n",
      "Epoch [129/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [130/1500], Step [100/100], Loss: 2.3018\n",
      "Epoch [130/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [131/1500], Step [100/100], Loss: 2.2989\n",
      "Epoch [131/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [132/1500], Step [100/100], Loss: 2.2959\n",
      "Epoch [132/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [133/1500], Step [100/100], Loss: 2.3039\n",
      "Epoch [133/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [134/1500], Step [100/100], Loss: 2.3040\n",
      "Epoch [134/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [135/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [135/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [136/1500], Step [100/100], Loss: 2.3049\n",
      "Epoch [136/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [137/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [137/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [138/1500], Step [100/100], Loss: 2.3034\n",
      "Epoch [138/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [139/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [139/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [140/1500], Step [100/100], Loss: 2.3041\n",
      "Epoch [140/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [141/1500], Step [100/100], Loss: 2.3032\n",
      "Epoch [141/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [142/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [142/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [143/1500], Step [100/100], Loss: 2.3042\n",
      "Epoch [143/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [144/1500], Step [100/100], Loss: 2.2983\n",
      "Epoch [144/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [145/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [145/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [146/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [146/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [147/1500], Step [100/100], Loss: 2.3037\n",
      "Epoch [147/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [148/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [148/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [149/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [149/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [150/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [150/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [151/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [151/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [152/1500], Step [100/100], Loss: 2.2993\n",
      "Epoch [152/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [153/1500], Step [100/100], Loss: 2.3008\n",
      "Epoch [153/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [154/1500], Step [100/100], Loss: 2.2988\n",
      "Epoch [154/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [155/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [155/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [156/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [156/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [157/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [157/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [158/1500], Step [100/100], Loss: 2.3015\n",
      "Epoch [158/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [159/1500], Step [100/100], Loss: 2.2976\n",
      "Epoch [159/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [160/1500], Step [100/100], Loss: 2.2988\n",
      "Epoch [160/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [161/1500], Step [100/100], Loss: 2.3039\n",
      "Epoch [161/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [162/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [162/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [163/1500], Step [100/100], Loss: 2.3046\n",
      "Epoch [163/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [164/1500], Step [100/100], Loss: 2.2983\n",
      "Epoch [164/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [165/1500], Step [100/100], Loss: 2.3022\n",
      "Epoch [165/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [166/1500], Step [100/100], Loss: 2.3016\n",
      "Epoch [166/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [167/1500], Step [100/100], Loss: 2.3035\n",
      "Epoch [167/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [168/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [168/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [169/1500], Step [100/100], Loss: 2.3031\n",
      "Epoch [169/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [170/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [170/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [171/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [171/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [172/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [172/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [173/1500], Step [100/100], Loss: 2.3037\n",
      "Epoch [173/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [174/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [174/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [175/1500], Step [100/100], Loss: 2.3044\n",
      "Epoch [175/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [176/1500], Step [100/100], Loss: 2.2999\n",
      "Epoch [176/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [177/1500], Step [100/100], Loss: 2.3048\n",
      "Epoch [177/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [178/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [178/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [179/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [179/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [180/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [180/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [181/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [181/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [182/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [182/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [183/1500], Step [100/100], Loss: 2.2985\n",
      "Epoch [183/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [184/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [184/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [185/1500], Step [100/100], Loss: 2.3019\n",
      "Epoch [185/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [186/1500], Step [100/100], Loss: 2.2974\n",
      "Epoch [186/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [187/1500], Step [100/100], Loss: 2.3061\n",
      "Epoch [187/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [188/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [188/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [189/1500], Step [100/100], Loss: 2.3001\n",
      "Epoch [189/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [190/1500], Step [100/100], Loss: 2.2984\n",
      "Epoch [190/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [191/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [191/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [192/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [192/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [193/1500], Step [100/100], Loss: 2.3015\n",
      "Epoch [193/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [194/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [194/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [195/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [195/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [196/1500], Step [100/100], Loss: 2.3040\n",
      "Epoch [196/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [197/1500], Step [100/100], Loss: 2.3008\n",
      "Epoch [197/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [198/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [198/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [199/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [199/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [200/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [200/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [201/1500], Step [100/100], Loss: 2.2997\n",
      "Epoch [201/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [202/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [202/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [203/1500], Step [100/100], Loss: 2.3016\n",
      "Epoch [203/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [204/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [204/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [205/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [205/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [206/1500], Step [100/100], Loss: 2.3015\n",
      "Epoch [206/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [207/1500], Step [100/100], Loss: 2.2984\n",
      "Epoch [207/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [208/1500], Step [100/100], Loss: 2.3033\n",
      "Epoch [208/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [209/1500], Step [100/100], Loss: 2.3019\n",
      "Epoch [209/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [210/1500], Step [100/100], Loss: 2.3046\n",
      "Epoch [210/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [211/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [211/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [212/1500], Step [100/100], Loss: 2.3018\n",
      "Epoch [212/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [213/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [213/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [214/1500], Step [100/100], Loss: 2.2974\n",
      "Epoch [214/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [215/1500], Step [100/100], Loss: 2.3025\n",
      "Epoch [215/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [216/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [216/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [217/1500], Step [100/100], Loss: 2.2989\n",
      "Epoch [217/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [218/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [218/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [219/1500], Step [100/100], Loss: 2.2999\n",
      "Epoch [219/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [220/1500], Step [100/100], Loss: 2.3034\n",
      "Epoch [220/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [221/1500], Step [100/100], Loss: 2.2974\n",
      "Epoch [221/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [222/1500], Step [100/100], Loss: 2.2976\n",
      "Epoch [222/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [223/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [223/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [224/1500], Step [100/100], Loss: 2.3025\n",
      "Epoch [224/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [225/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [225/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [226/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [226/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [227/1500], Step [100/100], Loss: 2.3001\n",
      "Epoch [227/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [228/1500], Step [100/100], Loss: 2.3022\n",
      "Epoch [228/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [229/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [229/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [230/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [230/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [231/1500], Step [100/100], Loss: 2.2973\n",
      "Epoch [231/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [232/1500], Step [100/100], Loss: 2.2985\n",
      "Epoch [232/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [233/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [233/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [234/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [234/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [235/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [235/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [236/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [236/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [237/1500], Step [100/100], Loss: 2.2991\n",
      "Epoch [237/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [238/1500], Step [100/100], Loss: 2.3001\n",
      "Epoch [238/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [239/1500], Step [100/100], Loss: 2.3049\n",
      "Epoch [239/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [240/1500], Step [100/100], Loss: 2.3058\n",
      "Epoch [240/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [241/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [241/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [242/1500], Step [100/100], Loss: 2.2990\n",
      "Epoch [242/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [243/1500], Step [100/100], Loss: 2.3007\n",
      "Epoch [243/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [244/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [244/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [245/1500], Step [100/100], Loss: 2.3007\n",
      "Epoch [245/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [246/1500], Step [100/100], Loss: 2.3020\n",
      "Epoch [246/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [247/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [247/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [248/1500], Step [100/100], Loss: 2.3036\n",
      "Epoch [248/1500], Accuracy : 11.233333333333333 %\n",
      "Epoch [249/1500], Step [100/100], Loss: 2.2993\n",
      "Epoch [249/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [250/1500], Step [100/100], Loss: 2.2997\n",
      "Epoch [250/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [251/1500], Step [100/100], Loss: 2.2959\n",
      "Epoch [251/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [252/1500], Step [100/100], Loss: 2.3035\n",
      "Epoch [252/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [253/1500], Step [100/100], Loss: 2.3040\n",
      "Epoch [253/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [254/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [254/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [255/1500], Step [100/100], Loss: 2.3041\n",
      "Epoch [255/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [256/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [256/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [257/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [257/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [258/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [258/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [259/1500], Step [100/100], Loss: 2.3035\n",
      "Epoch [259/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [260/1500], Step [100/100], Loss: 2.3031\n",
      "Epoch [260/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [261/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [261/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [262/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [262/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [263/1500], Step [100/100], Loss: 2.3031\n",
      "Epoch [263/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [264/1500], Step [100/100], Loss: 2.3086\n",
      "Epoch [264/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [265/1500], Step [100/100], Loss: 2.3008\n",
      "Epoch [265/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [266/1500], Step [100/100], Loss: 2.3062\n",
      "Epoch [266/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [267/1500], Step [100/100], Loss: 2.3046\n",
      "Epoch [267/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [268/1500], Step [100/100], Loss: 2.2978\n",
      "Epoch [268/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [269/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [269/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [270/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [270/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [271/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [271/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [272/1500], Step [100/100], Loss: 2.3034\n",
      "Epoch [272/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [273/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [273/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [274/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [274/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [275/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [275/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [276/1500], Step [100/100], Loss: 2.3064\n",
      "Epoch [276/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [277/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [277/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [278/1500], Step [100/100], Loss: 2.3040\n",
      "Epoch [278/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [279/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [279/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [280/1500], Step [100/100], Loss: 2.3041\n",
      "Epoch [280/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [281/1500], Step [100/100], Loss: 2.3041\n",
      "Epoch [281/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [282/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [282/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [283/1500], Step [100/100], Loss: 2.3005\n",
      "Epoch [283/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [284/1500], Step [100/100], Loss: 2.3045\n",
      "Epoch [284/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [285/1500], Step [100/100], Loss: 2.3033\n",
      "Epoch [285/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [286/1500], Step [100/100], Loss: 2.2987\n",
      "Epoch [286/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [287/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [287/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [288/1500], Step [100/100], Loss: 2.2973\n",
      "Epoch [288/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [289/1500], Step [100/100], Loss: 2.3015\n",
      "Epoch [289/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [290/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [290/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [291/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [291/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [292/1500], Step [100/100], Loss: 2.2995\n",
      "Epoch [292/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [293/1500], Step [100/100], Loss: 2.3020\n",
      "Epoch [293/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [294/1500], Step [100/100], Loss: 2.3020\n",
      "Epoch [294/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [295/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [295/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [296/1500], Step [100/100], Loss: 2.2988\n",
      "Epoch [296/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [297/1500], Step [100/100], Loss: 2.2989\n",
      "Epoch [297/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [298/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [298/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [299/1500], Step [100/100], Loss: 2.3040\n",
      "Epoch [299/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [300/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [300/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [301/1500], Step [100/100], Loss: 2.3001\n",
      "Epoch [301/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [302/1500], Step [100/100], Loss: 2.3040\n",
      "Epoch [302/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [303/1500], Step [100/100], Loss: 2.3008\n",
      "Epoch [303/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [304/1500], Step [100/100], Loss: 2.3033\n",
      "Epoch [304/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [305/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [305/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [306/1500], Step [100/100], Loss: 2.3016\n",
      "Epoch [306/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [307/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [307/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [308/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [308/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [309/1500], Step [100/100], Loss: 2.3038\n",
      "Epoch [309/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [310/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [310/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [311/1500], Step [100/100], Loss: 2.3037\n",
      "Epoch [311/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [312/1500], Step [100/100], Loss: 2.3021\n",
      "Epoch [312/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [313/1500], Step [100/100], Loss: 2.2983\n",
      "Epoch [313/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [314/1500], Step [100/100], Loss: 2.3001\n",
      "Epoch [314/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [315/1500], Step [100/100], Loss: 2.3030\n",
      "Epoch [315/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [316/1500], Step [100/100], Loss: 2.3037\n",
      "Epoch [316/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [317/1500], Step [100/100], Loss: 2.2994\n",
      "Epoch [317/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [318/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [318/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [319/1500], Step [100/100], Loss: 2.3004\n",
      "Epoch [319/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [320/1500], Step [100/100], Loss: 2.3016\n",
      "Epoch [320/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [321/1500], Step [100/100], Loss: 2.3035\n",
      "Epoch [321/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [322/1500], Step [100/100], Loss: 2.3019\n",
      "Epoch [322/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [323/1500], Step [100/100], Loss: 2.3036\n",
      "Epoch [323/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [324/1500], Step [100/100], Loss: 2.3028\n",
      "Epoch [324/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [325/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [325/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [326/1500], Step [100/100], Loss: 2.2989\n",
      "Epoch [326/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [327/1500], Step [100/100], Loss: 2.2998\n",
      "Epoch [327/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [328/1500], Step [100/100], Loss: 2.3017\n",
      "Epoch [328/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [329/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [329/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [330/1500], Step [100/100], Loss: 2.3022\n",
      "Epoch [330/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [331/1500], Step [100/100], Loss: 2.3007\n",
      "Epoch [331/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [332/1500], Step [100/100], Loss: 2.3037\n",
      "Epoch [332/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [333/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [333/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [334/1500], Step [100/100], Loss: 2.3034\n",
      "Epoch [334/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [335/1500], Step [100/100], Loss: 2.3046\n",
      "Epoch [335/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [336/1500], Step [100/100], Loss: 2.3032\n",
      "Epoch [336/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [337/1500], Step [100/100], Loss: 2.3063\n",
      "Epoch [337/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [338/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [338/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [339/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [339/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [340/1500], Step [100/100], Loss: 2.2986\n",
      "Epoch [340/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [341/1500], Step [100/100], Loss: 2.2986\n",
      "Epoch [341/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [342/1500], Step [100/100], Loss: 2.3000\n",
      "Epoch [342/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [343/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [343/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [344/1500], Step [100/100], Loss: 2.3025\n",
      "Epoch [344/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [345/1500], Step [100/100], Loss: 2.3027\n",
      "Epoch [345/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [346/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [346/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [347/1500], Step [100/100], Loss: 2.3024\n",
      "Epoch [347/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [348/1500], Step [100/100], Loss: 2.3005\n",
      "Epoch [348/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [349/1500], Step [100/100], Loss: 2.2992\n",
      "Epoch [349/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [350/1500], Step [100/100], Loss: 2.3007\n",
      "Epoch [350/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [351/1500], Step [100/100], Loss: 2.3061\n",
      "Epoch [351/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [352/1500], Step [100/100], Loss: 2.3026\n",
      "Epoch [352/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [353/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [353/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [354/1500], Step [100/100], Loss: 2.3025\n",
      "Epoch [354/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [355/1500], Step [100/100], Loss: 2.2965\n",
      "Epoch [355/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [356/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [356/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [357/1500], Step [100/100], Loss: 2.3035\n",
      "Epoch [357/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [358/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [358/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [359/1500], Step [100/100], Loss: 2.3011\n",
      "Epoch [359/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [360/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [360/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [361/1500], Step [100/100], Loss: 2.3009\n",
      "Epoch [361/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [362/1500], Step [100/100], Loss: 2.2996\n",
      "Epoch [362/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [363/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [363/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [364/1500], Step [100/100], Loss: 2.3005\n",
      "Epoch [364/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [365/1500], Step [100/100], Loss: 2.3020\n",
      "Epoch [365/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [366/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [366/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [367/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [367/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [368/1500], Step [100/100], Loss: 2.2997\n",
      "Epoch [368/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [369/1500], Step [100/100], Loss: 2.3014\n",
      "Epoch [369/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [370/1500], Step [100/100], Loss: 2.3041\n",
      "Epoch [370/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [371/1500], Step [100/100], Loss: 2.3019\n",
      "Epoch [371/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [372/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [372/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [373/1500], Step [100/100], Loss: 2.3053\n",
      "Epoch [373/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [374/1500], Step [100/100], Loss: 2.3006\n",
      "Epoch [374/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [375/1500], Step [100/100], Loss: 2.3029\n",
      "Epoch [375/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [376/1500], Step [100/100], Loss: 2.2994\n",
      "Epoch [376/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [377/1500], Step [100/100], Loss: 2.3018\n",
      "Epoch [377/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [378/1500], Step [100/100], Loss: 2.3010\n",
      "Epoch [378/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [379/1500], Step [100/100], Loss: 2.3003\n",
      "Epoch [379/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [380/1500], Step [100/100], Loss: 2.3042\n",
      "Epoch [380/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [381/1500], Step [100/100], Loss: 2.3012\n",
      "Epoch [381/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [382/1500], Step [100/100], Loss: 2.3039\n",
      "Epoch [382/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [383/1500], Step [100/100], Loss: 2.2985\n",
      "Epoch [383/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [384/1500], Step [100/100], Loss: 2.3032\n",
      "Epoch [384/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [385/1500], Step [100/100], Loss: 2.3046\n",
      "Epoch [385/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [386/1500], Step [100/100], Loss: 2.3015\n",
      "Epoch [386/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [387/1500], Step [100/100], Loss: 2.3023\n",
      "Epoch [387/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [388/1500], Step [100/100], Loss: 2.2977\n",
      "Epoch [388/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [389/1500], Step [100/100], Loss: 2.3013\n",
      "Epoch [389/1500], Accuracy : 11.236666666666666 %\n",
      "Epoch [390/1500], Step [100/100], Loss: 2.3025\n",
      "Epoch [390/1500], Accuracy : 11.236666666666666 %\n"
     ]
    }
   ],
   "source": [
    "train_epoch,train_losses,train_acc,test_losses,netTest_acc1Arr=testFunc(rmnist3,1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc736055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plt.plot(train_epoch,train_losses,color=\"blue\")\n",
    "plt.title('CNN Loss VS Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce41f6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plt.plot(train_epoch,train_acc,color=\"red\")\n",
    "plt.title('CNN Accuracy VS Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2393ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
