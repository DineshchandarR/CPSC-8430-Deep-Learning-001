{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1edb4e628b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader func\n",
    "def train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def test_loader(batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs,train_batch_size):\n",
    "    model.train()\n",
    "    print('strated')\n",
    "    train_load = train_loader(train_batch_size)\n",
    "    n_total_steps = len(train_load)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    not_converged =True\n",
    "    epoch = 0\n",
    "    while not_converged:\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_load):  \n",
    "            #if (i+1)% 60 == 0 : print(i+1)\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "\n",
    "            images.requires_grad = True\n",
    "\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # Backward and optimize\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            #Calculation for sensitivity\n",
    "            froGrad=0\n",
    "            count =0 \n",
    "            sensitivity=[]\n",
    "        \n",
    "            for p in model.parameters():\n",
    "                grad = 0.0\n",
    "                if p.grad is not None:\n",
    "                    grad = p.grad\n",
    "                    froGrad_norm = torch.linalg.norm(grad).numpy()\n",
    "                    froGrad += froGrad_norm\n",
    "                    count += 1\n",
    "            \n",
    "            sensitivity.append(froGrad/count)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            train_epoch.append(epoch)\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print (f'Train O/P: Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                # train_epoch.append(epoch)\n",
    "                # print(f'Epoch [{epoch}/{num_epochs}], Accuracy : {acc} %')\n",
    "                # train_acc.append(acc)\n",
    "                if epoch == num_epochs:\n",
    "                        print(\"Max Epoch Reached\")\n",
    "                        not_converged = False\n",
    "                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n",
    "                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n",
    "                        print(\"Convergeance reached for loss:\",train_losses[-1])\n",
    "                        not_converged = False\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc,sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10.  385.  760. 1135. 1510.]\n"
     ]
    }
   ],
   "source": [
    "batchArr = np.linspace (10,1510,5)\n",
    "print(batchArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFunction(model,loss_func,test_batch_size): \n",
    "    test_load = test_loader(test_batch_size)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        for images, labels in test_load:\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            prediction = model(images)\n",
    "            testLoss += loss_func(prediction,labels).item()\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "    netTest_loss = testLoss/n_samples\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {netTest_acc1}% & Test Loss: {netTest_loss} ')\n",
    "    return netTest_acc1, netTest_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculation for sensitivity\n",
    "# def sensitivityFunc(model):\n",
    "    \n",
    "#     froGrad=0\n",
    "#     count =0 \n",
    "#     sensitivity=[]\n",
    "  \n",
    "#     for p in model.parameters():\n",
    "#         grad = 0.0\n",
    "#         if p.grad is not None:\n",
    "#             grad = p.grad\n",
    "#             froGrad_norm = torch.linalg.norm(grad).numpy()\n",
    "#             froGrad += froGrad_norm\n",
    "#             count += 1\n",
    "       \n",
    "#     sensitivity.append(froGrad/count)\n",
    "#     return sensitivity\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model :34622 for with batch size:10\n",
      "strated\n",
      "Train O/P: Epoch [1/5], Step [10/6000], Loss: 2.2707\n",
      "Train O/P: Epoch [1/5], Step [20/6000], Loss: 2.1197\n",
      "Train O/P: Epoch [1/5], Step [30/6000], Loss: 2.0829\n",
      "Train O/P: Epoch [1/5], Step [40/6000], Loss: 1.7786\n",
      "Train O/P: Epoch [1/5], Step [50/6000], Loss: 1.2271\n",
      "Train O/P: Epoch [1/5], Step [60/6000], Loss: 0.7959\n",
      "Train O/P: Epoch [1/5], Step [70/6000], Loss: 1.2936\n",
      "Train O/P: Epoch [1/5], Step [80/6000], Loss: 0.6630\n",
      "Train O/P: Epoch [1/5], Step [90/6000], Loss: 0.6249\n",
      "Train O/P: Epoch [1/5], Step [100/6000], Loss: 0.6995\n",
      "Train O/P: Epoch [1/5], Step [110/6000], Loss: 0.5026\n",
      "Train O/P: Epoch [1/5], Step [120/6000], Loss: 0.7957\n",
      "Train O/P: Epoch [1/5], Step [130/6000], Loss: 0.5473\n",
      "Train O/P: Epoch [1/5], Step [140/6000], Loss: 0.2363\n",
      "Train O/P: Epoch [1/5], Step [150/6000], Loss: 0.4075\n",
      "Train O/P: Epoch [1/5], Step [160/6000], Loss: 0.1297\n",
      "Train O/P: Epoch [1/5], Step [170/6000], Loss: 0.3531\n",
      "Train O/P: Epoch [1/5], Step [180/6000], Loss: 0.2578\n",
      "Train O/P: Epoch [1/5], Step [190/6000], Loss: 1.0563\n",
      "Train O/P: Epoch [1/5], Step [200/6000], Loss: 0.4788\n",
      "Train O/P: Epoch [1/5], Step [210/6000], Loss: 0.6286\n",
      "Train O/P: Epoch [1/5], Step [220/6000], Loss: 0.5967\n",
      "Train O/P: Epoch [1/5], Step [230/6000], Loss: 0.4373\n",
      "Train O/P: Epoch [1/5], Step [240/6000], Loss: 0.4677\n",
      "Train O/P: Epoch [1/5], Step [250/6000], Loss: 0.1945\n",
      "Train O/P: Epoch [1/5], Step [260/6000], Loss: 0.1093\n",
      "Train O/P: Epoch [1/5], Step [270/6000], Loss: 0.1277\n",
      "Train O/P: Epoch [1/5], Step [280/6000], Loss: 0.7869\n",
      "Train O/P: Epoch [1/5], Step [290/6000], Loss: 0.2721\n",
      "Train O/P: Epoch [1/5], Step [300/6000], Loss: 0.2592\n",
      "Train O/P: Epoch [1/5], Step [310/6000], Loss: 0.3861\n",
      "Train O/P: Epoch [1/5], Step [320/6000], Loss: 0.3333\n",
      "Train O/P: Epoch [1/5], Step [330/6000], Loss: 0.5718\n",
      "Train O/P: Epoch [1/5], Step [340/6000], Loss: 0.3153\n",
      "Train O/P: Epoch [1/5], Step [350/6000], Loss: 0.2213\n",
      "Train O/P: Epoch [1/5], Step [360/6000], Loss: 0.0819\n",
      "Train O/P: Epoch [1/5], Step [370/6000], Loss: 0.7400\n",
      "Train O/P: Epoch [1/5], Step [380/6000], Loss: 0.2710\n",
      "Train O/P: Epoch [1/5], Step [390/6000], Loss: 0.2622\n",
      "Train O/P: Epoch [1/5], Step [400/6000], Loss: 0.1889\n",
      "Train O/P: Epoch [1/5], Step [410/6000], Loss: 0.1732\n",
      "Train O/P: Epoch [1/5], Step [420/6000], Loss: 0.1243\n",
      "Train O/P: Epoch [1/5], Step [430/6000], Loss: 0.2753\n",
      "Train O/P: Epoch [1/5], Step [440/6000], Loss: 0.1136\n",
      "Train O/P: Epoch [1/5], Step [450/6000], Loss: 0.1184\n",
      "Train O/P: Epoch [1/5], Step [460/6000], Loss: 0.1067\n",
      "Train O/P: Epoch [1/5], Step [470/6000], Loss: 0.0580\n",
      "Train O/P: Epoch [1/5], Step [480/6000], Loss: 0.1480\n",
      "Train O/P: Epoch [1/5], Step [490/6000], Loss: 0.1143\n",
      "Train O/P: Epoch [1/5], Step [500/6000], Loss: 0.0320\n",
      "Train O/P: Epoch [1/5], Step [510/6000], Loss: 0.1173\n",
      "Train O/P: Epoch [1/5], Step [520/6000], Loss: 0.0234\n",
      "Train O/P: Epoch [1/5], Step [530/6000], Loss: 0.0800\n",
      "Train O/P: Epoch [1/5], Step [540/6000], Loss: 0.1265\n",
      "Train O/P: Epoch [1/5], Step [550/6000], Loss: 0.3627\n",
      "Train O/P: Epoch [1/5], Step [560/6000], Loss: 0.0453\n",
      "Train O/P: Epoch [1/5], Step [570/6000], Loss: 0.1543\n",
      "Train O/P: Epoch [1/5], Step [580/6000], Loss: 0.2764\n",
      "Train O/P: Epoch [1/5], Step [590/6000], Loss: 0.2832\n",
      "Train O/P: Epoch [1/5], Step [600/6000], Loss: 0.0876\n",
      "Train O/P: Epoch [1/5], Step [610/6000], Loss: 0.4304\n",
      "Train O/P: Epoch [1/5], Step [620/6000], Loss: 0.2051\n",
      "Train O/P: Epoch [1/5], Step [630/6000], Loss: 0.2980\n",
      "Train O/P: Epoch [1/5], Step [640/6000], Loss: 0.0163\n",
      "Train O/P: Epoch [1/5], Step [650/6000], Loss: 0.1906\n",
      "Train O/P: Epoch [1/5], Step [660/6000], Loss: 0.1113\n",
      "Train O/P: Epoch [1/5], Step [670/6000], Loss: 0.3349\n",
      "Train O/P: Epoch [1/5], Step [680/6000], Loss: 0.1909\n",
      "Train O/P: Epoch [1/5], Step [690/6000], Loss: 0.3012\n",
      "Train O/P: Epoch [1/5], Step [700/6000], Loss: 0.1105\n",
      "Train O/P: Epoch [1/5], Step [710/6000], Loss: 0.5077\n",
      "Train O/P: Epoch [1/5], Step [720/6000], Loss: 0.0999\n",
      "Train O/P: Epoch [1/5], Step [730/6000], Loss: 0.1055\n",
      "Train O/P: Epoch [1/5], Step [740/6000], Loss: 0.4476\n",
      "Train O/P: Epoch [1/5], Step [750/6000], Loss: 0.3336\n",
      "Train O/P: Epoch [1/5], Step [760/6000], Loss: 0.6384\n",
      "Train O/P: Epoch [1/5], Step [770/6000], Loss: 0.1595\n",
      "Train O/P: Epoch [1/5], Step [780/6000], Loss: 0.1317\n",
      "Train O/P: Epoch [1/5], Step [790/6000], Loss: 0.2243\n",
      "Train O/P: Epoch [1/5], Step [800/6000], Loss: 0.0516\n",
      "Train O/P: Epoch [1/5], Step [810/6000], Loss: 0.0524\n",
      "Train O/P: Epoch [1/5], Step [820/6000], Loss: 0.0280\n",
      "Train O/P: Epoch [1/5], Step [830/6000], Loss: 0.2563\n",
      "Train O/P: Epoch [1/5], Step [840/6000], Loss: 0.7510\n",
      "Train O/P: Epoch [1/5], Step [850/6000], Loss: 0.1108\n",
      "Train O/P: Epoch [1/5], Step [860/6000], Loss: 0.5572\n",
      "Train O/P: Epoch [1/5], Step [870/6000], Loss: 0.2863\n",
      "Train O/P: Epoch [1/5], Step [880/6000], Loss: 0.0945\n",
      "Train O/P: Epoch [1/5], Step [890/6000], Loss: 0.1236\n",
      "Train O/P: Epoch [1/5], Step [900/6000], Loss: 0.1007\n",
      "Train O/P: Epoch [1/5], Step [910/6000], Loss: 0.2099\n",
      "Train O/P: Epoch [1/5], Step [920/6000], Loss: 0.1005\n",
      "Train O/P: Epoch [1/5], Step [930/6000], Loss: 0.0388\n",
      "Train O/P: Epoch [1/5], Step [940/6000], Loss: 0.6219\n",
      "Train O/P: Epoch [1/5], Step [950/6000], Loss: 0.1153\n",
      "Train O/P: Epoch [1/5], Step [960/6000], Loss: 0.2065\n",
      "Train O/P: Epoch [1/5], Step [970/6000], Loss: 0.2696\n",
      "Train O/P: Epoch [1/5], Step [980/6000], Loss: 0.2801\n",
      "Train O/P: Epoch [1/5], Step [990/6000], Loss: 0.9953\n",
      "Train O/P: Epoch [1/5], Step [1000/6000], Loss: 0.0760\n",
      "Train O/P: Epoch [1/5], Step [1010/6000], Loss: 0.3368\n",
      "Train O/P: Epoch [1/5], Step [1020/6000], Loss: 0.0404\n",
      "Train O/P: Epoch [1/5], Step [1030/6000], Loss: 0.2597\n",
      "Train O/P: Epoch [1/5], Step [1040/6000], Loss: 0.0228\n",
      "Train O/P: Epoch [1/5], Step [1050/6000], Loss: 0.1800\n",
      "Train O/P: Epoch [1/5], Step [1060/6000], Loss: 0.2075\n",
      "Train O/P: Epoch [1/5], Step [1070/6000], Loss: 0.2681\n",
      "Train O/P: Epoch [1/5], Step [1080/6000], Loss: 0.2776\n",
      "Train O/P: Epoch [1/5], Step [1090/6000], Loss: 0.1431\n",
      "Train O/P: Epoch [1/5], Step [1100/6000], Loss: 0.0241\n",
      "Train O/P: Epoch [1/5], Step [1110/6000], Loss: 0.0553\n",
      "Train O/P: Epoch [1/5], Step [1120/6000], Loss: 0.0556\n",
      "Train O/P: Epoch [1/5], Step [1130/6000], Loss: 0.8065\n",
      "Train O/P: Epoch [1/5], Step [1140/6000], Loss: 0.1702\n",
      "Train O/P: Epoch [1/5], Step [1150/6000], Loss: 0.0944\n",
      "Train O/P: Epoch [1/5], Step [1160/6000], Loss: 0.2301\n",
      "Train O/P: Epoch [1/5], Step [1170/6000], Loss: 0.1702\n",
      "Train O/P: Epoch [1/5], Step [1180/6000], Loss: 0.0691\n",
      "Train O/P: Epoch [1/5], Step [1190/6000], Loss: 0.0217\n",
      "Train O/P: Epoch [1/5], Step [1200/6000], Loss: 0.0890\n",
      "Train O/P: Epoch [1/5], Step [1210/6000], Loss: 0.0573\n",
      "Train O/P: Epoch [1/5], Step [1220/6000], Loss: 0.5191\n",
      "Train O/P: Epoch [1/5], Step [1230/6000], Loss: 0.0317\n",
      "Train O/P: Epoch [1/5], Step [1240/6000], Loss: 0.0982\n",
      "Train O/P: Epoch [1/5], Step [1250/6000], Loss: 0.2957\n",
      "Train O/P: Epoch [1/5], Step [1260/6000], Loss: 0.3260\n",
      "Train O/P: Epoch [1/5], Step [1270/6000], Loss: 0.4856\n",
      "Train O/P: Epoch [1/5], Step [1280/6000], Loss: 0.0798\n",
      "Train O/P: Epoch [1/5], Step [1290/6000], Loss: 0.0295\n",
      "Train O/P: Epoch [1/5], Step [1300/6000], Loss: 0.1601\n",
      "Train O/P: Epoch [1/5], Step [1310/6000], Loss: 0.1678\n",
      "Train O/P: Epoch [1/5], Step [1320/6000], Loss: 0.0623\n",
      "Train O/P: Epoch [1/5], Step [1330/6000], Loss: 0.1275\n",
      "Train O/P: Epoch [1/5], Step [1340/6000], Loss: 0.0347\n",
      "Train O/P: Epoch [1/5], Step [1350/6000], Loss: 0.0580\n",
      "Train O/P: Epoch [1/5], Step [1360/6000], Loss: 0.2876\n",
      "Train O/P: Epoch [1/5], Step [1370/6000], Loss: 0.1043\n",
      "Train O/P: Epoch [1/5], Step [1380/6000], Loss: 0.0420\n",
      "Train O/P: Epoch [1/5], Step [1390/6000], Loss: 0.1651\n",
      "Train O/P: Epoch [1/5], Step [1400/6000], Loss: 0.2970\n",
      "Train O/P: Epoch [1/5], Step [1410/6000], Loss: 0.1175\n",
      "Train O/P: Epoch [1/5], Step [1420/6000], Loss: 0.4181\n",
      "Train O/P: Epoch [1/5], Step [1430/6000], Loss: 0.0955\n",
      "Train O/P: Epoch [1/5], Step [1440/6000], Loss: 0.3818\n",
      "Train O/P: Epoch [1/5], Step [1450/6000], Loss: 0.2596\n",
      "Train O/P: Epoch [1/5], Step [1460/6000], Loss: 0.1347\n",
      "Train O/P: Epoch [1/5], Step [1470/6000], Loss: 0.0665\n",
      "Train O/P: Epoch [1/5], Step [1480/6000], Loss: 0.2531\n",
      "Train O/P: Epoch [1/5], Step [1490/6000], Loss: 0.0071\n",
      "Train O/P: Epoch [1/5], Step [1500/6000], Loss: 0.1440\n",
      "Train O/P: Epoch [1/5], Step [1510/6000], Loss: 0.0473\n",
      "Train O/P: Epoch [1/5], Step [1520/6000], Loss: 0.1218\n",
      "Train O/P: Epoch [1/5], Step [1530/6000], Loss: 0.1860\n",
      "Train O/P: Epoch [1/5], Step [1540/6000], Loss: 0.0591\n",
      "Train O/P: Epoch [1/5], Step [1550/6000], Loss: 0.2600\n",
      "Train O/P: Epoch [1/5], Step [1560/6000], Loss: 1.1810\n",
      "Train O/P: Epoch [1/5], Step [1570/6000], Loss: 0.0441\n",
      "Train O/P: Epoch [1/5], Step [1580/6000], Loss: 0.2972\n",
      "Train O/P: Epoch [1/5], Step [1590/6000], Loss: 0.0366\n",
      "Train O/P: Epoch [1/5], Step [1600/6000], Loss: 0.4601\n",
      "Train O/P: Epoch [1/5], Step [1610/6000], Loss: 0.0762\n",
      "Train O/P: Epoch [1/5], Step [1620/6000], Loss: 0.0074\n",
      "Train O/P: Epoch [1/5], Step [1630/6000], Loss: 0.0600\n",
      "Train O/P: Epoch [1/5], Step [1640/6000], Loss: 0.1255\n",
      "Train O/P: Epoch [1/5], Step [1650/6000], Loss: 0.2205\n",
      "Train O/P: Epoch [1/5], Step [1660/6000], Loss: 0.0049\n",
      "Train O/P: Epoch [1/5], Step [1670/6000], Loss: 0.2251\n",
      "Train O/P: Epoch [1/5], Step [1680/6000], Loss: 0.2361\n",
      "Train O/P: Epoch [1/5], Step [1690/6000], Loss: 0.9685\n",
      "Train O/P: Epoch [1/5], Step [1700/6000], Loss: 0.0108\n",
      "Train O/P: Epoch [1/5], Step [1710/6000], Loss: 0.2650\n",
      "Train O/P: Epoch [1/5], Step [1720/6000], Loss: 0.0487\n",
      "Train O/P: Epoch [1/5], Step [1730/6000], Loss: 0.0605\n",
      "Train O/P: Epoch [1/5], Step [1740/6000], Loss: 0.0640\n",
      "Train O/P: Epoch [1/5], Step [1750/6000], Loss: 0.1745\n",
      "Train O/P: Epoch [1/5], Step [1760/6000], Loss: 0.0865\n",
      "Train O/P: Epoch [1/5], Step [1770/6000], Loss: 0.0758\n",
      "Train O/P: Epoch [1/5], Step [1780/6000], Loss: 0.1683\n",
      "Train O/P: Epoch [1/5], Step [1790/6000], Loss: 0.0405\n",
      "Train O/P: Epoch [1/5], Step [1800/6000], Loss: 0.2686\n",
      "Train O/P: Epoch [1/5], Step [1810/6000], Loss: 0.0502\n",
      "Train O/P: Epoch [1/5], Step [1820/6000], Loss: 0.4605\n",
      "Train O/P: Epoch [1/5], Step [1830/6000], Loss: 0.0231\n",
      "Train O/P: Epoch [1/5], Step [1840/6000], Loss: 0.2809\n",
      "Train O/P: Epoch [1/5], Step [1850/6000], Loss: 0.7997\n",
      "Train O/P: Epoch [1/5], Step [1860/6000], Loss: 0.2838\n",
      "Train O/P: Epoch [1/5], Step [1870/6000], Loss: 0.0921\n",
      "Train O/P: Epoch [1/5], Step [1880/6000], Loss: 0.3309\n",
      "Train O/P: Epoch [1/5], Step [1890/6000], Loss: 0.2771\n",
      "Train O/P: Epoch [1/5], Step [1900/6000], Loss: 0.9245\n",
      "Train O/P: Epoch [1/5], Step [1910/6000], Loss: 0.0329\n",
      "Train O/P: Epoch [1/5], Step [1920/6000], Loss: 0.0741\n",
      "Train O/P: Epoch [1/5], Step [1930/6000], Loss: 0.5969\n",
      "Train O/P: Epoch [1/5], Step [1940/6000], Loss: 0.1374\n",
      "Train O/P: Epoch [1/5], Step [1950/6000], Loss: 0.4395\n",
      "Train O/P: Epoch [1/5], Step [1960/6000], Loss: 0.0439\n",
      "Train O/P: Epoch [1/5], Step [1970/6000], Loss: 0.1247\n",
      "Train O/P: Epoch [1/5], Step [1980/6000], Loss: 0.1124\n",
      "Train O/P: Epoch [1/5], Step [1990/6000], Loss: 0.2947\n",
      "Train O/P: Epoch [1/5], Step [2000/6000], Loss: 0.4710\n",
      "Train O/P: Epoch [1/5], Step [2010/6000], Loss: 0.2090\n",
      "Train O/P: Epoch [1/5], Step [2020/6000], Loss: 0.1264\n",
      "Train O/P: Epoch [1/5], Step [2030/6000], Loss: 0.0509\n",
      "Train O/P: Epoch [1/5], Step [2040/6000], Loss: 0.0700\n",
      "Train O/P: Epoch [1/5], Step [2050/6000], Loss: 0.0425\n",
      "Train O/P: Epoch [1/5], Step [2060/6000], Loss: 0.0848\n",
      "Train O/P: Epoch [1/5], Step [2070/6000], Loss: 0.1200\n",
      "Train O/P: Epoch [1/5], Step [2080/6000], Loss: 0.1441\n",
      "Train O/P: Epoch [1/5], Step [2090/6000], Loss: 0.1848\n",
      "Train O/P: Epoch [1/5], Step [2100/6000], Loss: 0.2998\n",
      "Train O/P: Epoch [1/5], Step [2110/6000], Loss: 0.0677\n",
      "Train O/P: Epoch [1/5], Step [2120/6000], Loss: 0.0428\n",
      "Train O/P: Epoch [1/5], Step [2130/6000], Loss: 0.0637\n",
      "Train O/P: Epoch [1/5], Step [2140/6000], Loss: 0.3653\n",
      "Train O/P: Epoch [1/5], Step [2150/6000], Loss: 0.1897\n",
      "Train O/P: Epoch [1/5], Step [2160/6000], Loss: 0.0199\n",
      "Train O/P: Epoch [1/5], Step [2170/6000], Loss: 0.0403\n",
      "Train O/P: Epoch [1/5], Step [2180/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [1/5], Step [2190/6000], Loss: 0.0602\n",
      "Train O/P: Epoch [1/5], Step [2200/6000], Loss: 0.4313\n",
      "Train O/P: Epoch [1/5], Step [2210/6000], Loss: 0.0048\n",
      "Train O/P: Epoch [1/5], Step [2220/6000], Loss: 0.1244\n",
      "Train O/P: Epoch [1/5], Step [2230/6000], Loss: 0.3782\n",
      "Train O/P: Epoch [1/5], Step [2240/6000], Loss: 0.0453\n",
      "Train O/P: Epoch [1/5], Step [2250/6000], Loss: 0.0114\n",
      "Train O/P: Epoch [1/5], Step [2260/6000], Loss: 0.1761\n",
      "Train O/P: Epoch [1/5], Step [2270/6000], Loss: 0.5255\n",
      "Train O/P: Epoch [1/5], Step [2280/6000], Loss: 0.0085\n",
      "Train O/P: Epoch [1/5], Step [2290/6000], Loss: 0.3762\n",
      "Train O/P: Epoch [1/5], Step [2300/6000], Loss: 0.0528\n",
      "Train O/P: Epoch [1/5], Step [2310/6000], Loss: 0.0226\n",
      "Train O/P: Epoch [1/5], Step [2320/6000], Loss: 0.1617\n",
      "Train O/P: Epoch [1/5], Step [2330/6000], Loss: 0.0419\n",
      "Train O/P: Epoch [1/5], Step [2340/6000], Loss: 0.1378\n",
      "Train O/P: Epoch [1/5], Step [2350/6000], Loss: 0.1559\n",
      "Train O/P: Epoch [1/5], Step [2360/6000], Loss: 0.1281\n",
      "Train O/P: Epoch [1/5], Step [2370/6000], Loss: 0.0244\n",
      "Train O/P: Epoch [1/5], Step [2380/6000], Loss: 0.3298\n",
      "Train O/P: Epoch [1/5], Step [2390/6000], Loss: 0.2625\n",
      "Train O/P: Epoch [1/5], Step [2400/6000], Loss: 0.3184\n",
      "Train O/P: Epoch [1/5], Step [2410/6000], Loss: 0.1141\n",
      "Train O/P: Epoch [1/5], Step [2420/6000], Loss: 0.0270\n",
      "Train O/P: Epoch [1/5], Step [2430/6000], Loss: 0.0116\n",
      "Train O/P: Epoch [1/5], Step [2440/6000], Loss: 0.0845\n",
      "Train O/P: Epoch [1/5], Step [2450/6000], Loss: 0.0656\n",
      "Train O/P: Epoch [1/5], Step [2460/6000], Loss: 0.0370\n",
      "Train O/P: Epoch [1/5], Step [2470/6000], Loss: 0.0787\n",
      "Train O/P: Epoch [1/5], Step [2480/6000], Loss: 0.1814\n",
      "Train O/P: Epoch [1/5], Step [2490/6000], Loss: 0.0190\n",
      "Train O/P: Epoch [1/5], Step [2500/6000], Loss: 0.0417\n",
      "Train O/P: Epoch [1/5], Step [2510/6000], Loss: 0.0177\n",
      "Train O/P: Epoch [1/5], Step [2520/6000], Loss: 0.0209\n",
      "Train O/P: Epoch [1/5], Step [2530/6000], Loss: 0.2018\n",
      "Train O/P: Epoch [1/5], Step [2540/6000], Loss: 0.5120\n",
      "Train O/P: Epoch [1/5], Step [2550/6000], Loss: 0.1766\n",
      "Train O/P: Epoch [1/5], Step [2560/6000], Loss: 0.1011\n",
      "Train O/P: Epoch [1/5], Step [2570/6000], Loss: 0.2294\n",
      "Train O/P: Epoch [1/5], Step [2580/6000], Loss: 0.1371\n",
      "Train O/P: Epoch [1/5], Step [2590/6000], Loss: 0.0883\n",
      "Train O/P: Epoch [1/5], Step [2600/6000], Loss: 0.0078\n",
      "Train O/P: Epoch [1/5], Step [2610/6000], Loss: 0.0751\n",
      "Train O/P: Epoch [1/5], Step [2620/6000], Loss: 0.0385\n",
      "Train O/P: Epoch [1/5], Step [2630/6000], Loss: 0.0693\n",
      "Train O/P: Epoch [1/5], Step [2640/6000], Loss: 0.0098\n",
      "Train O/P: Epoch [1/5], Step [2650/6000], Loss: 0.0669\n",
      "Train O/P: Epoch [1/5], Step [2660/6000], Loss: 0.3159\n",
      "Train O/P: Epoch [1/5], Step [2670/6000], Loss: 0.0441\n",
      "Train O/P: Epoch [1/5], Step [2680/6000], Loss: 0.0145\n",
      "Train O/P: Epoch [1/5], Step [2690/6000], Loss: 0.2691\n",
      "Train O/P: Epoch [1/5], Step [2700/6000], Loss: 0.1255\n",
      "Train O/P: Epoch [1/5], Step [2710/6000], Loss: 0.3025\n",
      "Train O/P: Epoch [1/5], Step [2720/6000], Loss: 0.2768\n",
      "Train O/P: Epoch [1/5], Step [2730/6000], Loss: 0.0832\n",
      "Train O/P: Epoch [1/5], Step [2740/6000], Loss: 0.0416\n",
      "Train O/P: Epoch [1/5], Step [2750/6000], Loss: 0.1403\n",
      "Train O/P: Epoch [1/5], Step [2760/6000], Loss: 0.1406\n",
      "Train O/P: Epoch [1/5], Step [2770/6000], Loss: 0.0956\n",
      "Train O/P: Epoch [1/5], Step [2780/6000], Loss: 0.0110\n",
      "Train O/P: Epoch [1/5], Step [2790/6000], Loss: 0.0845\n",
      "Train O/P: Epoch [1/5], Step [2800/6000], Loss: 0.0965\n",
      "Train O/P: Epoch [1/5], Step [2810/6000], Loss: 0.0144\n",
      "Train O/P: Epoch [1/5], Step [2820/6000], Loss: 0.4242\n",
      "Train O/P: Epoch [1/5], Step [2830/6000], Loss: 0.1794\n",
      "Train O/P: Epoch [1/5], Step [2840/6000], Loss: 0.2533\n",
      "Train O/P: Epoch [1/5], Step [2850/6000], Loss: 0.0213\n",
      "Train O/P: Epoch [1/5], Step [2860/6000], Loss: 0.2642\n",
      "Train O/P: Epoch [1/5], Step [2870/6000], Loss: 0.2132\n",
      "Train O/P: Epoch [1/5], Step [2880/6000], Loss: 0.0660\n",
      "Train O/P: Epoch [1/5], Step [2890/6000], Loss: 0.1213\n",
      "Train O/P: Epoch [1/5], Step [2900/6000], Loss: 0.0463\n",
      "Train O/P: Epoch [1/5], Step [2910/6000], Loss: 0.0388\n",
      "Train O/P: Epoch [1/5], Step [2920/6000], Loss: 0.0343\n",
      "Train O/P: Epoch [1/5], Step [2930/6000], Loss: 0.0755\n",
      "Train O/P: Epoch [1/5], Step [2940/6000], Loss: 0.0295\n",
      "Train O/P: Epoch [1/5], Step [2950/6000], Loss: 0.3885\n",
      "Train O/P: Epoch [1/5], Step [2960/6000], Loss: 0.0805\n",
      "Train O/P: Epoch [1/5], Step [2970/6000], Loss: 0.2167\n",
      "Train O/P: Epoch [1/5], Step [2980/6000], Loss: 0.1917\n",
      "Train O/P: Epoch [1/5], Step [2990/6000], Loss: 0.0722\n",
      "Train O/P: Epoch [1/5], Step [3000/6000], Loss: 0.4151\n",
      "Train O/P: Epoch [1/5], Step [3010/6000], Loss: 0.1169\n",
      "Train O/P: Epoch [1/5], Step [3020/6000], Loss: 0.0422\n",
      "Train O/P: Epoch [1/5], Step [3030/6000], Loss: 0.1010\n",
      "Train O/P: Epoch [1/5], Step [3040/6000], Loss: 0.4148\n",
      "Train O/P: Epoch [1/5], Step [3050/6000], Loss: 0.1691\n",
      "Train O/P: Epoch [1/5], Step [3060/6000], Loss: 0.1910\n",
      "Train O/P: Epoch [1/5], Step [3070/6000], Loss: 0.0934\n",
      "Train O/P: Epoch [1/5], Step [3080/6000], Loss: 0.4109\n",
      "Train O/P: Epoch [1/5], Step [3090/6000], Loss: 0.0887\n",
      "Train O/P: Epoch [1/5], Step [3100/6000], Loss: 0.3096\n",
      "Train O/P: Epoch [1/5], Step [3110/6000], Loss: 0.0425\n",
      "Train O/P: Epoch [1/5], Step [3120/6000], Loss: 0.2916\n",
      "Train O/P: Epoch [1/5], Step [3130/6000], Loss: 0.0242\n",
      "Train O/P: Epoch [1/5], Step [3140/6000], Loss: 0.0783\n",
      "Train O/P: Epoch [1/5], Step [3150/6000], Loss: 0.1594\n",
      "Train O/P: Epoch [1/5], Step [3160/6000], Loss: 0.1925\n",
      "Train O/P: Epoch [1/5], Step [3170/6000], Loss: 0.0373\n",
      "Train O/P: Epoch [1/5], Step [3180/6000], Loss: 0.1874\n",
      "Train O/P: Epoch [1/5], Step [3190/6000], Loss: 0.2717\n",
      "Train O/P: Epoch [1/5], Step [3200/6000], Loss: 0.0419\n",
      "Train O/P: Epoch [1/5], Step [3210/6000], Loss: 0.0074\n",
      "Train O/P: Epoch [1/5], Step [3220/6000], Loss: 0.0799\n",
      "Train O/P: Epoch [1/5], Step [3230/6000], Loss: 0.4510\n",
      "Train O/P: Epoch [1/5], Step [3240/6000], Loss: 0.0343\n",
      "Train O/P: Epoch [1/5], Step [3250/6000], Loss: 0.0808\n",
      "Train O/P: Epoch [1/5], Step [3260/6000], Loss: 0.2670\n",
      "Train O/P: Epoch [1/5], Step [3270/6000], Loss: 0.0538\n",
      "Train O/P: Epoch [1/5], Step [3280/6000], Loss: 0.2833\n",
      "Train O/P: Epoch [1/5], Step [3290/6000], Loss: 0.4241\n",
      "Train O/P: Epoch [1/5], Step [3300/6000], Loss: 0.2460\n",
      "Train O/P: Epoch [1/5], Step [3310/6000], Loss: 0.0993\n",
      "Train O/P: Epoch [1/5], Step [3320/6000], Loss: 0.0341\n",
      "Train O/P: Epoch [1/5], Step [3330/6000], Loss: 0.0272\n",
      "Train O/P: Epoch [1/5], Step [3340/6000], Loss: 0.0235\n",
      "Train O/P: Epoch [1/5], Step [3350/6000], Loss: 0.4838\n",
      "Train O/P: Epoch [1/5], Step [3360/6000], Loss: 0.3853\n",
      "Train O/P: Epoch [1/5], Step [3370/6000], Loss: 0.1668\n",
      "Train O/P: Epoch [1/5], Step [3380/6000], Loss: 0.0987\n",
      "Train O/P: Epoch [1/5], Step [3390/6000], Loss: 0.0216\n",
      "Train O/P: Epoch [1/5], Step [3400/6000], Loss: 0.7033\n",
      "Train O/P: Epoch [1/5], Step [3410/6000], Loss: 0.0095\n",
      "Train O/P: Epoch [1/5], Step [3420/6000], Loss: 0.3849\n",
      "Train O/P: Epoch [1/5], Step [3430/6000], Loss: 0.0461\n",
      "Train O/P: Epoch [1/5], Step [3440/6000], Loss: 0.5533\n",
      "Train O/P: Epoch [1/5], Step [3450/6000], Loss: 0.0492\n",
      "Train O/P: Epoch [1/5], Step [3460/6000], Loss: 0.3478\n",
      "Train O/P: Epoch [1/5], Step [3470/6000], Loss: 0.0671\n",
      "Train O/P: Epoch [1/5], Step [3480/6000], Loss: 0.4074\n",
      "Train O/P: Epoch [1/5], Step [3490/6000], Loss: 0.0332\n",
      "Train O/P: Epoch [1/5], Step [3500/6000], Loss: 0.2684\n",
      "Train O/P: Epoch [1/5], Step [3510/6000], Loss: 0.0455\n",
      "Train O/P: Epoch [1/5], Step [3520/6000], Loss: 0.0360\n",
      "Train O/P: Epoch [1/5], Step [3530/6000], Loss: 0.2249\n",
      "Train O/P: Epoch [1/5], Step [3540/6000], Loss: 0.5574\n",
      "Train O/P: Epoch [1/5], Step [3550/6000], Loss: 0.0105\n",
      "Train O/P: Epoch [1/5], Step [3560/6000], Loss: 0.0593\n",
      "Train O/P: Epoch [1/5], Step [3570/6000], Loss: 0.0810\n",
      "Train O/P: Epoch [1/5], Step [3580/6000], Loss: 0.1128\n",
      "Train O/P: Epoch [1/5], Step [3590/6000], Loss: 0.0269\n",
      "Train O/P: Epoch [1/5], Step [3600/6000], Loss: 0.2221\n",
      "Train O/P: Epoch [1/5], Step [3610/6000], Loss: 0.3573\n",
      "Train O/P: Epoch [1/5], Step [3620/6000], Loss: 0.7912\n",
      "Train O/P: Epoch [1/5], Step [3630/6000], Loss: 0.4393\n",
      "Train O/P: Epoch [1/5], Step [3640/6000], Loss: 0.0591\n",
      "Train O/P: Epoch [1/5], Step [3650/6000], Loss: 0.1463\n",
      "Train O/P: Epoch [1/5], Step [3660/6000], Loss: 0.0800\n",
      "Train O/P: Epoch [1/5], Step [3670/6000], Loss: 0.1900\n",
      "Train O/P: Epoch [1/5], Step [3680/6000], Loss: 0.0179\n",
      "Train O/P: Epoch [1/5], Step [3690/6000], Loss: 0.0697\n",
      "Train O/P: Epoch [1/5], Step [3700/6000], Loss: 0.6940\n",
      "Train O/P: Epoch [1/5], Step [3710/6000], Loss: 0.0260\n",
      "Train O/P: Epoch [1/5], Step [3720/6000], Loss: 0.0161\n",
      "Train O/P: Epoch [1/5], Step [3730/6000], Loss: 0.2541\n",
      "Train O/P: Epoch [1/5], Step [3740/6000], Loss: 0.0158\n",
      "Train O/P: Epoch [1/5], Step [3750/6000], Loss: 0.0184\n",
      "Train O/P: Epoch [1/5], Step [3760/6000], Loss: 0.2745\n",
      "Train O/P: Epoch [1/5], Step [3770/6000], Loss: 0.0497\n",
      "Train O/P: Epoch [1/5], Step [3780/6000], Loss: 0.1326\n",
      "Train O/P: Epoch [1/5], Step [3790/6000], Loss: 0.0643\n",
      "Train O/P: Epoch [1/5], Step [3800/6000], Loss: 0.3517\n",
      "Train O/P: Epoch [1/5], Step [3810/6000], Loss: 0.1834\n",
      "Train O/P: Epoch [1/5], Step [3820/6000], Loss: 0.2550\n",
      "Train O/P: Epoch [1/5], Step [3830/6000], Loss: 0.1231\n",
      "Train O/P: Epoch [1/5], Step [3840/6000], Loss: 0.0685\n",
      "Train O/P: Epoch [1/5], Step [3850/6000], Loss: 0.0972\n",
      "Train O/P: Epoch [1/5], Step [3860/6000], Loss: 0.4794\n",
      "Train O/P: Epoch [1/5], Step [3870/6000], Loss: 0.0460\n",
      "Train O/P: Epoch [1/5], Step [3880/6000], Loss: 0.1930\n",
      "Train O/P: Epoch [1/5], Step [3890/6000], Loss: 0.1039\n",
      "Train O/P: Epoch [1/5], Step [3900/6000], Loss: 0.2356\n",
      "Train O/P: Epoch [1/5], Step [3910/6000], Loss: 0.1139\n",
      "Train O/P: Epoch [1/5], Step [3920/6000], Loss: 0.0979\n",
      "Train O/P: Epoch [1/5], Step [3930/6000], Loss: 0.7312\n",
      "Train O/P: Epoch [1/5], Step [3940/6000], Loss: 0.0275\n",
      "Train O/P: Epoch [1/5], Step [3950/6000], Loss: 0.2934\n",
      "Train O/P: Epoch [1/5], Step [3960/6000], Loss: 0.3713\n",
      "Train O/P: Epoch [1/5], Step [3970/6000], Loss: 0.0542\n",
      "Train O/P: Epoch [1/5], Step [3980/6000], Loss: 0.0324\n",
      "Train O/P: Epoch [1/5], Step [3990/6000], Loss: 0.1691\n",
      "Train O/P: Epoch [1/5], Step [4000/6000], Loss: 0.0221\n",
      "Train O/P: Epoch [1/5], Step [4010/6000], Loss: 0.1580\n",
      "Train O/P: Epoch [1/5], Step [4020/6000], Loss: 0.1022\n",
      "Train O/P: Epoch [1/5], Step [4030/6000], Loss: 0.2746\n",
      "Train O/P: Epoch [1/5], Step [4040/6000], Loss: 0.0800\n",
      "Train O/P: Epoch [1/5], Step [4050/6000], Loss: 0.0112\n",
      "Train O/P: Epoch [1/5], Step [4060/6000], Loss: 0.0752\n",
      "Train O/P: Epoch [1/5], Step [4070/6000], Loss: 0.0668\n",
      "Train O/P: Epoch [1/5], Step [4080/6000], Loss: 0.1789\n",
      "Train O/P: Epoch [1/5], Step [4090/6000], Loss: 0.0183\n",
      "Train O/P: Epoch [1/5], Step [4100/6000], Loss: 0.1232\n",
      "Train O/P: Epoch [1/5], Step [4110/6000], Loss: 0.1891\n",
      "Train O/P: Epoch [1/5], Step [4120/6000], Loss: 0.7936\n",
      "Train O/P: Epoch [1/5], Step [4130/6000], Loss: 0.0814\n",
      "Train O/P: Epoch [1/5], Step [4140/6000], Loss: 0.1595\n",
      "Train O/P: Epoch [1/5], Step [4150/6000], Loss: 0.0944\n",
      "Train O/P: Epoch [1/5], Step [4160/6000], Loss: 0.0097\n",
      "Train O/P: Epoch [1/5], Step [4170/6000], Loss: 0.0196\n",
      "Train O/P: Epoch [1/5], Step [4180/6000], Loss: 0.0566\n",
      "Train O/P: Epoch [1/5], Step [4190/6000], Loss: 0.0844\n",
      "Train O/P: Epoch [1/5], Step [4200/6000], Loss: 0.4585\n",
      "Train O/P: Epoch [1/5], Step [4210/6000], Loss: 0.1927\n",
      "Train O/P: Epoch [1/5], Step [4220/6000], Loss: 0.1319\n",
      "Train O/P: Epoch [1/5], Step [4230/6000], Loss: 0.1506\n",
      "Train O/P: Epoch [1/5], Step [4240/6000], Loss: 0.1305\n",
      "Train O/P: Epoch [1/5], Step [4250/6000], Loss: 0.0546\n",
      "Train O/P: Epoch [1/5], Step [4260/6000], Loss: 0.2713\n",
      "Train O/P: Epoch [1/5], Step [4270/6000], Loss: 0.3310\n",
      "Train O/P: Epoch [1/5], Step [4280/6000], Loss: 0.2911\n",
      "Train O/P: Epoch [1/5], Step [4290/6000], Loss: 0.0532\n",
      "Train O/P: Epoch [1/5], Step [4300/6000], Loss: 0.0403\n",
      "Train O/P: Epoch [1/5], Step [4310/6000], Loss: 0.5272\n",
      "Train O/P: Epoch [1/5], Step [4320/6000], Loss: 0.0026\n",
      "Train O/P: Epoch [1/5], Step [4330/6000], Loss: 0.0073\n",
      "Train O/P: Epoch [1/5], Step [4340/6000], Loss: 0.1262\n",
      "Train O/P: Epoch [1/5], Step [4350/6000], Loss: 0.0107\n",
      "Train O/P: Epoch [1/5], Step [4360/6000], Loss: 0.0285\n",
      "Train O/P: Epoch [1/5], Step [4370/6000], Loss: 0.2893\n",
      "Train O/P: Epoch [1/5], Step [4380/6000], Loss: 0.1472\n",
      "Train O/P: Epoch [1/5], Step [4390/6000], Loss: 0.1333\n",
      "Train O/P: Epoch [1/5], Step [4400/6000], Loss: 0.1067\n",
      "Train O/P: Epoch [1/5], Step [4410/6000], Loss: 0.7490\n",
      "Train O/P: Epoch [1/5], Step [4420/6000], Loss: 0.1772\n",
      "Train O/P: Epoch [1/5], Step [4430/6000], Loss: 0.0628\n",
      "Train O/P: Epoch [1/5], Step [4440/6000], Loss: 0.0603\n",
      "Train O/P: Epoch [1/5], Step [4450/6000], Loss: 0.0997\n",
      "Train O/P: Epoch [1/5], Step [4460/6000], Loss: 0.0143\n",
      "Train O/P: Epoch [1/5], Step [4470/6000], Loss: 0.0163\n",
      "Train O/P: Epoch [1/5], Step [4480/6000], Loss: 0.0745\n",
      "Train O/P: Epoch [1/5], Step [4490/6000], Loss: 0.1954\n",
      "Train O/P: Epoch [1/5], Step [4500/6000], Loss: 0.1265\n",
      "Train O/P: Epoch [1/5], Step [4510/6000], Loss: 0.0870\n",
      "Train O/P: Epoch [1/5], Step [4520/6000], Loss: 0.0589\n",
      "Train O/P: Epoch [1/5], Step [4530/6000], Loss: 0.0457\n",
      "Train O/P: Epoch [1/5], Step [4540/6000], Loss: 0.0162\n",
      "Train O/P: Epoch [1/5], Step [4550/6000], Loss: 0.1183\n",
      "Train O/P: Epoch [1/5], Step [4560/6000], Loss: 0.0073\n",
      "Train O/P: Epoch [1/5], Step [4570/6000], Loss: 0.3777\n",
      "Train O/P: Epoch [1/5], Step [4580/6000], Loss: 0.4442\n",
      "Train O/P: Epoch [1/5], Step [4590/6000], Loss: 0.1307\n",
      "Train O/P: Epoch [1/5], Step [4600/6000], Loss: 0.0556\n",
      "Train O/P: Epoch [1/5], Step [4610/6000], Loss: 0.0200\n",
      "Train O/P: Epoch [1/5], Step [4620/6000], Loss: 0.0369\n",
      "Train O/P: Epoch [1/5], Step [4630/6000], Loss: 0.2042\n",
      "Train O/P: Epoch [1/5], Step [4640/6000], Loss: 0.0957\n",
      "Train O/P: Epoch [1/5], Step [4650/6000], Loss: 0.0021\n",
      "Train O/P: Epoch [1/5], Step [4660/6000], Loss: 0.0846\n",
      "Train O/P: Epoch [1/5], Step [4670/6000], Loss: 0.0477\n",
      "Train O/P: Epoch [1/5], Step [4680/6000], Loss: 0.0365\n",
      "Train O/P: Epoch [1/5], Step [4690/6000], Loss: 0.0097\n",
      "Train O/P: Epoch [1/5], Step [4700/6000], Loss: 0.1189\n",
      "Train O/P: Epoch [1/5], Step [4710/6000], Loss: 0.0281\n",
      "Train O/P: Epoch [1/5], Step [4720/6000], Loss: 0.1202\n",
      "Train O/P: Epoch [1/5], Step [4730/6000], Loss: 0.2113\n",
      "Train O/P: Epoch [1/5], Step [4740/6000], Loss: 0.1835\n",
      "Train O/P: Epoch [1/5], Step [4750/6000], Loss: 0.1891\n",
      "Train O/P: Epoch [1/5], Step [4760/6000], Loss: 0.0068\n",
      "Train O/P: Epoch [1/5], Step [4770/6000], Loss: 0.0227\n",
      "Train O/P: Epoch [1/5], Step [4780/6000], Loss: 0.1855\n",
      "Train O/P: Epoch [1/5], Step [4790/6000], Loss: 0.0184\n",
      "Train O/P: Epoch [1/5], Step [4800/6000], Loss: 0.0721\n",
      "Train O/P: Epoch [1/5], Step [4810/6000], Loss: 0.3906\n",
      "Train O/P: Epoch [1/5], Step [4820/6000], Loss: 0.0370\n",
      "Train O/P: Epoch [1/5], Step [4830/6000], Loss: 0.0131\n",
      "Train O/P: Epoch [1/5], Step [4840/6000], Loss: 0.3467\n",
      "Train O/P: Epoch [1/5], Step [4850/6000], Loss: 0.1996\n",
      "Train O/P: Epoch [1/5], Step [4860/6000], Loss: 0.4493\n",
      "Train O/P: Epoch [1/5], Step [4870/6000], Loss: 0.0176\n",
      "Train O/P: Epoch [1/5], Step [4880/6000], Loss: 0.0213\n",
      "Train O/P: Epoch [1/5], Step [4890/6000], Loss: 0.1173\n",
      "Train O/P: Epoch [1/5], Step [4900/6000], Loss: 0.1660\n",
      "Train O/P: Epoch [1/5], Step [4910/6000], Loss: 0.0595\n",
      "Train O/P: Epoch [1/5], Step [4920/6000], Loss: 0.0252\n",
      "Train O/P: Epoch [1/5], Step [4930/6000], Loss: 0.0940\n",
      "Train O/P: Epoch [1/5], Step [4940/6000], Loss: 0.0775\n",
      "Train O/P: Epoch [1/5], Step [4950/6000], Loss: 0.0097\n",
      "Train O/P: Epoch [1/5], Step [4960/6000], Loss: 0.0201\n",
      "Train O/P: Epoch [1/5], Step [4970/6000], Loss: 0.1730\n",
      "Train O/P: Epoch [1/5], Step [4980/6000], Loss: 0.1916\n",
      "Train O/P: Epoch [1/5], Step [4990/6000], Loss: 0.0907\n",
      "Train O/P: Epoch [1/5], Step [5000/6000], Loss: 0.0230\n",
      "Train O/P: Epoch [1/5], Step [5010/6000], Loss: 0.0189\n",
      "Train O/P: Epoch [1/5], Step [5020/6000], Loss: 0.0100\n",
      "Train O/P: Epoch [1/5], Step [5030/6000], Loss: 0.0431\n",
      "Train O/P: Epoch [1/5], Step [5040/6000], Loss: 0.0237\n",
      "Train O/P: Epoch [1/5], Step [5050/6000], Loss: 0.1393\n",
      "Train O/P: Epoch [1/5], Step [5060/6000], Loss: 0.9838\n",
      "Train O/P: Epoch [1/5], Step [5070/6000], Loss: 0.3149\n",
      "Train O/P: Epoch [1/5], Step [5080/6000], Loss: 0.0321\n",
      "Train O/P: Epoch [1/5], Step [5090/6000], Loss: 0.3967\n",
      "Train O/P: Epoch [1/5], Step [5100/6000], Loss: 0.0432\n",
      "Train O/P: Epoch [1/5], Step [5110/6000], Loss: 0.1282\n",
      "Train O/P: Epoch [1/5], Step [5120/6000], Loss: 0.3936\n",
      "Train O/P: Epoch [1/5], Step [5130/6000], Loss: 0.4746\n",
      "Train O/P: Epoch [1/5], Step [5140/6000], Loss: 0.1186\n",
      "Train O/P: Epoch [1/5], Step [5150/6000], Loss: 0.2529\n",
      "Train O/P: Epoch [1/5], Step [5160/6000], Loss: 0.0836\n",
      "Train O/P: Epoch [1/5], Step [5170/6000], Loss: 0.1849\n",
      "Train O/P: Epoch [1/5], Step [5180/6000], Loss: 0.1712\n",
      "Train O/P: Epoch [1/5], Step [5190/6000], Loss: 0.2366\n",
      "Train O/P: Epoch [1/5], Step [5200/6000], Loss: 0.0258\n",
      "Train O/P: Epoch [1/5], Step [5210/6000], Loss: 0.1495\n",
      "Train O/P: Epoch [1/5], Step [5220/6000], Loss: 0.1242\n",
      "Train O/P: Epoch [1/5], Step [5230/6000], Loss: 0.0503\n",
      "Train O/P: Epoch [1/5], Step [5240/6000], Loss: 0.4840\n",
      "Train O/P: Epoch [1/5], Step [5250/6000], Loss: 0.0308\n",
      "Train O/P: Epoch [1/5], Step [5260/6000], Loss: 0.1746\n",
      "Train O/P: Epoch [1/5], Step [5270/6000], Loss: 0.1074\n",
      "Train O/P: Epoch [1/5], Step [5280/6000], Loss: 0.2882\n",
      "Train O/P: Epoch [1/5], Step [5290/6000], Loss: 0.0865\n",
      "Train O/P: Epoch [1/5], Step [5300/6000], Loss: 0.3266\n",
      "Train O/P: Epoch [1/5], Step [5310/6000], Loss: 0.0938\n",
      "Train O/P: Epoch [1/5], Step [5320/6000], Loss: 0.0334\n",
      "Train O/P: Epoch [1/5], Step [5330/6000], Loss: 0.0069\n",
      "Train O/P: Epoch [1/5], Step [5340/6000], Loss: 0.0794\n",
      "Train O/P: Epoch [1/5], Step [5350/6000], Loss: 0.0034\n",
      "Train O/P: Epoch [1/5], Step [5360/6000], Loss: 0.1124\n",
      "Train O/P: Epoch [1/5], Step [5370/6000], Loss: 0.1056\n",
      "Train O/P: Epoch [1/5], Step [5380/6000], Loss: 0.2645\n",
      "Train O/P: Epoch [1/5], Step [5390/6000], Loss: 0.1893\n",
      "Train O/P: Epoch [1/5], Step [5400/6000], Loss: 0.0066\n",
      "Train O/P: Epoch [1/5], Step [5410/6000], Loss: 0.0081\n",
      "Train O/P: Epoch [1/5], Step [5420/6000], Loss: 0.0917\n",
      "Train O/P: Epoch [1/5], Step [5430/6000], Loss: 0.1807\n",
      "Train O/P: Epoch [1/5], Step [5440/6000], Loss: 0.0195\n",
      "Train O/P: Epoch [1/5], Step [5450/6000], Loss: 0.0685\n",
      "Train O/P: Epoch [1/5], Step [5460/6000], Loss: 0.0440\n",
      "Train O/P: Epoch [1/5], Step [5470/6000], Loss: 0.1383\n",
      "Train O/P: Epoch [1/5], Step [5480/6000], Loss: 0.2992\n",
      "Train O/P: Epoch [1/5], Step [5490/6000], Loss: 0.0130\n",
      "Train O/P: Epoch [1/5], Step [5500/6000], Loss: 0.4997\n",
      "Train O/P: Epoch [1/5], Step [5510/6000], Loss: 0.2964\n",
      "Train O/P: Epoch [1/5], Step [5520/6000], Loss: 0.1203\n",
      "Train O/P: Epoch [1/5], Step [5530/6000], Loss: 0.0346\n",
      "Train O/P: Epoch [1/5], Step [5540/6000], Loss: 0.0562\n",
      "Train O/P: Epoch [1/5], Step [5550/6000], Loss: 0.0099\n",
      "Train O/P: Epoch [1/5], Step [5560/6000], Loss: 0.0319\n",
      "Train O/P: Epoch [1/5], Step [5570/6000], Loss: 0.1235\n",
      "Train O/P: Epoch [1/5], Step [5580/6000], Loss: 0.1167\n",
      "Train O/P: Epoch [1/5], Step [5590/6000], Loss: 0.0607\n",
      "Train O/P: Epoch [1/5], Step [5600/6000], Loss: 0.0235\n",
      "Train O/P: Epoch [1/5], Step [5610/6000], Loss: 0.4633\n",
      "Train O/P: Epoch [1/5], Step [5620/6000], Loss: 0.5311\n",
      "Train O/P: Epoch [1/5], Step [5630/6000], Loss: 0.0096\n",
      "Train O/P: Epoch [1/5], Step [5640/6000], Loss: 0.0473\n",
      "Train O/P: Epoch [1/5], Step [5650/6000], Loss: 0.0454\n",
      "Train O/P: Epoch [1/5], Step [5660/6000], Loss: 0.0200\n",
      "Train O/P: Epoch [1/5], Step [5670/6000], Loss: 0.2615\n",
      "Train O/P: Epoch [1/5], Step [5680/6000], Loss: 0.0137\n",
      "Train O/P: Epoch [1/5], Step [5690/6000], Loss: 0.0913\n",
      "Train O/P: Epoch [1/5], Step [5700/6000], Loss: 0.3845\n",
      "Train O/P: Epoch [1/5], Step [5710/6000], Loss: 0.0494\n",
      "Train O/P: Epoch [1/5], Step [5720/6000], Loss: 0.1644\n",
      "Train O/P: Epoch [1/5], Step [5730/6000], Loss: 0.1957\n",
      "Train O/P: Epoch [1/5], Step [5740/6000], Loss: 0.4901\n",
      "Train O/P: Epoch [1/5], Step [5750/6000], Loss: 0.0653\n",
      "Train O/P: Epoch [1/5], Step [5760/6000], Loss: 0.2157\n",
      "Train O/P: Epoch [1/5], Step [5770/6000], Loss: 0.0350\n",
      "Train O/P: Epoch [1/5], Step [5780/6000], Loss: 0.0612\n",
      "Train O/P: Epoch [1/5], Step [5790/6000], Loss: 0.0273\n",
      "Train O/P: Epoch [1/5], Step [5800/6000], Loss: 0.0651\n",
      "Train O/P: Epoch [1/5], Step [5810/6000], Loss: 0.0209\n",
      "Train O/P: Epoch [1/5], Step [5820/6000], Loss: 0.0745\n",
      "Train O/P: Epoch [1/5], Step [5830/6000], Loss: 0.0271\n",
      "Train O/P: Epoch [1/5], Step [5840/6000], Loss: 0.2066\n",
      "Train O/P: Epoch [1/5], Step [5850/6000], Loss: 0.0969\n",
      "Train O/P: Epoch [1/5], Step [5860/6000], Loss: 0.1387\n",
      "Train O/P: Epoch [1/5], Step [5870/6000], Loss: 0.1723\n",
      "Train O/P: Epoch [1/5], Step [5880/6000], Loss: 0.0131\n",
      "Train O/P: Epoch [1/5], Step [5890/6000], Loss: 0.0093\n",
      "Train O/P: Epoch [1/5], Step [5900/6000], Loss: 0.0373\n",
      "Train O/P: Epoch [1/5], Step [5910/6000], Loss: 0.2461\n",
      "Train O/P: Epoch [1/5], Step [5920/6000], Loss: 0.1609\n",
      "Train O/P: Epoch [1/5], Step [5930/6000], Loss: 0.0179\n",
      "Train O/P: Epoch [1/5], Step [5940/6000], Loss: 0.1408\n",
      "Train O/P: Epoch [1/5], Step [5950/6000], Loss: 0.3988\n",
      "Train O/P: Epoch [1/5], Step [5960/6000], Loss: 0.0195\n",
      "Train O/P: Epoch [1/5], Step [5970/6000], Loss: 0.0669\n",
      "Train O/P: Epoch [1/5], Step [5980/6000], Loss: 0.0207\n",
      "Train O/P: Epoch [1/5], Step [5990/6000], Loss: 0.3024\n",
      "Train O/P: Epoch [1/5], Step [6000/6000], Loss: 0.0765\n",
      "Train O/P: Epoch [2/5], Step [10/6000], Loss: 0.0396\n",
      "Train O/P: Epoch [2/5], Step [20/6000], Loss: 0.0463\n",
      "Train O/P: Epoch [2/5], Step [30/6000], Loss: 0.1157\n",
      "Train O/P: Epoch [2/5], Step [40/6000], Loss: 0.0050\n",
      "Train O/P: Epoch [2/5], Step [50/6000], Loss: 0.1098\n",
      "Train O/P: Epoch [2/5], Step [60/6000], Loss: 0.6209\n",
      "Train O/P: Epoch [2/5], Step [70/6000], Loss: 0.5648\n",
      "Train O/P: Epoch [2/5], Step [80/6000], Loss: 0.0884\n",
      "Train O/P: Epoch [2/5], Step [90/6000], Loss: 0.1568\n",
      "Train O/P: Epoch [2/5], Step [100/6000], Loss: 0.1557\n",
      "Train O/P: Epoch [2/5], Step [110/6000], Loss: 0.0526\n",
      "Train O/P: Epoch [2/5], Step [120/6000], Loss: 0.0615\n",
      "Train O/P: Epoch [2/5], Step [130/6000], Loss: 0.0179\n",
      "Train O/P: Epoch [2/5], Step [140/6000], Loss: 0.0392\n",
      "Train O/P: Epoch [2/5], Step [150/6000], Loss: 0.4538\n",
      "Train O/P: Epoch [2/5], Step [160/6000], Loss: 0.0611\n",
      "Train O/P: Epoch [2/5], Step [170/6000], Loss: 0.1573\n",
      "Train O/P: Epoch [2/5], Step [180/6000], Loss: 0.0556\n",
      "Train O/P: Epoch [2/5], Step [190/6000], Loss: 0.7419\n",
      "Train O/P: Epoch [2/5], Step [200/6000], Loss: 0.0205\n",
      "Train O/P: Epoch [2/5], Step [210/6000], Loss: 0.0803\n",
      "Train O/P: Epoch [2/5], Step [220/6000], Loss: 0.0087\n",
      "Train O/P: Epoch [2/5], Step [230/6000], Loss: 0.4653\n",
      "Train O/P: Epoch [2/5], Step [240/6000], Loss: 0.1121\n",
      "Train O/P: Epoch [2/5], Step [250/6000], Loss: 0.3297\n",
      "Train O/P: Epoch [2/5], Step [260/6000], Loss: 0.2269\n",
      "Train O/P: Epoch [2/5], Step [270/6000], Loss: 0.0794\n",
      "Train O/P: Epoch [2/5], Step [280/6000], Loss: 0.1299\n",
      "Train O/P: Epoch [2/5], Step [290/6000], Loss: 0.0219\n",
      "Train O/P: Epoch [2/5], Step [300/6000], Loss: 0.0751\n",
      "Train O/P: Epoch [2/5], Step [310/6000], Loss: 0.2386\n",
      "Train O/P: Epoch [2/5], Step [320/6000], Loss: 0.4571\n",
      "Train O/P: Epoch [2/5], Step [330/6000], Loss: 0.1530\n",
      "Train O/P: Epoch [2/5], Step [340/6000], Loss: 0.0061\n",
      "Train O/P: Epoch [2/5], Step [350/6000], Loss: 0.0170\n",
      "Train O/P: Epoch [2/5], Step [360/6000], Loss: 0.0786\n",
      "Train O/P: Epoch [2/5], Step [370/6000], Loss: 0.0354\n",
      "Train O/P: Epoch [2/5], Step [380/6000], Loss: 0.0133\n",
      "Train O/P: Epoch [2/5], Step [390/6000], Loss: 0.2671\n",
      "Train O/P: Epoch [2/5], Step [400/6000], Loss: 0.0361\n",
      "Train O/P: Epoch [2/5], Step [410/6000], Loss: 0.1486\n",
      "Train O/P: Epoch [2/5], Step [420/6000], Loss: 0.0195\n",
      "Train O/P: Epoch [2/5], Step [430/6000], Loss: 0.1346\n",
      "Train O/P: Epoch [2/5], Step [440/6000], Loss: 0.0164\n",
      "Train O/P: Epoch [2/5], Step [450/6000], Loss: 0.1036\n",
      "Train O/P: Epoch [2/5], Step [460/6000], Loss: 0.0627\n",
      "Train O/P: Epoch [2/5], Step [470/6000], Loss: 0.0225\n",
      "Train O/P: Epoch [2/5], Step [480/6000], Loss: 0.0212\n",
      "Train O/P: Epoch [2/5], Step [490/6000], Loss: 0.0291\n",
      "Train O/P: Epoch [2/5], Step [500/6000], Loss: 0.0171\n",
      "Train O/P: Epoch [2/5], Step [510/6000], Loss: 0.0338\n",
      "Train O/P: Epoch [2/5], Step [520/6000], Loss: 0.0876\n",
      "Train O/P: Epoch [2/5], Step [530/6000], Loss: 0.0814\n",
      "Train O/P: Epoch [2/5], Step [540/6000], Loss: 0.3586\n",
      "Train O/P: Epoch [2/5], Step [550/6000], Loss: 0.3106\n",
      "Train O/P: Epoch [2/5], Step [560/6000], Loss: 0.0314\n",
      "Train O/P: Epoch [2/5], Step [570/6000], Loss: 0.0649\n",
      "Train O/P: Epoch [2/5], Step [580/6000], Loss: 0.0859\n",
      "Train O/P: Epoch [2/5], Step [590/6000], Loss: 0.0705\n",
      "Train O/P: Epoch [2/5], Step [600/6000], Loss: 0.0459\n",
      "Train O/P: Epoch [2/5], Step [610/6000], Loss: 0.4711\n",
      "Train O/P: Epoch [2/5], Step [620/6000], Loss: 0.0854\n",
      "Train O/P: Epoch [2/5], Step [630/6000], Loss: 0.2765\n",
      "Train O/P: Epoch [2/5], Step [640/6000], Loss: 0.0911\n",
      "Train O/P: Epoch [2/5], Step [650/6000], Loss: 0.0282\n",
      "Train O/P: Epoch [2/5], Step [660/6000], Loss: 0.5716\n",
      "Train O/P: Epoch [2/5], Step [670/6000], Loss: 0.4597\n",
      "Train O/P: Epoch [2/5], Step [680/6000], Loss: 0.0961\n",
      "Train O/P: Epoch [2/5], Step [690/6000], Loss: 0.0211\n",
      "Train O/P: Epoch [2/5], Step [700/6000], Loss: 0.1322\n",
      "Train O/P: Epoch [2/5], Step [710/6000], Loss: 0.2677\n",
      "Train O/P: Epoch [2/5], Step [720/6000], Loss: 0.1754\n",
      "Train O/P: Epoch [2/5], Step [730/6000], Loss: 0.0204\n",
      "Train O/P: Epoch [2/5], Step [740/6000], Loss: 0.0438\n",
      "Train O/P: Epoch [2/5], Step [750/6000], Loss: 0.0135\n",
      "Train O/P: Epoch [2/5], Step [760/6000], Loss: 0.0458\n",
      "Train O/P: Epoch [2/5], Step [770/6000], Loss: 0.2005\n",
      "Train O/P: Epoch [2/5], Step [780/6000], Loss: 0.0917\n",
      "Train O/P: Epoch [2/5], Step [790/6000], Loss: 0.0055\n",
      "Train O/P: Epoch [2/5], Step [800/6000], Loss: 0.2220\n",
      "Train O/P: Epoch [2/5], Step [810/6000], Loss: 0.0704\n",
      "Train O/P: Epoch [2/5], Step [820/6000], Loss: 0.3332\n",
      "Train O/P: Epoch [2/5], Step [830/6000], Loss: 0.0483\n",
      "Train O/P: Epoch [2/5], Step [840/6000], Loss: 0.1460\n",
      "Train O/P: Epoch [2/5], Step [850/6000], Loss: 0.2883\n",
      "Train O/P: Epoch [2/5], Step [860/6000], Loss: 0.0974\n",
      "Train O/P: Epoch [2/5], Step [870/6000], Loss: 0.0804\n",
      "Train O/P: Epoch [2/5], Step [880/6000], Loss: 0.2105\n",
      "Train O/P: Epoch [2/5], Step [890/6000], Loss: 0.4618\n",
      "Train O/P: Epoch [2/5], Step [900/6000], Loss: 0.0892\n",
      "Train O/P: Epoch [2/5], Step [910/6000], Loss: 0.0568\n",
      "Train O/P: Epoch [2/5], Step [920/6000], Loss: 0.0415\n",
      "Train O/P: Epoch [2/5], Step [930/6000], Loss: 0.0169\n",
      "Train O/P: Epoch [2/5], Step [940/6000], Loss: 0.0090\n",
      "Train O/P: Epoch [2/5], Step [950/6000], Loss: 0.0640\n",
      "Train O/P: Epoch [2/5], Step [960/6000], Loss: 0.0161\n",
      "Train O/P: Epoch [2/5], Step [970/6000], Loss: 0.1243\n",
      "Train O/P: Epoch [2/5], Step [980/6000], Loss: 0.0210\n",
      "Train O/P: Epoch [2/5], Step [990/6000], Loss: 0.0191\n",
      "Train O/P: Epoch [2/5], Step [1000/6000], Loss: 0.0335\n",
      "Train O/P: Epoch [2/5], Step [1010/6000], Loss: 0.0524\n",
      "Train O/P: Epoch [2/5], Step [1020/6000], Loss: 0.2661\n",
      "Train O/P: Epoch [2/5], Step [1030/6000], Loss: 0.1568\n",
      "Train O/P: Epoch [2/5], Step [1040/6000], Loss: 0.2870\n",
      "Train O/P: Epoch [2/5], Step [1050/6000], Loss: 0.0061\n",
      "Train O/P: Epoch [2/5], Step [1060/6000], Loss: 0.1519\n",
      "Train O/P: Epoch [2/5], Step [1070/6000], Loss: 0.1491\n",
      "Train O/P: Epoch [2/5], Step [1080/6000], Loss: 0.0370\n",
      "Train O/P: Epoch [2/5], Step [1090/6000], Loss: 0.0341\n",
      "Train O/P: Epoch [2/5], Step [1100/6000], Loss: 0.0303\n",
      "Train O/P: Epoch [2/5], Step [1110/6000], Loss: 0.0861\n",
      "Train O/P: Epoch [2/5], Step [1120/6000], Loss: 0.3294\n",
      "Train O/P: Epoch [2/5], Step [1130/6000], Loss: 0.0155\n",
      "Train O/P: Epoch [2/5], Step [1140/6000], Loss: 0.0539\n",
      "Train O/P: Epoch [2/5], Step [1150/6000], Loss: 0.1452\n",
      "Train O/P: Epoch [2/5], Step [1160/6000], Loss: 0.0132\n",
      "Train O/P: Epoch [2/5], Step [1170/6000], Loss: 0.0612\n",
      "Train O/P: Epoch [2/5], Step [1180/6000], Loss: 0.0063\n",
      "Train O/P: Epoch [2/5], Step [1190/6000], Loss: 0.0137\n",
      "Train O/P: Epoch [2/5], Step [1200/6000], Loss: 0.0302\n",
      "Train O/P: Epoch [2/5], Step [1210/6000], Loss: 0.0970\n",
      "Train O/P: Epoch [2/5], Step [1220/6000], Loss: 0.0480\n",
      "Train O/P: Epoch [2/5], Step [1230/6000], Loss: 0.0622\n",
      "Train O/P: Epoch [2/5], Step [1240/6000], Loss: 0.2809\n",
      "Train O/P: Epoch [2/5], Step [1250/6000], Loss: 0.0306\n",
      "Train O/P: Epoch [2/5], Step [1260/6000], Loss: 0.2439\n",
      "Train O/P: Epoch [2/5], Step [1270/6000], Loss: 0.2672\n",
      "Train O/P: Epoch [2/5], Step [1280/6000], Loss: 0.2564\n",
      "Train O/P: Epoch [2/5], Step [1290/6000], Loss: 0.2408\n",
      "Train O/P: Epoch [2/5], Step [1300/6000], Loss: 0.0188\n",
      "Train O/P: Epoch [2/5], Step [1310/6000], Loss: 0.4914\n",
      "Train O/P: Epoch [2/5], Step [1320/6000], Loss: 0.0600\n",
      "Train O/P: Epoch [2/5], Step [1330/6000], Loss: 0.0226\n",
      "Train O/P: Epoch [2/5], Step [1340/6000], Loss: 0.2832\n",
      "Train O/P: Epoch [2/5], Step [1350/6000], Loss: 0.2459\n",
      "Train O/P: Epoch [2/5], Step [1360/6000], Loss: 0.1237\n",
      "Train O/P: Epoch [2/5], Step [1370/6000], Loss: 0.0549\n",
      "Train O/P: Epoch [2/5], Step [1380/6000], Loss: 0.7905\n",
      "Train O/P: Epoch [2/5], Step [1390/6000], Loss: 0.0197\n",
      "Train O/P: Epoch [2/5], Step [1400/6000], Loss: 0.0981\n",
      "Train O/P: Epoch [2/5], Step [1410/6000], Loss: 0.1349\n",
      "Train O/P: Epoch [2/5], Step [1420/6000], Loss: 0.0699\n",
      "Train O/P: Epoch [2/5], Step [1430/6000], Loss: 0.1044\n",
      "Train O/P: Epoch [2/5], Step [1440/6000], Loss: 0.0957\n",
      "Train O/P: Epoch [2/5], Step [1450/6000], Loss: 0.2506\n",
      "Train O/P: Epoch [2/5], Step [1460/6000], Loss: 0.0637\n",
      "Train O/P: Epoch [2/5], Step [1470/6000], Loss: 0.0366\n",
      "Train O/P: Epoch [2/5], Step [1480/6000], Loss: 0.0086\n",
      "Train O/P: Epoch [2/5], Step [1490/6000], Loss: 0.2673\n",
      "Train O/P: Epoch [2/5], Step [1500/6000], Loss: 0.2210\n",
      "Train O/P: Epoch [2/5], Step [1510/6000], Loss: 0.0831\n",
      "Train O/P: Epoch [2/5], Step [1520/6000], Loss: 0.0423\n",
      "Train O/P: Epoch [2/5], Step [1530/6000], Loss: 0.0075\n",
      "Train O/P: Epoch [2/5], Step [1540/6000], Loss: 0.2741\n",
      "Train O/P: Epoch [2/5], Step [1550/6000], Loss: 0.1907\n",
      "Train O/P: Epoch [2/5], Step [1560/6000], Loss: 0.0365\n",
      "Train O/P: Epoch [2/5], Step [1570/6000], Loss: 0.2927\n",
      "Train O/P: Epoch [2/5], Step [1580/6000], Loss: 0.6631\n",
      "Train O/P: Epoch [2/5], Step [1590/6000], Loss: 0.0132\n",
      "Train O/P: Epoch [2/5], Step [1600/6000], Loss: 0.0080\n",
      "Train O/P: Epoch [2/5], Step [1610/6000], Loss: 0.3364\n",
      "Train O/P: Epoch [2/5], Step [1620/6000], Loss: 0.0115\n",
      "Train O/P: Epoch [2/5], Step [1630/6000], Loss: 0.5310\n",
      "Train O/P: Epoch [2/5], Step [1640/6000], Loss: 0.0145\n",
      "Train O/P: Epoch [2/5], Step [1650/6000], Loss: 0.0567\n",
      "Train O/P: Epoch [2/5], Step [1660/6000], Loss: 0.0136\n",
      "Train O/P: Epoch [2/5], Step [1670/6000], Loss: 0.1093\n",
      "Train O/P: Epoch [2/5], Step [1680/6000], Loss: 0.0577\n",
      "Train O/P: Epoch [2/5], Step [1690/6000], Loss: 0.2565\n",
      "Train O/P: Epoch [2/5], Step [1700/6000], Loss: 0.2164\n",
      "Train O/P: Epoch [2/5], Step [1710/6000], Loss: 0.0128\n",
      "Train O/P: Epoch [2/5], Step [1720/6000], Loss: 0.0497\n",
      "Train O/P: Epoch [2/5], Step [1730/6000], Loss: 0.0526\n",
      "Train O/P: Epoch [2/5], Step [1740/6000], Loss: 0.0944\n",
      "Train O/P: Epoch [2/5], Step [1750/6000], Loss: 0.0138\n",
      "Train O/P: Epoch [2/5], Step [1760/6000], Loss: 0.3657\n",
      "Train O/P: Epoch [2/5], Step [1770/6000], Loss: 0.2273\n",
      "Train O/P: Epoch [2/5], Step [1780/6000], Loss: 0.0100\n",
      "Train O/P: Epoch [2/5], Step [1790/6000], Loss: 0.0933\n",
      "Train O/P: Epoch [2/5], Step [1800/6000], Loss: 0.3020\n",
      "Train O/P: Epoch [2/5], Step [1810/6000], Loss: 0.0508\n",
      "Train O/P: Epoch [2/5], Step [1820/6000], Loss: 0.0114\n",
      "Train O/P: Epoch [2/5], Step [1830/6000], Loss: 0.0151\n",
      "Train O/P: Epoch [2/5], Step [1840/6000], Loss: 0.4028\n",
      "Train O/P: Epoch [2/5], Step [1850/6000], Loss: 0.2823\n",
      "Train O/P: Epoch [2/5], Step [1860/6000], Loss: 0.0196\n",
      "Train O/P: Epoch [2/5], Step [1870/6000], Loss: 0.0217\n",
      "Train O/P: Epoch [2/5], Step [1880/6000], Loss: 0.0270\n",
      "Train O/P: Epoch [2/5], Step [1890/6000], Loss: 0.2006\n",
      "Train O/P: Epoch [2/5], Step [1900/6000], Loss: 0.0255\n",
      "Train O/P: Epoch [2/5], Step [1910/6000], Loss: 0.0089\n",
      "Train O/P: Epoch [2/5], Step [1920/6000], Loss: 0.2503\n",
      "Train O/P: Epoch [2/5], Step [1930/6000], Loss: 0.2277\n",
      "Train O/P: Epoch [2/5], Step [1940/6000], Loss: 0.1567\n",
      "Train O/P: Epoch [2/5], Step [1950/6000], Loss: 0.0295\n",
      "Train O/P: Epoch [2/5], Step [1960/6000], Loss: 0.1237\n",
      "Train O/P: Epoch [2/5], Step [1970/6000], Loss: 0.0313\n",
      "Train O/P: Epoch [2/5], Step [1980/6000], Loss: 0.1749\n",
      "Train O/P: Epoch [2/5], Step [1990/6000], Loss: 0.1886\n",
      "Train O/P: Epoch [2/5], Step [2000/6000], Loss: 0.2857\n",
      "Train O/P: Epoch [2/5], Step [2010/6000], Loss: 0.5658\n",
      "Train O/P: Epoch [2/5], Step [2020/6000], Loss: 0.1445\n",
      "Train O/P: Epoch [2/5], Step [2030/6000], Loss: 0.0626\n",
      "Train O/P: Epoch [2/5], Step [2040/6000], Loss: 0.2563\n",
      "Train O/P: Epoch [2/5], Step [2050/6000], Loss: 0.0175\n",
      "Train O/P: Epoch [2/5], Step [2060/6000], Loss: 0.1683\n",
      "Train O/P: Epoch [2/5], Step [2070/6000], Loss: 0.2485\n",
      "Train O/P: Epoch [2/5], Step [2080/6000], Loss: 0.2531\n",
      "Train O/P: Epoch [2/5], Step [2090/6000], Loss: 0.1803\n",
      "Train O/P: Epoch [2/5], Step [2100/6000], Loss: 0.0841\n",
      "Train O/P: Epoch [2/5], Step [2110/6000], Loss: 0.0541\n",
      "Train O/P: Epoch [2/5], Step [2120/6000], Loss: 0.4016\n",
      "Train O/P: Epoch [2/5], Step [2130/6000], Loss: 0.3382\n",
      "Train O/P: Epoch [2/5], Step [2140/6000], Loss: 0.0748\n",
      "Train O/P: Epoch [2/5], Step [2150/6000], Loss: 0.3521\n",
      "Train O/P: Epoch [2/5], Step [2160/6000], Loss: 0.9591\n",
      "Train O/P: Epoch [2/5], Step [2170/6000], Loss: 0.3168\n",
      "Train O/P: Epoch [2/5], Step [2180/6000], Loss: 0.0659\n",
      "Train O/P: Epoch [2/5], Step [2190/6000], Loss: 0.2434\n",
      "Train O/P: Epoch [2/5], Step [2200/6000], Loss: 0.0200\n",
      "Train O/P: Epoch [2/5], Step [2210/6000], Loss: 0.0304\n",
      "Train O/P: Epoch [2/5], Step [2220/6000], Loss: 0.1866\n",
      "Train O/P: Epoch [2/5], Step [2230/6000], Loss: 0.0384\n",
      "Train O/P: Epoch [2/5], Step [2240/6000], Loss: 0.0821\n",
      "Train O/P: Epoch [2/5], Step [2250/6000], Loss: 0.0623\n",
      "Train O/P: Epoch [2/5], Step [2260/6000], Loss: 0.0149\n",
      "Train O/P: Epoch [2/5], Step [2270/6000], Loss: 0.2196\n",
      "Train O/P: Epoch [2/5], Step [2280/6000], Loss: 0.1364\n",
      "Train O/P: Epoch [2/5], Step [2290/6000], Loss: 0.0984\n",
      "Train O/P: Epoch [2/5], Step [2300/6000], Loss: 0.0432\n",
      "Train O/P: Epoch [2/5], Step [2310/6000], Loss: 0.0319\n",
      "Train O/P: Epoch [2/5], Step [2320/6000], Loss: 0.2913\n",
      "Train O/P: Epoch [2/5], Step [2330/6000], Loss: 0.1794\n",
      "Train O/P: Epoch [2/5], Step [2340/6000], Loss: 0.0355\n",
      "Train O/P: Epoch [2/5], Step [2350/6000], Loss: 0.0184\n",
      "Train O/P: Epoch [2/5], Step [2360/6000], Loss: 0.0369\n",
      "Train O/P: Epoch [2/5], Step [2370/6000], Loss: 0.3824\n",
      "Train O/P: Epoch [2/5], Step [2380/6000], Loss: 0.1790\n",
      "Train O/P: Epoch [2/5], Step [2390/6000], Loss: 0.7364\n",
      "Train O/P: Epoch [2/5], Step [2400/6000], Loss: 0.0601\n",
      "Train O/P: Epoch [2/5], Step [2410/6000], Loss: 0.0426\n",
      "Train O/P: Epoch [2/5], Step [2420/6000], Loss: 0.0362\n",
      "Train O/P: Epoch [2/5], Step [2430/6000], Loss: 0.0915\n",
      "Train O/P: Epoch [2/5], Step [2440/6000], Loss: 0.0532\n",
      "Train O/P: Epoch [2/5], Step [2450/6000], Loss: 1.7732\n",
      "Train O/P: Epoch [2/5], Step [2460/6000], Loss: 0.1017\n",
      "Train O/P: Epoch [2/5], Step [2470/6000], Loss: 0.0446\n",
      "Train O/P: Epoch [2/5], Step [2480/6000], Loss: 0.0128\n",
      "Train O/P: Epoch [2/5], Step [2490/6000], Loss: 0.1382\n",
      "Train O/P: Epoch [2/5], Step [2500/6000], Loss: 0.0496\n",
      "Train O/P: Epoch [2/5], Step [2510/6000], Loss: 0.1398\n",
      "Train O/P: Epoch [2/5], Step [2520/6000], Loss: 0.0330\n",
      "Train O/P: Epoch [2/5], Step [2530/6000], Loss: 0.5611\n",
      "Train O/P: Epoch [2/5], Step [2540/6000], Loss: 0.0289\n",
      "Train O/P: Epoch [2/5], Step [2550/6000], Loss: 0.0193\n",
      "Train O/P: Epoch [2/5], Step [2560/6000], Loss: 0.0328\n",
      "Train O/P: Epoch [2/5], Step [2570/6000], Loss: 0.3382\n",
      "Train O/P: Epoch [2/5], Step [2580/6000], Loss: 0.1765\n",
      "Train O/P: Epoch [2/5], Step [2590/6000], Loss: 0.0142\n",
      "Train O/P: Epoch [2/5], Step [2600/6000], Loss: 0.0923\n",
      "Train O/P: Epoch [2/5], Step [2610/6000], Loss: 0.0700\n",
      "Train O/P: Epoch [2/5], Step [2620/6000], Loss: 0.0751\n",
      "Train O/P: Epoch [2/5], Step [2630/6000], Loss: 0.0664\n",
      "Train O/P: Epoch [2/5], Step [2640/6000], Loss: 0.0233\n",
      "Train O/P: Epoch [2/5], Step [2650/6000], Loss: 0.0531\n",
      "Train O/P: Epoch [2/5], Step [2660/6000], Loss: 0.0070\n",
      "Train O/P: Epoch [2/5], Step [2670/6000], Loss: 0.0123\n",
      "Train O/P: Epoch [2/5], Step [2680/6000], Loss: 0.0625\n",
      "Train O/P: Epoch [2/5], Step [2690/6000], Loss: 0.0712\n",
      "Train O/P: Epoch [2/5], Step [2700/6000], Loss: 0.0152\n",
      "Train O/P: Epoch [2/5], Step [2710/6000], Loss: 0.0514\n",
      "Train O/P: Epoch [2/5], Step [2720/6000], Loss: 0.0442\n",
      "Train O/P: Epoch [2/5], Step [2730/6000], Loss: 0.0321\n",
      "Train O/P: Epoch [2/5], Step [2740/6000], Loss: 0.0503\n",
      "Train O/P: Epoch [2/5], Step [2750/6000], Loss: 0.0218\n",
      "Train O/P: Epoch [2/5], Step [2760/6000], Loss: 0.0527\n",
      "Train O/P: Epoch [2/5], Step [2770/6000], Loss: 0.4825\n",
      "Train O/P: Epoch [2/5], Step [2780/6000], Loss: 0.1522\n",
      "Train O/P: Epoch [2/5], Step [2790/6000], Loss: 0.0209\n",
      "Train O/P: Epoch [2/5], Step [2800/6000], Loss: 0.0099\n",
      "Train O/P: Epoch [2/5], Step [2810/6000], Loss: 0.0815\n",
      "Train O/P: Epoch [2/5], Step [2820/6000], Loss: 0.0039\n",
      "Train O/P: Epoch [2/5], Step [2830/6000], Loss: 0.2349\n",
      "Train O/P: Epoch [2/5], Step [2840/6000], Loss: 0.7629\n",
      "Train O/P: Epoch [2/5], Step [2850/6000], Loss: 0.0347\n",
      "Train O/P: Epoch [2/5], Step [2860/6000], Loss: 0.1146\n",
      "Train O/P: Epoch [2/5], Step [2870/6000], Loss: 0.1872\n",
      "Train O/P: Epoch [2/5], Step [2880/6000], Loss: 0.0358\n",
      "Train O/P: Epoch [2/5], Step [2890/6000], Loss: 0.0774\n",
      "Train O/P: Epoch [2/5], Step [2900/6000], Loss: 0.4299\n",
      "Train O/P: Epoch [2/5], Step [2910/6000], Loss: 0.0380\n",
      "Train O/P: Epoch [2/5], Step [2920/6000], Loss: 0.0265\n",
      "Train O/P: Epoch [2/5], Step [2930/6000], Loss: 0.0204\n",
      "Train O/P: Epoch [2/5], Step [2940/6000], Loss: 0.0687\n",
      "Train O/P: Epoch [2/5], Step [2950/6000], Loss: 0.2844\n",
      "Train O/P: Epoch [2/5], Step [2960/6000], Loss: 0.2216\n",
      "Train O/P: Epoch [2/5], Step [2970/6000], Loss: 0.1383\n",
      "Train O/P: Epoch [2/5], Step [2980/6000], Loss: 0.0764\n",
      "Train O/P: Epoch [2/5], Step [2990/6000], Loss: 0.2161\n",
      "Train O/P: Epoch [2/5], Step [3000/6000], Loss: 0.2951\n",
      "Train O/P: Epoch [2/5], Step [3010/6000], Loss: 0.0281\n",
      "Train O/P: Epoch [2/5], Step [3020/6000], Loss: 0.4554\n",
      "Train O/P: Epoch [2/5], Step [3030/6000], Loss: 0.0475\n",
      "Train O/P: Epoch [2/5], Step [3040/6000], Loss: 0.0188\n",
      "Train O/P: Epoch [2/5], Step [3050/6000], Loss: 0.3212\n",
      "Train O/P: Epoch [2/5], Step [3060/6000], Loss: 0.0540\n",
      "Train O/P: Epoch [2/5], Step [3070/6000], Loss: 0.0273\n",
      "Train O/P: Epoch [2/5], Step [3080/6000], Loss: 0.0509\n",
      "Train O/P: Epoch [2/5], Step [3090/6000], Loss: 0.0544\n",
      "Train O/P: Epoch [2/5], Step [3100/6000], Loss: 0.0632\n",
      "Train O/P: Epoch [2/5], Step [3110/6000], Loss: 0.0105\n",
      "Train O/P: Epoch [2/5], Step [3120/6000], Loss: 0.1758\n",
      "Train O/P: Epoch [2/5], Step [3130/6000], Loss: 0.0679\n",
      "Train O/P: Epoch [2/5], Step [3140/6000], Loss: 0.2951\n",
      "Train O/P: Epoch [2/5], Step [3150/6000], Loss: 0.1253\n",
      "Train O/P: Epoch [2/5], Step [3160/6000], Loss: 0.1343\n",
      "Train O/P: Epoch [2/5], Step [3170/6000], Loss: 0.0431\n",
      "Train O/P: Epoch [2/5], Step [3180/6000], Loss: 0.0342\n",
      "Train O/P: Epoch [2/5], Step [3190/6000], Loss: 0.0513\n",
      "Train O/P: Epoch [2/5], Step [3200/6000], Loss: 0.1151\n",
      "Train O/P: Epoch [2/5], Step [3210/6000], Loss: 0.0714\n",
      "Train O/P: Epoch [2/5], Step [3220/6000], Loss: 0.0490\n",
      "Train O/P: Epoch [2/5], Step [3230/6000], Loss: 0.0821\n",
      "Train O/P: Epoch [2/5], Step [3240/6000], Loss: 0.2539\n",
      "Train O/P: Epoch [2/5], Step [3250/6000], Loss: 0.1499\n",
      "Train O/P: Epoch [2/5], Step [3260/6000], Loss: 0.1941\n",
      "Train O/P: Epoch [2/5], Step [3270/6000], Loss: 0.0414\n",
      "Train O/P: Epoch [2/5], Step [3280/6000], Loss: 0.2057\n",
      "Train O/P: Epoch [2/5], Step [3290/6000], Loss: 0.0379\n",
      "Train O/P: Epoch [2/5], Step [3300/6000], Loss: 0.1403\n",
      "Train O/P: Epoch [2/5], Step [3310/6000], Loss: 0.1905\n",
      "Train O/P: Epoch [2/5], Step [3320/6000], Loss: 0.3904\n",
      "Train O/P: Epoch [2/5], Step [3330/6000], Loss: 0.0493\n",
      "Train O/P: Epoch [2/5], Step [3340/6000], Loss: 0.0425\n",
      "Train O/P: Epoch [2/5], Step [3350/6000], Loss: 0.0294\n",
      "Train O/P: Epoch [2/5], Step [3360/6000], Loss: 0.1395\n",
      "Train O/P: Epoch [2/5], Step [3370/6000], Loss: 0.1832\n",
      "Train O/P: Epoch [2/5], Step [3380/6000], Loss: 0.0252\n",
      "Train O/P: Epoch [2/5], Step [3390/6000], Loss: 0.0609\n",
      "Train O/P: Epoch [2/5], Step [3400/6000], Loss: 0.1915\n",
      "Train O/P: Epoch [2/5], Step [3410/6000], Loss: 0.2137\n",
      "Train O/P: Epoch [2/5], Step [3420/6000], Loss: 0.0467\n",
      "Train O/P: Epoch [2/5], Step [3430/6000], Loss: 0.0265\n",
      "Train O/P: Epoch [2/5], Step [3440/6000], Loss: 0.0192\n",
      "Train O/P: Epoch [2/5], Step [3450/6000], Loss: 0.2193\n",
      "Train O/P: Epoch [2/5], Step [3460/6000], Loss: 0.3367\n",
      "Train O/P: Epoch [2/5], Step [3470/6000], Loss: 0.4736\n",
      "Train O/P: Epoch [2/5], Step [3480/6000], Loss: 0.2419\n",
      "Train O/P: Epoch [2/5], Step [3490/6000], Loss: 0.4173\n",
      "Train O/P: Epoch [2/5], Step [3500/6000], Loss: 0.0081\n",
      "Train O/P: Epoch [2/5], Step [3510/6000], Loss: 0.0094\n",
      "Train O/P: Epoch [2/5], Step [3520/6000], Loss: 0.1502\n",
      "Train O/P: Epoch [2/5], Step [3530/6000], Loss: 0.0624\n",
      "Train O/P: Epoch [2/5], Step [3540/6000], Loss: 0.0789\n",
      "Train O/P: Epoch [2/5], Step [3550/6000], Loss: 0.0360\n",
      "Train O/P: Epoch [2/5], Step [3560/6000], Loss: 0.1482\n",
      "Train O/P: Epoch [2/5], Step [3570/6000], Loss: 0.0247\n",
      "Train O/P: Epoch [2/5], Step [3580/6000], Loss: 0.0237\n",
      "Train O/P: Epoch [2/5], Step [3590/6000], Loss: 0.0828\n",
      "Train O/P: Epoch [2/5], Step [3600/6000], Loss: 0.0054\n",
      "Train O/P: Epoch [2/5], Step [3610/6000], Loss: 0.0723\n",
      "Train O/P: Epoch [2/5], Step [3620/6000], Loss: 0.0638\n",
      "Train O/P: Epoch [2/5], Step [3630/6000], Loss: 0.3830\n",
      "Train O/P: Epoch [2/5], Step [3640/6000], Loss: 0.0114\n",
      "Train O/P: Epoch [2/5], Step [3650/6000], Loss: 0.0260\n",
      "Train O/P: Epoch [2/5], Step [3660/6000], Loss: 0.0113\n",
      "Train O/P: Epoch [2/5], Step [3670/6000], Loss: 0.0828\n",
      "Train O/P: Epoch [2/5], Step [3680/6000], Loss: 0.3900\n",
      "Train O/P: Epoch [2/5], Step [3690/6000], Loss: 0.0341\n",
      "Train O/P: Epoch [2/5], Step [3700/6000], Loss: 0.0217\n",
      "Train O/P: Epoch [2/5], Step [3710/6000], Loss: 0.1068\n",
      "Train O/P: Epoch [2/5], Step [3720/6000], Loss: 0.0378\n",
      "Train O/P: Epoch [2/5], Step [3730/6000], Loss: 0.1656\n",
      "Train O/P: Epoch [2/5], Step [3740/6000], Loss: 0.0502\n",
      "Train O/P: Epoch [2/5], Step [3750/6000], Loss: 0.0045\n",
      "Train O/P: Epoch [2/5], Step [3760/6000], Loss: 0.0431\n",
      "Train O/P: Epoch [2/5], Step [3770/6000], Loss: 0.0374\n",
      "Train O/P: Epoch [2/5], Step [3780/6000], Loss: 0.0231\n",
      "Train O/P: Epoch [2/5], Step [3790/6000], Loss: 0.0414\n",
      "Train O/P: Epoch [2/5], Step [3800/6000], Loss: 0.0409\n",
      "Train O/P: Epoch [2/5], Step [3810/6000], Loss: 0.0509\n",
      "Train O/P: Epoch [2/5], Step [3820/6000], Loss: 0.0494\n",
      "Train O/P: Epoch [2/5], Step [3830/6000], Loss: 0.0355\n",
      "Train O/P: Epoch [2/5], Step [3840/6000], Loss: 0.1210\n",
      "Train O/P: Epoch [2/5], Step [3850/6000], Loss: 0.0527\n",
      "Train O/P: Epoch [2/5], Step [3860/6000], Loss: 0.1396\n",
      "Train O/P: Epoch [2/5], Step [3870/6000], Loss: 0.0356\n",
      "Train O/P: Epoch [2/5], Step [3880/6000], Loss: 0.0152\n",
      "Train O/P: Epoch [2/5], Step [3890/6000], Loss: 0.2768\n",
      "Train O/P: Epoch [2/5], Step [3900/6000], Loss: 0.0935\n",
      "Train O/P: Epoch [2/5], Step [3910/6000], Loss: 0.2041\n",
      "Train O/P: Epoch [2/5], Step [3920/6000], Loss: 0.0720\n",
      "Train O/P: Epoch [2/5], Step [3930/6000], Loss: 0.0255\n",
      "Train O/P: Epoch [2/5], Step [3940/6000], Loss: 0.1411\n",
      "Train O/P: Epoch [2/5], Step [3950/6000], Loss: 0.0149\n",
      "Train O/P: Epoch [2/5], Step [3960/6000], Loss: 0.0262\n",
      "Train O/P: Epoch [2/5], Step [3970/6000], Loss: 0.0466\n",
      "Train O/P: Epoch [2/5], Step [3980/6000], Loss: 0.1501\n",
      "Train O/P: Epoch [2/5], Step [3990/6000], Loss: 0.0632\n",
      "Train O/P: Epoch [2/5], Step [4000/6000], Loss: 0.0104\n",
      "Train O/P: Epoch [2/5], Step [4010/6000], Loss: 0.0052\n",
      "Train O/P: Epoch [2/5], Step [4020/6000], Loss: 0.0095\n",
      "Train O/P: Epoch [2/5], Step [4030/6000], Loss: 0.1109\n",
      "Train O/P: Epoch [2/5], Step [4040/6000], Loss: 0.0264\n",
      "Train O/P: Epoch [2/5], Step [4050/6000], Loss: 0.4475\n",
      "Train O/P: Epoch [2/5], Step [4060/6000], Loss: 0.3587\n",
      "Train O/P: Epoch [2/5], Step [4070/6000], Loss: 0.0569\n",
      "Train O/P: Epoch [2/5], Step [4080/6000], Loss: 0.0743\n",
      "Train O/P: Epoch [2/5], Step [4090/6000], Loss: 0.0283\n",
      "Train O/P: Epoch [2/5], Step [4100/6000], Loss: 0.0049\n",
      "Train O/P: Epoch [2/5], Step [4110/6000], Loss: 0.2329\n",
      "Train O/P: Epoch [2/5], Step [4120/6000], Loss: 0.3139\n",
      "Train O/P: Epoch [2/5], Step [4130/6000], Loss: 0.0844\n",
      "Train O/P: Epoch [2/5], Step [4140/6000], Loss: 0.1028\n",
      "Train O/P: Epoch [2/5], Step [4150/6000], Loss: 0.1024\n",
      "Train O/P: Epoch [2/5], Step [4160/6000], Loss: 0.3382\n",
      "Train O/P: Epoch [2/5], Step [4170/6000], Loss: 0.6050\n",
      "Train O/P: Epoch [2/5], Step [4180/6000], Loss: 0.1302\n",
      "Train O/P: Epoch [2/5], Step [4190/6000], Loss: 0.0807\n",
      "Train O/P: Epoch [2/5], Step [4200/6000], Loss: 0.1893\n",
      "Train O/P: Epoch [2/5], Step [4210/6000], Loss: 0.0857\n",
      "Train O/P: Epoch [2/5], Step [4220/6000], Loss: 0.2736\n",
      "Train O/P: Epoch [2/5], Step [4230/6000], Loss: 0.0385\n",
      "Train O/P: Epoch [2/5], Step [4240/6000], Loss: 0.3387\n",
      "Train O/P: Epoch [2/5], Step [4250/6000], Loss: 0.1518\n",
      "Train O/P: Epoch [2/5], Step [4260/6000], Loss: 0.0351\n",
      "Train O/P: Epoch [2/5], Step [4270/6000], Loss: 0.0237\n",
      "Train O/P: Epoch [2/5], Step [4280/6000], Loss: 0.0302\n",
      "Train O/P: Epoch [2/5], Step [4290/6000], Loss: 0.1110\n",
      "Train O/P: Epoch [2/5], Step [4300/6000], Loss: 0.1102\n",
      "Train O/P: Epoch [2/5], Step [4310/6000], Loss: 0.0273\n",
      "Train O/P: Epoch [2/5], Step [4320/6000], Loss: 0.3035\n",
      "Train O/P: Epoch [2/5], Step [4330/6000], Loss: 0.0629\n",
      "Train O/P: Epoch [2/5], Step [4340/6000], Loss: 0.0025\n",
      "Train O/P: Epoch [2/5], Step [4350/6000], Loss: 0.0441\n",
      "Train O/P: Epoch [2/5], Step [4360/6000], Loss: 0.0365\n",
      "Train O/P: Epoch [2/5], Step [4370/6000], Loss: 0.2141\n",
      "Train O/P: Epoch [2/5], Step [4380/6000], Loss: 0.0479\n",
      "Train O/P: Epoch [2/5], Step [4390/6000], Loss: 0.1270\n",
      "Train O/P: Epoch [2/5], Step [4400/6000], Loss: 0.2957\n",
      "Train O/P: Epoch [2/5], Step [4410/6000], Loss: 0.0373\n",
      "Train O/P: Epoch [2/5], Step [4420/6000], Loss: 0.0470\n",
      "Train O/P: Epoch [2/5], Step [4430/6000], Loss: 0.2649\n",
      "Train O/P: Epoch [2/5], Step [4440/6000], Loss: 0.0615\n",
      "Train O/P: Epoch [2/5], Step [4450/6000], Loss: 0.1784\n",
      "Train O/P: Epoch [2/5], Step [4460/6000], Loss: 0.0514\n",
      "Train O/P: Epoch [2/5], Step [4470/6000], Loss: 0.0303\n",
      "Train O/P: Epoch [2/5], Step [4480/6000], Loss: 0.2907\n",
      "Train O/P: Epoch [2/5], Step [4490/6000], Loss: 0.0518\n",
      "Train O/P: Epoch [2/5], Step [4500/6000], Loss: 0.0342\n",
      "Train O/P: Epoch [2/5], Step [4510/6000], Loss: 0.0585\n",
      "Train O/P: Epoch [2/5], Step [4520/6000], Loss: 0.0161\n",
      "Train O/P: Epoch [2/5], Step [4530/6000], Loss: 0.0337\n",
      "Train O/P: Epoch [2/5], Step [4540/6000], Loss: 0.0444\n",
      "Train O/P: Epoch [2/5], Step [4550/6000], Loss: 0.3734\n",
      "Train O/P: Epoch [2/5], Step [4560/6000], Loss: 0.1387\n",
      "Train O/P: Epoch [2/5], Step [4570/6000], Loss: 0.0322\n",
      "Train O/P: Epoch [2/5], Step [4580/6000], Loss: 0.3056\n",
      "Train O/P: Epoch [2/5], Step [4590/6000], Loss: 0.0244\n",
      "Train O/P: Epoch [2/5], Step [4600/6000], Loss: 0.0236\n",
      "Train O/P: Epoch [2/5], Step [4610/6000], Loss: 0.1743\n",
      "Train O/P: Epoch [2/5], Step [4620/6000], Loss: 0.0453\n",
      "Train O/P: Epoch [2/5], Step [4630/6000], Loss: 0.0140\n",
      "Train O/P: Epoch [2/5], Step [4640/6000], Loss: 0.0077\n",
      "Train O/P: Epoch [2/5], Step [4650/6000], Loss: 0.0128\n",
      "Train O/P: Epoch [2/5], Step [4660/6000], Loss: 0.0138\n",
      "Train O/P: Epoch [2/5], Step [4670/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [2/5], Step [4680/6000], Loss: 0.0346\n",
      "Train O/P: Epoch [2/5], Step [4690/6000], Loss: 0.0195\n",
      "Train O/P: Epoch [2/5], Step [4700/6000], Loss: 0.0739\n",
      "Train O/P: Epoch [2/5], Step [4710/6000], Loss: 0.1540\n",
      "Train O/P: Epoch [2/5], Step [4720/6000], Loss: 0.0174\n",
      "Train O/P: Epoch [2/5], Step [4730/6000], Loss: 0.0359\n",
      "Train O/P: Epoch [2/5], Step [4740/6000], Loss: 0.0554\n",
      "Train O/P: Epoch [2/5], Step [4750/6000], Loss: 0.5313\n",
      "Train O/P: Epoch [2/5], Step [4760/6000], Loss: 0.0375\n",
      "Train O/P: Epoch [2/5], Step [4770/6000], Loss: 0.0629\n",
      "Train O/P: Epoch [2/5], Step [4780/6000], Loss: 0.0702\n",
      "Train O/P: Epoch [2/5], Step [4790/6000], Loss: 0.0477\n",
      "Train O/P: Epoch [2/5], Step [4800/6000], Loss: 0.0828\n",
      "Train O/P: Epoch [2/5], Step [4810/6000], Loss: 0.0933\n",
      "Train O/P: Epoch [2/5], Step [4820/6000], Loss: 0.0393\n",
      "Train O/P: Epoch [2/5], Step [4830/6000], Loss: 0.1734\n",
      "Train O/P: Epoch [2/5], Step [4840/6000], Loss: 0.0383\n",
      "Train O/P: Epoch [2/5], Step [4850/6000], Loss: 0.0340\n",
      "Train O/P: Epoch [2/5], Step [4860/6000], Loss: 0.0050\n",
      "Train O/P: Epoch [2/5], Step [4870/6000], Loss: 0.1258\n",
      "Train O/P: Epoch [2/5], Step [4880/6000], Loss: 0.0186\n",
      "Train O/P: Epoch [2/5], Step [4890/6000], Loss: 0.0888\n",
      "Train O/P: Epoch [2/5], Step [4900/6000], Loss: 0.0660\n",
      "Train O/P: Epoch [2/5], Step [4910/6000], Loss: 0.0486\n",
      "Train O/P: Epoch [2/5], Step [4920/6000], Loss: 0.5528\n",
      "Train O/P: Epoch [2/5], Step [4930/6000], Loss: 0.2754\n",
      "Train O/P: Epoch [2/5], Step [4940/6000], Loss: 0.0106\n",
      "Train O/P: Epoch [2/5], Step [4950/6000], Loss: 0.0046\n",
      "Train O/P: Epoch [2/5], Step [4960/6000], Loss: 0.2855\n",
      "Train O/P: Epoch [2/5], Step [4970/6000], Loss: 0.0326\n",
      "Train O/P: Epoch [2/5], Step [4980/6000], Loss: 0.1759\n",
      "Train O/P: Epoch [2/5], Step [4990/6000], Loss: 0.0450\n",
      "Train O/P: Epoch [2/5], Step [5000/6000], Loss: 0.0586\n",
      "Train O/P: Epoch [2/5], Step [5010/6000], Loss: 0.0572\n",
      "Train O/P: Epoch [2/5], Step [5020/6000], Loss: 0.0172\n",
      "Train O/P: Epoch [2/5], Step [5030/6000], Loss: 0.7604\n",
      "Train O/P: Epoch [2/5], Step [5040/6000], Loss: 0.0147\n",
      "Train O/P: Epoch [2/5], Step [5050/6000], Loss: 0.9654\n",
      "Train O/P: Epoch [2/5], Step [5060/6000], Loss: 0.0984\n",
      "Train O/P: Epoch [2/5], Step [5070/6000], Loss: 0.2932\n",
      "Train O/P: Epoch [2/5], Step [5080/6000], Loss: 0.2641\n",
      "Train O/P: Epoch [2/5], Step [5090/6000], Loss: 0.0196\n",
      "Train O/P: Epoch [2/5], Step [5100/6000], Loss: 0.0692\n",
      "Train O/P: Epoch [2/5], Step [5110/6000], Loss: 0.0535\n",
      "Train O/P: Epoch [2/5], Step [5120/6000], Loss: 0.0063\n",
      "Train O/P: Epoch [2/5], Step [5130/6000], Loss: 0.0383\n",
      "Train O/P: Epoch [2/5], Step [5140/6000], Loss: 0.2709\n",
      "Train O/P: Epoch [2/5], Step [5150/6000], Loss: 0.0682\n",
      "Train O/P: Epoch [2/5], Step [5160/6000], Loss: 0.0104\n",
      "Train O/P: Epoch [2/5], Step [5170/6000], Loss: 0.0981\n",
      "Train O/P: Epoch [2/5], Step [5180/6000], Loss: 0.1039\n",
      "Train O/P: Epoch [2/5], Step [5190/6000], Loss: 0.0353\n",
      "Train O/P: Epoch [2/5], Step [5200/6000], Loss: 0.0148\n",
      "Train O/P: Epoch [2/5], Step [5210/6000], Loss: 0.2033\n",
      "Train O/P: Epoch [2/5], Step [5220/6000], Loss: 0.0481\n",
      "Train O/P: Epoch [2/5], Step [5230/6000], Loss: 0.0866\n",
      "Train O/P: Epoch [2/5], Step [5240/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [2/5], Step [5250/6000], Loss: 0.0436\n",
      "Train O/P: Epoch [2/5], Step [5260/6000], Loss: 0.5580\n",
      "Train O/P: Epoch [2/5], Step [5270/6000], Loss: 0.3722\n",
      "Train O/P: Epoch [2/5], Step [5280/6000], Loss: 0.0235\n",
      "Train O/P: Epoch [2/5], Step [5290/6000], Loss: 0.0238\n",
      "Train O/P: Epoch [2/5], Step [5300/6000], Loss: 0.0477\n",
      "Train O/P: Epoch [2/5], Step [5310/6000], Loss: 0.2300\n",
      "Train O/P: Epoch [2/5], Step [5320/6000], Loss: 0.0418\n",
      "Train O/P: Epoch [2/5], Step [5330/6000], Loss: 0.4982\n",
      "Train O/P: Epoch [2/5], Step [5340/6000], Loss: 0.0921\n",
      "Train O/P: Epoch [2/5], Step [5350/6000], Loss: 0.0736\n",
      "Train O/P: Epoch [2/5], Step [5360/6000], Loss: 0.0828\n",
      "Train O/P: Epoch [2/5], Step [5370/6000], Loss: 0.0210\n",
      "Train O/P: Epoch [2/5], Step [5380/6000], Loss: 0.4177\n",
      "Train O/P: Epoch [2/5], Step [5390/6000], Loss: 0.0094\n",
      "Train O/P: Epoch [2/5], Step [5400/6000], Loss: 0.5599\n",
      "Train O/P: Epoch [2/5], Step [5410/6000], Loss: 0.0290\n",
      "Train O/P: Epoch [2/5], Step [5420/6000], Loss: 0.2438\n",
      "Train O/P: Epoch [2/5], Step [5430/6000], Loss: 0.0208\n",
      "Train O/P: Epoch [2/5], Step [5440/6000], Loss: 0.0271\n",
      "Train O/P: Epoch [2/5], Step [5450/6000], Loss: 0.0677\n",
      "Train O/P: Epoch [2/5], Step [5460/6000], Loss: 0.0073\n",
      "Train O/P: Epoch [2/5], Step [5470/6000], Loss: 0.1032\n",
      "Train O/P: Epoch [2/5], Step [5480/6000], Loss: 0.0102\n",
      "Train O/P: Epoch [2/5], Step [5490/6000], Loss: 0.0416\n",
      "Train O/P: Epoch [2/5], Step [5500/6000], Loss: 0.0796\n",
      "Train O/P: Epoch [2/5], Step [5510/6000], Loss: 0.0297\n",
      "Train O/P: Epoch [2/5], Step [5520/6000], Loss: 0.1459\n",
      "Train O/P: Epoch [2/5], Step [5530/6000], Loss: 0.0059\n",
      "Train O/P: Epoch [2/5], Step [5540/6000], Loss: 0.0389\n",
      "Train O/P: Epoch [2/5], Step [5550/6000], Loss: 0.1108\n",
      "Train O/P: Epoch [2/5], Step [5560/6000], Loss: 0.0171\n",
      "Train O/P: Epoch [2/5], Step [5570/6000], Loss: 0.0704\n",
      "Train O/P: Epoch [2/5], Step [5580/6000], Loss: 0.0303\n",
      "Train O/P: Epoch [2/5], Step [5590/6000], Loss: 0.1553\n",
      "Train O/P: Epoch [2/5], Step [5600/6000], Loss: 0.0616\n",
      "Train O/P: Epoch [2/5], Step [5610/6000], Loss: 0.0691\n",
      "Train O/P: Epoch [2/5], Step [5620/6000], Loss: 0.2376\n",
      "Train O/P: Epoch [2/5], Step [5630/6000], Loss: 0.8079\n",
      "Train O/P: Epoch [2/5], Step [5640/6000], Loss: 0.0280\n",
      "Train O/P: Epoch [2/5], Step [5650/6000], Loss: 0.0313\n",
      "Train O/P: Epoch [2/5], Step [5660/6000], Loss: 0.1361\n",
      "Train O/P: Epoch [2/5], Step [5670/6000], Loss: 0.0085\n",
      "Train O/P: Epoch [2/5], Step [5680/6000], Loss: 0.0113\n",
      "Train O/P: Epoch [2/5], Step [5690/6000], Loss: 0.2417\n",
      "Train O/P: Epoch [2/5], Step [5700/6000], Loss: 0.2443\n",
      "Train O/P: Epoch [2/5], Step [5710/6000], Loss: 0.0487\n",
      "Train O/P: Epoch [2/5], Step [5720/6000], Loss: 0.0859\n",
      "Train O/P: Epoch [2/5], Step [5730/6000], Loss: 0.0127\n",
      "Train O/P: Epoch [2/5], Step [5740/6000], Loss: 0.0144\n",
      "Train O/P: Epoch [2/5], Step [5750/6000], Loss: 0.0184\n",
      "Train O/P: Epoch [2/5], Step [5760/6000], Loss: 0.2859\n",
      "Train O/P: Epoch [2/5], Step [5770/6000], Loss: 0.0770\n",
      "Train O/P: Epoch [2/5], Step [5780/6000], Loss: 0.3406\n",
      "Train O/P: Epoch [2/5], Step [5790/6000], Loss: 0.0696\n",
      "Train O/P: Epoch [2/5], Step [5800/6000], Loss: 0.0825\n",
      "Train O/P: Epoch [2/5], Step [5810/6000], Loss: 0.0231\n",
      "Train O/P: Epoch [2/5], Step [5820/6000], Loss: 0.2954\n",
      "Train O/P: Epoch [2/5], Step [5830/6000], Loss: 0.0287\n",
      "Train O/P: Epoch [2/5], Step [5840/6000], Loss: 0.0158\n",
      "Train O/P: Epoch [2/5], Step [5850/6000], Loss: 0.1396\n",
      "Train O/P: Epoch [2/5], Step [5860/6000], Loss: 0.0214\n",
      "Train O/P: Epoch [2/5], Step [5870/6000], Loss: 0.0608\n",
      "Train O/P: Epoch [2/5], Step [5880/6000], Loss: 0.1411\n",
      "Train O/P: Epoch [2/5], Step [5890/6000], Loss: 0.0419\n",
      "Train O/P: Epoch [2/5], Step [5900/6000], Loss: 0.0103\n",
      "Train O/P: Epoch [2/5], Step [5910/6000], Loss: 0.1469\n",
      "Train O/P: Epoch [2/5], Step [5920/6000], Loss: 0.0312\n",
      "Train O/P: Epoch [2/5], Step [5930/6000], Loss: 0.0292\n",
      "Train O/P: Epoch [2/5], Step [5940/6000], Loss: 0.1884\n",
      "Train O/P: Epoch [2/5], Step [5950/6000], Loss: 0.0753\n",
      "Train O/P: Epoch [2/5], Step [5960/6000], Loss: 0.1168\n",
      "Train O/P: Epoch [2/5], Step [5970/6000], Loss: 0.0855\n",
      "Train O/P: Epoch [2/5], Step [5980/6000], Loss: 0.2597\n",
      "Train O/P: Epoch [2/5], Step [5990/6000], Loss: 0.0106\n",
      "Train O/P: Epoch [2/5], Step [6000/6000], Loss: 0.0187\n",
      "Train O/P: Epoch [3/5], Step [10/6000], Loss: 0.2556\n",
      "Train O/P: Epoch [3/5], Step [20/6000], Loss: 0.0926\n",
      "Train O/P: Epoch [3/5], Step [30/6000], Loss: 0.0179\n",
      "Train O/P: Epoch [3/5], Step [40/6000], Loss: 0.0919\n",
      "Train O/P: Epoch [3/5], Step [50/6000], Loss: 0.5609\n",
      "Train O/P: Epoch [3/5], Step [60/6000], Loss: 0.4174\n",
      "Train O/P: Epoch [3/5], Step [70/6000], Loss: 0.0328\n",
      "Train O/P: Epoch [3/5], Step [80/6000], Loss: 0.0156\n",
      "Train O/P: Epoch [3/5], Step [90/6000], Loss: 0.0399\n",
      "Train O/P: Epoch [3/5], Step [100/6000], Loss: 0.0209\n",
      "Train O/P: Epoch [3/5], Step [110/6000], Loss: 0.3067\n",
      "Train O/P: Epoch [3/5], Step [120/6000], Loss: 0.0168\n",
      "Train O/P: Epoch [3/5], Step [130/6000], Loss: 0.4379\n",
      "Train O/P: Epoch [3/5], Step [140/6000], Loss: 0.0733\n",
      "Train O/P: Epoch [3/5], Step [150/6000], Loss: 0.0361\n",
      "Train O/P: Epoch [3/5], Step [160/6000], Loss: 0.2100\n",
      "Train O/P: Epoch [3/5], Step [170/6000], Loss: 0.3138\n",
      "Train O/P: Epoch [3/5], Step [180/6000], Loss: 0.0165\n",
      "Train O/P: Epoch [3/5], Step [190/6000], Loss: 0.0901\n",
      "Train O/P: Epoch [3/5], Step [200/6000], Loss: 0.0217\n",
      "Train O/P: Epoch [3/5], Step [210/6000], Loss: 0.2706\n",
      "Train O/P: Epoch [3/5], Step [220/6000], Loss: 0.0884\n",
      "Train O/P: Epoch [3/5], Step [230/6000], Loss: 0.0462\n",
      "Train O/P: Epoch [3/5], Step [240/6000], Loss: 0.0295\n",
      "Train O/P: Epoch [3/5], Step [250/6000], Loss: 0.2188\n",
      "Train O/P: Epoch [3/5], Step [260/6000], Loss: 0.0179\n",
      "Train O/P: Epoch [3/5], Step [270/6000], Loss: 0.0796\n",
      "Train O/P: Epoch [3/5], Step [280/6000], Loss: 0.0685\n",
      "Train O/P: Epoch [3/5], Step [290/6000], Loss: 0.0084\n",
      "Train O/P: Epoch [3/5], Step [300/6000], Loss: 0.0810\n",
      "Train O/P: Epoch [3/5], Step [310/6000], Loss: 0.0788\n",
      "Train O/P: Epoch [3/5], Step [320/6000], Loss: 0.2328\n",
      "Train O/P: Epoch [3/5], Step [330/6000], Loss: 0.0830\n",
      "Train O/P: Epoch [3/5], Step [340/6000], Loss: 0.0248\n",
      "Train O/P: Epoch [3/5], Step [350/6000], Loss: 0.0114\n",
      "Train O/P: Epoch [3/5], Step [360/6000], Loss: 0.0217\n",
      "Train O/P: Epoch [3/5], Step [370/6000], Loss: 0.4245\n",
      "Train O/P: Epoch [3/5], Step [380/6000], Loss: 0.2430\n",
      "Train O/P: Epoch [3/5], Step [390/6000], Loss: 0.0758\n",
      "Train O/P: Epoch [3/5], Step [400/6000], Loss: 0.0254\n",
      "Train O/P: Epoch [3/5], Step [410/6000], Loss: 0.0370\n",
      "Train O/P: Epoch [3/5], Step [420/6000], Loss: 0.0908\n",
      "Train O/P: Epoch [3/5], Step [430/6000], Loss: 0.0295\n",
      "Train O/P: Epoch [3/5], Step [440/6000], Loss: 0.0216\n",
      "Train O/P: Epoch [3/5], Step [450/6000], Loss: 0.1645\n",
      "Train O/P: Epoch [3/5], Step [460/6000], Loss: 0.0315\n",
      "Train O/P: Epoch [3/5], Step [470/6000], Loss: 0.1228\n",
      "Train O/P: Epoch [3/5], Step [480/6000], Loss: 0.1078\n",
      "Train O/P: Epoch [3/5], Step [490/6000], Loss: 0.2573\n",
      "Train O/P: Epoch [3/5], Step [500/6000], Loss: 0.1353\n",
      "Train O/P: Epoch [3/5], Step [510/6000], Loss: 0.2233\n",
      "Train O/P: Epoch [3/5], Step [520/6000], Loss: 0.4742\n",
      "Train O/P: Epoch [3/5], Step [530/6000], Loss: 0.1278\n",
      "Train O/P: Epoch [3/5], Step [540/6000], Loss: 0.0619\n",
      "Train O/P: Epoch [3/5], Step [550/6000], Loss: 0.0532\n",
      "Train O/P: Epoch [3/5], Step [560/6000], Loss: 0.0103\n",
      "Train O/P: Epoch [3/5], Step [570/6000], Loss: 0.2350\n",
      "Train O/P: Epoch [3/5], Step [580/6000], Loss: 0.7598\n",
      "Train O/P: Epoch [3/5], Step [590/6000], Loss: 0.0089\n",
      "Train O/P: Epoch [3/5], Step [600/6000], Loss: 0.0118\n",
      "Train O/P: Epoch [3/5], Step [610/6000], Loss: 0.2292\n",
      "Train O/P: Epoch [3/5], Step [620/6000], Loss: 0.0067\n",
      "Train O/P: Epoch [3/5], Step [630/6000], Loss: 0.1268\n",
      "Train O/P: Epoch [3/5], Step [640/6000], Loss: 0.2600\n",
      "Train O/P: Epoch [3/5], Step [650/6000], Loss: 0.0949\n",
      "Train O/P: Epoch [3/5], Step [660/6000], Loss: 0.2265\n",
      "Train O/P: Epoch [3/5], Step [670/6000], Loss: 0.0839\n",
      "Train O/P: Epoch [3/5], Step [680/6000], Loss: 0.0839\n",
      "Train O/P: Epoch [3/5], Step [690/6000], Loss: 0.0600\n",
      "Train O/P: Epoch [3/5], Step [700/6000], Loss: 0.0790\n",
      "Train O/P: Epoch [3/5], Step [710/6000], Loss: 0.1954\n",
      "Train O/P: Epoch [3/5], Step [720/6000], Loss: 0.0290\n",
      "Train O/P: Epoch [3/5], Step [730/6000], Loss: 0.0054\n",
      "Train O/P: Epoch [3/5], Step [740/6000], Loss: 0.0153\n",
      "Train O/P: Epoch [3/5], Step [750/6000], Loss: 0.0779\n",
      "Train O/P: Epoch [3/5], Step [760/6000], Loss: 0.0280\n",
      "Train O/P: Epoch [3/5], Step [770/6000], Loss: 0.0032\n",
      "Train O/P: Epoch [3/5], Step [780/6000], Loss: 0.0423\n",
      "Train O/P: Epoch [3/5], Step [790/6000], Loss: 0.0221\n",
      "Train O/P: Epoch [3/5], Step [800/6000], Loss: 0.1456\n",
      "Train O/P: Epoch [3/5], Step [810/6000], Loss: 0.1288\n",
      "Train O/P: Epoch [3/5], Step [820/6000], Loss: 0.0312\n",
      "Train O/P: Epoch [3/5], Step [830/6000], Loss: 0.0098\n",
      "Train O/P: Epoch [3/5], Step [840/6000], Loss: 0.3052\n",
      "Train O/P: Epoch [3/5], Step [850/6000], Loss: 0.0449\n",
      "Train O/P: Epoch [3/5], Step [860/6000], Loss: 0.2938\n",
      "Train O/P: Epoch [3/5], Step [870/6000], Loss: 0.0881\n",
      "Train O/P: Epoch [3/5], Step [880/6000], Loss: 0.0025\n",
      "Train O/P: Epoch [3/5], Step [890/6000], Loss: 0.0089\n",
      "Train O/P: Epoch [3/5], Step [900/6000], Loss: 0.0048\n",
      "Train O/P: Epoch [3/5], Step [910/6000], Loss: 0.0022\n",
      "Train O/P: Epoch [3/5], Step [920/6000], Loss: 0.0112\n",
      "Train O/P: Epoch [3/5], Step [930/6000], Loss: 1.3121\n",
      "Train O/P: Epoch [3/5], Step [940/6000], Loss: 0.0973\n",
      "Train O/P: Epoch [3/5], Step [950/6000], Loss: 0.2062\n",
      "Train O/P: Epoch [3/5], Step [960/6000], Loss: 0.4085\n",
      "Train O/P: Epoch [3/5], Step [970/6000], Loss: 0.0398\n",
      "Train O/P: Epoch [3/5], Step [980/6000], Loss: 0.5407\n",
      "Train O/P: Epoch [3/5], Step [990/6000], Loss: 0.0533\n",
      "Train O/P: Epoch [3/5], Step [1000/6000], Loss: 0.0747\n",
      "Train O/P: Epoch [3/5], Step [1010/6000], Loss: 0.1154\n",
      "Train O/P: Epoch [3/5], Step [1020/6000], Loss: 0.3514\n",
      "Train O/P: Epoch [3/5], Step [1030/6000], Loss: 0.0245\n",
      "Train O/P: Epoch [3/5], Step [1040/6000], Loss: 0.0073\n",
      "Train O/P: Epoch [3/5], Step [1050/6000], Loss: 0.0369\n",
      "Train O/P: Epoch [3/5], Step [1060/6000], Loss: 0.0276\n",
      "Train O/P: Epoch [3/5], Step [1070/6000], Loss: 0.0042\n",
      "Train O/P: Epoch [3/5], Step [1080/6000], Loss: 0.0565\n",
      "Train O/P: Epoch [3/5], Step [1090/6000], Loss: 0.0132\n",
      "Train O/P: Epoch [3/5], Step [1100/6000], Loss: 0.1223\n",
      "Train O/P: Epoch [3/5], Step [1110/6000], Loss: 0.0353\n",
      "Train O/P: Epoch [3/5], Step [1120/6000], Loss: 0.0275\n",
      "Train O/P: Epoch [3/5], Step [1130/6000], Loss: 0.1436\n",
      "Train O/P: Epoch [3/5], Step [1140/6000], Loss: 0.0362\n",
      "Train O/P: Epoch [3/5], Step [1150/6000], Loss: 0.0463\n",
      "Train O/P: Epoch [3/5], Step [1160/6000], Loss: 0.0288\n",
      "Train O/P: Epoch [3/5], Step [1170/6000], Loss: 0.0579\n",
      "Train O/P: Epoch [3/5], Step [1180/6000], Loss: 0.1810\n",
      "Train O/P: Epoch [3/5], Step [1190/6000], Loss: 0.0082\n",
      "Train O/P: Epoch [3/5], Step [1200/6000], Loss: 0.0370\n",
      "Train O/P: Epoch [3/5], Step [1210/6000], Loss: 0.0232\n",
      "Train O/P: Epoch [3/5], Step [1220/6000], Loss: 0.0636\n",
      "Train O/P: Epoch [3/5], Step [1230/6000], Loss: 0.0347\n",
      "Train O/P: Epoch [3/5], Step [1240/6000], Loss: 0.0202\n",
      "Train O/P: Epoch [3/5], Step [1250/6000], Loss: 0.0218\n",
      "Train O/P: Epoch [3/5], Step [1260/6000], Loss: 0.0619\n",
      "Train O/P: Epoch [3/5], Step [1270/6000], Loss: 0.0932\n",
      "Train O/P: Epoch [3/5], Step [1280/6000], Loss: 0.0185\n",
      "Train O/P: Epoch [3/5], Step [1290/6000], Loss: 0.1977\n",
      "Train O/P: Epoch [3/5], Step [1300/6000], Loss: 0.1474\n",
      "Train O/P: Epoch [3/5], Step [1310/6000], Loss: 0.1467\n",
      "Train O/P: Epoch [3/5], Step [1320/6000], Loss: 0.0060\n",
      "Train O/P: Epoch [3/5], Step [1330/6000], Loss: 0.0094\n",
      "Train O/P: Epoch [3/5], Step [1340/6000], Loss: 0.0423\n",
      "Train O/P: Epoch [3/5], Step [1350/6000], Loss: 0.1047\n",
      "Train O/P: Epoch [3/5], Step [1360/6000], Loss: 0.0264\n",
      "Train O/P: Epoch [3/5], Step [1370/6000], Loss: 0.3295\n",
      "Train O/P: Epoch [3/5], Step [1380/6000], Loss: 0.0673\n",
      "Train O/P: Epoch [3/5], Step [1390/6000], Loss: 0.2678\n",
      "Train O/P: Epoch [3/5], Step [1400/6000], Loss: 0.0518\n",
      "Train O/P: Epoch [3/5], Step [1410/6000], Loss: 0.1052\n",
      "Train O/P: Epoch [3/5], Step [1420/6000], Loss: 0.0475\n",
      "Train O/P: Epoch [3/5], Step [1430/6000], Loss: 0.0302\n",
      "Train O/P: Epoch [3/5], Step [1440/6000], Loss: 0.0093\n",
      "Train O/P: Epoch [3/5], Step [1450/6000], Loss: 0.0763\n",
      "Train O/P: Epoch [3/5], Step [1460/6000], Loss: 0.0431\n",
      "Train O/P: Epoch [3/5], Step [1470/6000], Loss: 0.0692\n",
      "Train O/P: Epoch [3/5], Step [1480/6000], Loss: 0.0987\n",
      "Train O/P: Epoch [3/5], Step [1490/6000], Loss: 0.0167\n",
      "Train O/P: Epoch [3/5], Step [1500/6000], Loss: 0.0659\n",
      "Train O/P: Epoch [3/5], Step [1510/6000], Loss: 0.0409\n",
      "Train O/P: Epoch [3/5], Step [1520/6000], Loss: 0.0299\n",
      "Train O/P: Epoch [3/5], Step [1530/6000], Loss: 0.0757\n",
      "Train O/P: Epoch [3/5], Step [1540/6000], Loss: 0.0621\n",
      "Train O/P: Epoch [3/5], Step [1550/6000], Loss: 0.1905\n",
      "Train O/P: Epoch [3/5], Step [1560/6000], Loss: 0.0224\n",
      "Train O/P: Epoch [3/5], Step [1570/6000], Loss: 0.0813\n",
      "Train O/P: Epoch [3/5], Step [1580/6000], Loss: 0.1401\n",
      "Train O/P: Epoch [3/5], Step [1590/6000], Loss: 0.1168\n",
      "Train O/P: Epoch [3/5], Step [1600/6000], Loss: 0.0192\n",
      "Train O/P: Epoch [3/5], Step [1610/6000], Loss: 0.0649\n",
      "Train O/P: Epoch [3/5], Step [1620/6000], Loss: 0.0511\n",
      "Train O/P: Epoch [3/5], Step [1630/6000], Loss: 0.0216\n",
      "Train O/P: Epoch [3/5], Step [1640/6000], Loss: 0.0715\n",
      "Train O/P: Epoch [3/5], Step [1650/6000], Loss: 0.0605\n",
      "Train O/P: Epoch [3/5], Step [1660/6000], Loss: 0.4129\n",
      "Train O/P: Epoch [3/5], Step [1670/6000], Loss: 0.0165\n",
      "Train O/P: Epoch [3/5], Step [1680/6000], Loss: 0.2800\n",
      "Train O/P: Epoch [3/5], Step [1690/6000], Loss: 0.1520\n",
      "Train O/P: Epoch [3/5], Step [1700/6000], Loss: 0.0386\n",
      "Train O/P: Epoch [3/5], Step [1710/6000], Loss: 0.0150\n",
      "Train O/P: Epoch [3/5], Step [1720/6000], Loss: 0.1963\n",
      "Train O/P: Epoch [3/5], Step [1730/6000], Loss: 0.0127\n",
      "Train O/P: Epoch [3/5], Step [1740/6000], Loss: 0.0322\n",
      "Train O/P: Epoch [3/5], Step [1750/6000], Loss: 0.0103\n",
      "Train O/P: Epoch [3/5], Step [1760/6000], Loss: 0.0039\n",
      "Train O/P: Epoch [3/5], Step [1770/6000], Loss: 0.0519\n",
      "Train O/P: Epoch [3/5], Step [1780/6000], Loss: 0.0533\n",
      "Train O/P: Epoch [3/5], Step [1790/6000], Loss: 0.0312\n",
      "Train O/P: Epoch [3/5], Step [1800/6000], Loss: 0.0267\n",
      "Train O/P: Epoch [3/5], Step [1810/6000], Loss: 0.0257\n",
      "Train O/P: Epoch [3/5], Step [1820/6000], Loss: 0.1299\n",
      "Train O/P: Epoch [3/5], Step [1830/6000], Loss: 0.0571\n",
      "Train O/P: Epoch [3/5], Step [1840/6000], Loss: 0.0633\n",
      "Train O/P: Epoch [3/5], Step [1850/6000], Loss: 0.4731\n",
      "Train O/P: Epoch [3/5], Step [1860/6000], Loss: 0.1627\n",
      "Train O/P: Epoch [3/5], Step [1870/6000], Loss: 0.0080\n",
      "Train O/P: Epoch [3/5], Step [1880/6000], Loss: 0.0156\n",
      "Train O/P: Epoch [3/5], Step [1890/6000], Loss: 0.2116\n",
      "Train O/P: Epoch [3/5], Step [1900/6000], Loss: 0.0980\n",
      "Train O/P: Epoch [3/5], Step [1910/6000], Loss: 0.0537\n",
      "Train O/P: Epoch [3/5], Step [1920/6000], Loss: 0.0245\n",
      "Train O/P: Epoch [3/5], Step [1930/6000], Loss: 0.0294\n",
      "Train O/P: Epoch [3/5], Step [1940/6000], Loss: 0.0124\n",
      "Train O/P: Epoch [3/5], Step [1950/6000], Loss: 0.3227\n",
      "Train O/P: Epoch [3/5], Step [1960/6000], Loss: 0.0617\n",
      "Train O/P: Epoch [3/5], Step [1970/6000], Loss: 0.1155\n",
      "Train O/P: Epoch [3/5], Step [1980/6000], Loss: 0.0171\n",
      "Train O/P: Epoch [3/5], Step [1990/6000], Loss: 0.0531\n",
      "Train O/P: Epoch [3/5], Step [2000/6000], Loss: 0.0115\n",
      "Train O/P: Epoch [3/5], Step [2010/6000], Loss: 0.0649\n",
      "Train O/P: Epoch [3/5], Step [2020/6000], Loss: 0.5278\n",
      "Train O/P: Epoch [3/5], Step [2030/6000], Loss: 0.2648\n",
      "Train O/P: Epoch [3/5], Step [2040/6000], Loss: 0.0769\n",
      "Train O/P: Epoch [3/5], Step [2050/6000], Loss: 0.0788\n",
      "Train O/P: Epoch [3/5], Step [2060/6000], Loss: 0.0170\n",
      "Train O/P: Epoch [3/5], Step [2070/6000], Loss: 0.6933\n",
      "Train O/P: Epoch [3/5], Step [2080/6000], Loss: 0.1539\n",
      "Train O/P: Epoch [3/5], Step [2090/6000], Loss: 0.3206\n",
      "Train O/P: Epoch [3/5], Step [2100/6000], Loss: 0.3068\n",
      "Train O/P: Epoch [3/5], Step [2110/6000], Loss: 0.0395\n",
      "Train O/P: Epoch [3/5], Step [2120/6000], Loss: 0.0574\n",
      "Train O/P: Epoch [3/5], Step [2130/6000], Loss: 0.0521\n",
      "Train O/P: Epoch [3/5], Step [2140/6000], Loss: 0.0296\n",
      "Train O/P: Epoch [3/5], Step [2150/6000], Loss: 0.3576\n",
      "Train O/P: Epoch [3/5], Step [2160/6000], Loss: 0.0851\n",
      "Train O/P: Epoch [3/5], Step [2170/6000], Loss: 0.0619\n",
      "Train O/P: Epoch [3/5], Step [2180/6000], Loss: 0.1305\n",
      "Train O/P: Epoch [3/5], Step [2190/6000], Loss: 0.0425\n",
      "Train O/P: Epoch [3/5], Step [2200/6000], Loss: 0.0986\n",
      "Train O/P: Epoch [3/5], Step [2210/6000], Loss: 0.6287\n",
      "Train O/P: Epoch [3/5], Step [2220/6000], Loss: 0.0715\n",
      "Train O/P: Epoch [3/5], Step [2230/6000], Loss: 0.0122\n",
      "Train O/P: Epoch [3/5], Step [2240/6000], Loss: 0.0239\n",
      "Train O/P: Epoch [3/5], Step [2250/6000], Loss: 0.2209\n",
      "Train O/P: Epoch [3/5], Step [2260/6000], Loss: 0.3761\n",
      "Train O/P: Epoch [3/5], Step [2270/6000], Loss: 0.0102\n",
      "Train O/P: Epoch [3/5], Step [2280/6000], Loss: 0.1974\n",
      "Train O/P: Epoch [3/5], Step [2290/6000], Loss: 0.4946\n",
      "Train O/P: Epoch [3/5], Step [2300/6000], Loss: 0.1073\n",
      "Train O/P: Epoch [3/5], Step [2310/6000], Loss: 0.1571\n",
      "Train O/P: Epoch [3/5], Step [2320/6000], Loss: 0.0320\n",
      "Train O/P: Epoch [3/5], Step [2330/6000], Loss: 0.2507\n",
      "Train O/P: Epoch [3/5], Step [2340/6000], Loss: 0.0289\n",
      "Train O/P: Epoch [3/5], Step [2350/6000], Loss: 0.0406\n",
      "Train O/P: Epoch [3/5], Step [2360/6000], Loss: 0.0751\n",
      "Train O/P: Epoch [3/5], Step [2370/6000], Loss: 0.0692\n",
      "Train O/P: Epoch [3/5], Step [2380/6000], Loss: 0.0324\n",
      "Train O/P: Epoch [3/5], Step [2390/6000], Loss: 0.1509\n",
      "Train O/P: Epoch [3/5], Step [2400/6000], Loss: 0.2514\n",
      "Train O/P: Epoch [3/5], Step [2410/6000], Loss: 0.1033\n",
      "Train O/P: Epoch [3/5], Step [2420/6000], Loss: 0.0260\n",
      "Train O/P: Epoch [3/5], Step [2430/6000], Loss: 0.5381\n",
      "Train O/P: Epoch [3/5], Step [2440/6000], Loss: 0.0225\n",
      "Train O/P: Epoch [3/5], Step [2450/6000], Loss: 0.0921\n",
      "Train O/P: Epoch [3/5], Step [2460/6000], Loss: 0.1212\n",
      "Train O/P: Epoch [3/5], Step [2470/6000], Loss: 0.1320\n",
      "Train O/P: Epoch [3/5], Step [2480/6000], Loss: 0.1322\n",
      "Train O/P: Epoch [3/5], Step [2490/6000], Loss: 0.0138\n",
      "Train O/P: Epoch [3/5], Step [2500/6000], Loss: 0.0418\n",
      "Train O/P: Epoch [3/5], Step [2510/6000], Loss: 0.1239\n",
      "Train O/P: Epoch [3/5], Step [2520/6000], Loss: 0.0408\n",
      "Train O/P: Epoch [3/5], Step [2530/6000], Loss: 0.1037\n",
      "Train O/P: Epoch [3/5], Step [2540/6000], Loss: 0.3024\n",
      "Train O/P: Epoch [3/5], Step [2550/6000], Loss: 0.4177\n",
      "Train O/P: Epoch [3/5], Step [2560/6000], Loss: 0.1005\n",
      "Train O/P: Epoch [3/5], Step [2570/6000], Loss: 0.1108\n",
      "Train O/P: Epoch [3/5], Step [2580/6000], Loss: 0.0165\n",
      "Train O/P: Epoch [3/5], Step [2590/6000], Loss: 0.4542\n",
      "Train O/P: Epoch [3/5], Step [2600/6000], Loss: 0.0972\n",
      "Train O/P: Epoch [3/5], Step [2610/6000], Loss: 0.0492\n",
      "Train O/P: Epoch [3/5], Step [2620/6000], Loss: 0.0711\n",
      "Train O/P: Epoch [3/5], Step [2630/6000], Loss: 0.0433\n",
      "Train O/P: Epoch [3/5], Step [2640/6000], Loss: 0.0787\n",
      "Train O/P: Epoch [3/5], Step [2650/6000], Loss: 0.2440\n",
      "Train O/P: Epoch [3/5], Step [2660/6000], Loss: 0.0683\n",
      "Train O/P: Epoch [3/5], Step [2670/6000], Loss: 0.0617\n",
      "Train O/P: Epoch [3/5], Step [2680/6000], Loss: 0.0312\n",
      "Train O/P: Epoch [3/5], Step [2690/6000], Loss: 0.0141\n",
      "Train O/P: Epoch [3/5], Step [2700/6000], Loss: 0.0743\n",
      "Train O/P: Epoch [3/5], Step [2710/6000], Loss: 0.0456\n",
      "Train O/P: Epoch [3/5], Step [2720/6000], Loss: 0.0076\n",
      "Train O/P: Epoch [3/5], Step [2730/6000], Loss: 0.3812\n",
      "Train O/P: Epoch [3/5], Step [2740/6000], Loss: 0.3022\n",
      "Train O/P: Epoch [3/5], Step [2750/6000], Loss: 0.1487\n",
      "Train O/P: Epoch [3/5], Step [2760/6000], Loss: 0.0201\n",
      "Train O/P: Epoch [3/5], Step [2770/6000], Loss: 0.0100\n",
      "Train O/P: Epoch [3/5], Step [2780/6000], Loss: 0.2511\n",
      "Train O/P: Epoch [3/5], Step [2790/6000], Loss: 0.0625\n",
      "Train O/P: Epoch [3/5], Step [2800/6000], Loss: 0.0611\n",
      "Train O/P: Epoch [3/5], Step [2810/6000], Loss: 0.1216\n",
      "Train O/P: Epoch [3/5], Step [2820/6000], Loss: 0.0119\n",
      "Train O/P: Epoch [3/5], Step [2830/6000], Loss: 0.0147\n",
      "Train O/P: Epoch [3/5], Step [2840/6000], Loss: 0.0145\n",
      "Train O/P: Epoch [3/5], Step [2850/6000], Loss: 0.0555\n",
      "Train O/P: Epoch [3/5], Step [2860/6000], Loss: 0.0785\n",
      "Train O/P: Epoch [3/5], Step [2870/6000], Loss: 0.0117\n",
      "Train O/P: Epoch [3/5], Step [2880/6000], Loss: 0.0115\n",
      "Train O/P: Epoch [3/5], Step [2890/6000], Loss: 0.2012\n",
      "Train O/P: Epoch [3/5], Step [2900/6000], Loss: 0.1163\n",
      "Train O/P: Epoch [3/5], Step [2910/6000], Loss: 0.1228\n",
      "Train O/P: Epoch [3/5], Step [2920/6000], Loss: 0.2824\n",
      "Train O/P: Epoch [3/5], Step [2930/6000], Loss: 0.0161\n",
      "Train O/P: Epoch [3/5], Step [2940/6000], Loss: 0.0827\n",
      "Train O/P: Epoch [3/5], Step [2950/6000], Loss: 0.1035\n",
      "Train O/P: Epoch [3/5], Step [2960/6000], Loss: 0.0136\n",
      "Train O/P: Epoch [3/5], Step [2970/6000], Loss: 0.2876\n",
      "Train O/P: Epoch [3/5], Step [2980/6000], Loss: 0.1192\n",
      "Train O/P: Epoch [3/5], Step [2990/6000], Loss: 0.0992\n",
      "Train O/P: Epoch [3/5], Step [3000/6000], Loss: 0.0676\n",
      "Train O/P: Epoch [3/5], Step [3010/6000], Loss: 0.0412\n",
      "Train O/P: Epoch [3/5], Step [3020/6000], Loss: 0.1485\n",
      "Train O/P: Epoch [3/5], Step [3030/6000], Loss: 0.0756\n",
      "Train O/P: Epoch [3/5], Step [3040/6000], Loss: 0.2260\n",
      "Train O/P: Epoch [3/5], Step [3050/6000], Loss: 0.2086\n",
      "Train O/P: Epoch [3/5], Step [3060/6000], Loss: 0.3590\n",
      "Train O/P: Epoch [3/5], Step [3070/6000], Loss: 0.1485\n",
      "Train O/P: Epoch [3/5], Step [3080/6000], Loss: 0.1002\n",
      "Train O/P: Epoch [3/5], Step [3090/6000], Loss: 0.0710\n",
      "Train O/P: Epoch [3/5], Step [3100/6000], Loss: 0.0144\n",
      "Train O/P: Epoch [3/5], Step [3110/6000], Loss: 0.0697\n",
      "Train O/P: Epoch [3/5], Step [3120/6000], Loss: 0.1723\n",
      "Train O/P: Epoch [3/5], Step [3130/6000], Loss: 0.0167\n",
      "Train O/P: Epoch [3/5], Step [3140/6000], Loss: 0.3512\n",
      "Train O/P: Epoch [3/5], Step [3150/6000], Loss: 0.3101\n",
      "Train O/P: Epoch [3/5], Step [3160/6000], Loss: 0.0189\n",
      "Train O/P: Epoch [3/5], Step [3170/6000], Loss: 0.0769\n",
      "Train O/P: Epoch [3/5], Step [3180/6000], Loss: 0.0429\n",
      "Train O/P: Epoch [3/5], Step [3190/6000], Loss: 0.1396\n",
      "Train O/P: Epoch [3/5], Step [3200/6000], Loss: 0.1751\n",
      "Train O/P: Epoch [3/5], Step [3210/6000], Loss: 0.0694\n",
      "Train O/P: Epoch [3/5], Step [3220/6000], Loss: 0.2393\n",
      "Train O/P: Epoch [3/5], Step [3230/6000], Loss: 0.0237\n",
      "Train O/P: Epoch [3/5], Step [3240/6000], Loss: 0.3493\n",
      "Train O/P: Epoch [3/5], Step [3250/6000], Loss: 0.5454\n",
      "Train O/P: Epoch [3/5], Step [3260/6000], Loss: 0.2151\n",
      "Train O/P: Epoch [3/5], Step [3270/6000], Loss: 0.1038\n",
      "Train O/P: Epoch [3/5], Step [3280/6000], Loss: 0.1571\n",
      "Train O/P: Epoch [3/5], Step [3290/6000], Loss: 0.4265\n",
      "Train O/P: Epoch [3/5], Step [3300/6000], Loss: 0.1932\n",
      "Train O/P: Epoch [3/5], Step [3310/6000], Loss: 0.1894\n",
      "Train O/P: Epoch [3/5], Step [3320/6000], Loss: 0.0639\n",
      "Train O/P: Epoch [3/5], Step [3330/6000], Loss: 0.4363\n",
      "Train O/P: Epoch [3/5], Step [3340/6000], Loss: 0.0382\n",
      "Train O/P: Epoch [3/5], Step [3350/6000], Loss: 0.2042\n",
      "Train O/P: Epoch [3/5], Step [3360/6000], Loss: 0.1962\n",
      "Train O/P: Epoch [3/5], Step [3370/6000], Loss: 0.1164\n",
      "Train O/P: Epoch [3/5], Step [3380/6000], Loss: 0.3519\n",
      "Train O/P: Epoch [3/5], Step [3390/6000], Loss: 0.0364\n",
      "Train O/P: Epoch [3/5], Step [3400/6000], Loss: 0.0919\n",
      "Train O/P: Epoch [3/5], Step [3410/6000], Loss: 0.0413\n",
      "Train O/P: Epoch [3/5], Step [3420/6000], Loss: 0.0105\n",
      "Train O/P: Epoch [3/5], Step [3430/6000], Loss: 0.0449\n",
      "Train O/P: Epoch [3/5], Step [3440/6000], Loss: 0.0195\n",
      "Train O/P: Epoch [3/5], Step [3450/6000], Loss: 0.3836\n",
      "Train O/P: Epoch [3/5], Step [3460/6000], Loss: 0.1581\n",
      "Train O/P: Epoch [3/5], Step [3470/6000], Loss: 0.2203\n",
      "Train O/P: Epoch [3/5], Step [3480/6000], Loss: 0.2968\n",
      "Train O/P: Epoch [3/5], Step [3490/6000], Loss: 0.1638\n",
      "Train O/P: Epoch [3/5], Step [3500/6000], Loss: 0.0595\n",
      "Train O/P: Epoch [3/5], Step [3510/6000], Loss: 0.2000\n",
      "Train O/P: Epoch [3/5], Step [3520/6000], Loss: 0.0228\n",
      "Train O/P: Epoch [3/5], Step [3530/6000], Loss: 0.2858\n",
      "Train O/P: Epoch [3/5], Step [3540/6000], Loss: 0.0435\n",
      "Train O/P: Epoch [3/5], Step [3550/6000], Loss: 0.0196\n",
      "Train O/P: Epoch [3/5], Step [3560/6000], Loss: 0.0612\n",
      "Train O/P: Epoch [3/5], Step [3570/6000], Loss: 0.1950\n",
      "Train O/P: Epoch [3/5], Step [3580/6000], Loss: 0.0882\n",
      "Train O/P: Epoch [3/5], Step [3590/6000], Loss: 0.0288\n",
      "Train O/P: Epoch [3/5], Step [3600/6000], Loss: 0.3887\n",
      "Train O/P: Epoch [3/5], Step [3610/6000], Loss: 0.4558\n",
      "Train O/P: Epoch [3/5], Step [3620/6000], Loss: 0.1512\n",
      "Train O/P: Epoch [3/5], Step [3630/6000], Loss: 0.0260\n",
      "Train O/P: Epoch [3/5], Step [3640/6000], Loss: 0.1920\n",
      "Train O/P: Epoch [3/5], Step [3650/6000], Loss: 0.0432\n",
      "Train O/P: Epoch [3/5], Step [3660/6000], Loss: 0.0275\n",
      "Train O/P: Epoch [3/5], Step [3670/6000], Loss: 0.0209\n",
      "Train O/P: Epoch [3/5], Step [3680/6000], Loss: 0.0585\n",
      "Train O/P: Epoch [3/5], Step [3690/6000], Loss: 0.0490\n",
      "Train O/P: Epoch [3/5], Step [3700/6000], Loss: 0.0090\n",
      "Train O/P: Epoch [3/5], Step [3710/6000], Loss: 0.1210\n",
      "Train O/P: Epoch [3/5], Step [3720/6000], Loss: 0.0848\n",
      "Train O/P: Epoch [3/5], Step [3730/6000], Loss: 0.0056\n",
      "Train O/P: Epoch [3/5], Step [3740/6000], Loss: 0.5127\n",
      "Train O/P: Epoch [3/5], Step [3750/6000], Loss: 0.0117\n",
      "Train O/P: Epoch [3/5], Step [3760/6000], Loss: 0.0990\n",
      "Train O/P: Epoch [3/5], Step [3770/6000], Loss: 0.0845\n",
      "Train O/P: Epoch [3/5], Step [3780/6000], Loss: 0.1031\n",
      "Train O/P: Epoch [3/5], Step [3790/6000], Loss: 0.4579\n",
      "Train O/P: Epoch [3/5], Step [3800/6000], Loss: 0.1399\n",
      "Train O/P: Epoch [3/5], Step [3810/6000], Loss: 0.0111\n",
      "Train O/P: Epoch [3/5], Step [3820/6000], Loss: 0.4222\n",
      "Train O/P: Epoch [3/5], Step [3830/6000], Loss: 0.1745\n",
      "Train O/P: Epoch [3/5], Step [3840/6000], Loss: 0.0449\n",
      "Train O/P: Epoch [3/5], Step [3850/6000], Loss: 0.0286\n",
      "Train O/P: Epoch [3/5], Step [3860/6000], Loss: 0.0486\n",
      "Train O/P: Epoch [3/5], Step [3870/6000], Loss: 0.0196\n",
      "Train O/P: Epoch [3/5], Step [3880/6000], Loss: 0.0212\n",
      "Train O/P: Epoch [3/5], Step [3890/6000], Loss: 0.0272\n",
      "Train O/P: Epoch [3/5], Step [3900/6000], Loss: 0.4350\n",
      "Train O/P: Epoch [3/5], Step [3910/6000], Loss: 0.0744\n",
      "Train O/P: Epoch [3/5], Step [3920/6000], Loss: 0.0845\n",
      "Train O/P: Epoch [3/5], Step [3930/6000], Loss: 0.0639\n",
      "Train O/P: Epoch [3/5], Step [3940/6000], Loss: 0.0469\n",
      "Train O/P: Epoch [3/5], Step [3950/6000], Loss: 0.0150\n",
      "Train O/P: Epoch [3/5], Step [3960/6000], Loss: 0.0499\n",
      "Train O/P: Epoch [3/5], Step [3970/6000], Loss: 0.2685\n",
      "Train O/P: Epoch [3/5], Step [3980/6000], Loss: 0.5658\n",
      "Train O/P: Epoch [3/5], Step [3990/6000], Loss: 0.0223\n",
      "Train O/P: Epoch [3/5], Step [4000/6000], Loss: 0.0721\n",
      "Train O/P: Epoch [3/5], Step [4010/6000], Loss: 0.0067\n",
      "Train O/P: Epoch [3/5], Step [4020/6000], Loss: 0.0570\n",
      "Train O/P: Epoch [3/5], Step [4030/6000], Loss: 0.0193\n",
      "Train O/P: Epoch [3/5], Step [4040/6000], Loss: 0.1012\n",
      "Train O/P: Epoch [3/5], Step [4050/6000], Loss: 0.2649\n",
      "Train O/P: Epoch [3/5], Step [4060/6000], Loss: 0.0080\n",
      "Train O/P: Epoch [3/5], Step [4070/6000], Loss: 0.0395\n",
      "Train O/P: Epoch [3/5], Step [4080/6000], Loss: 0.0616\n",
      "Train O/P: Epoch [3/5], Step [4090/6000], Loss: 0.0371\n",
      "Train O/P: Epoch [3/5], Step [4100/6000], Loss: 0.1628\n",
      "Train O/P: Epoch [3/5], Step [4110/6000], Loss: 0.0176\n",
      "Train O/P: Epoch [3/5], Step [4120/6000], Loss: 0.0626\n",
      "Train O/P: Epoch [3/5], Step [4130/6000], Loss: 0.0629\n",
      "Train O/P: Epoch [3/5], Step [4140/6000], Loss: 0.1633\n",
      "Train O/P: Epoch [3/5], Step [4150/6000], Loss: 0.0087\n",
      "Train O/P: Epoch [3/5], Step [4160/6000], Loss: 0.1718\n",
      "Train O/P: Epoch [3/5], Step [4170/6000], Loss: 0.1338\n",
      "Train O/P: Epoch [3/5], Step [4180/6000], Loss: 0.0201\n",
      "Train O/P: Epoch [3/5], Step [4190/6000], Loss: 0.4640\n",
      "Train O/P: Epoch [3/5], Step [4200/6000], Loss: 0.1005\n",
      "Train O/P: Epoch [3/5], Step [4210/6000], Loss: 0.0598\n",
      "Train O/P: Epoch [3/5], Step [4220/6000], Loss: 0.0819\n",
      "Train O/P: Epoch [3/5], Step [4230/6000], Loss: 0.0167\n",
      "Train O/P: Epoch [3/5], Step [4240/6000], Loss: 0.0044\n",
      "Train O/P: Epoch [3/5], Step [4250/6000], Loss: 0.1856\n",
      "Train O/P: Epoch [3/5], Step [4260/6000], Loss: 0.2279\n",
      "Train O/P: Epoch [3/5], Step [4270/6000], Loss: 0.1567\n",
      "Train O/P: Epoch [3/5], Step [4280/6000], Loss: 0.1014\n",
      "Train O/P: Epoch [3/5], Step [4290/6000], Loss: 0.0717\n",
      "Train O/P: Epoch [3/5], Step [4300/6000], Loss: 0.0833\n",
      "Train O/P: Epoch [3/5], Step [4310/6000], Loss: 0.4648\n",
      "Train O/P: Epoch [3/5], Step [4320/6000], Loss: 0.2188\n",
      "Train O/P: Epoch [3/5], Step [4330/6000], Loss: 0.0486\n",
      "Train O/P: Epoch [3/5], Step [4340/6000], Loss: 0.0313\n",
      "Train O/P: Epoch [3/5], Step [4350/6000], Loss: 0.3492\n",
      "Train O/P: Epoch [3/5], Step [4360/6000], Loss: 0.2512\n",
      "Train O/P: Epoch [3/5], Step [4370/6000], Loss: 0.0730\n",
      "Train O/P: Epoch [3/5], Step [4380/6000], Loss: 0.0025\n",
      "Train O/P: Epoch [3/5], Step [4390/6000], Loss: 0.4813\n",
      "Train O/P: Epoch [3/5], Step [4400/6000], Loss: 0.4904\n",
      "Train O/P: Epoch [3/5], Step [4410/6000], Loss: 0.0745\n",
      "Train O/P: Epoch [3/5], Step [4420/6000], Loss: 0.1668\n",
      "Train O/P: Epoch [3/5], Step [4430/6000], Loss: 0.0659\n",
      "Train O/P: Epoch [3/5], Step [4440/6000], Loss: 0.1874\n",
      "Train O/P: Epoch [3/5], Step [4450/6000], Loss: 0.1984\n",
      "Train O/P: Epoch [3/5], Step [4460/6000], Loss: 0.0289\n",
      "Train O/P: Epoch [3/5], Step [4470/6000], Loss: 0.1826\n",
      "Train O/P: Epoch [3/5], Step [4480/6000], Loss: 0.0665\n",
      "Train O/P: Epoch [3/5], Step [4490/6000], Loss: 0.3824\n",
      "Train O/P: Epoch [3/5], Step [4500/6000], Loss: 0.1048\n",
      "Train O/P: Epoch [3/5], Step [4510/6000], Loss: 0.0888\n",
      "Train O/P: Epoch [3/5], Step [4520/6000], Loss: 0.2031\n",
      "Train O/P: Epoch [3/5], Step [4530/6000], Loss: 0.1975\n",
      "Train O/P: Epoch [3/5], Step [4540/6000], Loss: 0.3254\n",
      "Train O/P: Epoch [3/5], Step [4550/6000], Loss: 0.1100\n",
      "Train O/P: Epoch [3/5], Step [4560/6000], Loss: 0.0678\n",
      "Train O/P: Epoch [3/5], Step [4570/6000], Loss: 0.0187\n",
      "Train O/P: Epoch [3/5], Step [4580/6000], Loss: 0.0928\n",
      "Train O/P: Epoch [3/5], Step [4590/6000], Loss: 0.1661\n",
      "Train O/P: Epoch [3/5], Step [4600/6000], Loss: 0.0985\n",
      "Train O/P: Epoch [3/5], Step [4610/6000], Loss: 0.0178\n",
      "Train O/P: Epoch [3/5], Step [4620/6000], Loss: 0.2330\n",
      "Train O/P: Epoch [3/5], Step [4630/6000], Loss: 0.2953\n",
      "Train O/P: Epoch [3/5], Step [4640/6000], Loss: 0.0499\n",
      "Train O/P: Epoch [3/5], Step [4650/6000], Loss: 0.1586\n",
      "Train O/P: Epoch [3/5], Step [4660/6000], Loss: 0.0377\n",
      "Train O/P: Epoch [3/5], Step [4670/6000], Loss: 0.0126\n",
      "Train O/P: Epoch [3/5], Step [4680/6000], Loss: 0.0086\n",
      "Train O/P: Epoch [3/5], Step [4690/6000], Loss: 0.0873\n",
      "Train O/P: Epoch [3/5], Step [4700/6000], Loss: 0.0219\n",
      "Train O/P: Epoch [3/5], Step [4710/6000], Loss: 0.0934\n",
      "Train O/P: Epoch [3/5], Step [4720/6000], Loss: 0.0841\n",
      "Train O/P: Epoch [3/5], Step [4730/6000], Loss: 0.0139\n",
      "Train O/P: Epoch [3/5], Step [4740/6000], Loss: 0.1599\n",
      "Train O/P: Epoch [3/5], Step [4750/6000], Loss: 0.0321\n",
      "Train O/P: Epoch [3/5], Step [4760/6000], Loss: 0.1664\n",
      "Train O/P: Epoch [3/5], Step [4770/6000], Loss: 0.0995\n",
      "Train O/P: Epoch [3/5], Step [4780/6000], Loss: 0.4710\n",
      "Train O/P: Epoch [3/5], Step [4790/6000], Loss: 0.2089\n",
      "Train O/P: Epoch [3/5], Step [4800/6000], Loss: 0.5577\n",
      "Train O/P: Epoch [3/5], Step [4810/6000], Loss: 0.0540\n",
      "Train O/P: Epoch [3/5], Step [4820/6000], Loss: 0.0495\n",
      "Train O/P: Epoch [3/5], Step [4830/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [3/5], Step [4840/6000], Loss: 0.0418\n",
      "Train O/P: Epoch [3/5], Step [4850/6000], Loss: 0.0660\n",
      "Train O/P: Epoch [3/5], Step [4860/6000], Loss: 0.0493\n",
      "Train O/P: Epoch [3/5], Step [4870/6000], Loss: 0.0551\n",
      "Train O/P: Epoch [3/5], Step [4880/6000], Loss: 0.0657\n",
      "Train O/P: Epoch [3/5], Step [4890/6000], Loss: 0.0113\n",
      "Train O/P: Epoch [3/5], Step [4900/6000], Loss: 0.3116\n",
      "Train O/P: Epoch [3/5], Step [4910/6000], Loss: 0.0123\n",
      "Train O/P: Epoch [3/5], Step [4920/6000], Loss: 0.2169\n",
      "Train O/P: Epoch [3/5], Step [4930/6000], Loss: 0.0305\n",
      "Train O/P: Epoch [3/5], Step [4940/6000], Loss: 0.0522\n",
      "Train O/P: Epoch [3/5], Step [4950/6000], Loss: 0.0752\n",
      "Train O/P: Epoch [3/5], Step [4960/6000], Loss: 0.0389\n",
      "Train O/P: Epoch [3/5], Step [4970/6000], Loss: 0.0825\n",
      "Train O/P: Epoch [3/5], Step [4980/6000], Loss: 0.0038\n",
      "Train O/P: Epoch [3/5], Step [4990/6000], Loss: 0.0816\n",
      "Train O/P: Epoch [3/5], Step [5000/6000], Loss: 0.0108\n",
      "Train O/P: Epoch [3/5], Step [5010/6000], Loss: 0.0233\n",
      "Train O/P: Epoch [3/5], Step [5020/6000], Loss: 0.0163\n",
      "Train O/P: Epoch [3/5], Step [5030/6000], Loss: 0.1180\n",
      "Train O/P: Epoch [3/5], Step [5040/6000], Loss: 0.0088\n",
      "Train O/P: Epoch [3/5], Step [5050/6000], Loss: 0.4631\n",
      "Train O/P: Epoch [3/5], Step [5060/6000], Loss: 0.0294\n",
      "Train O/P: Epoch [3/5], Step [5070/6000], Loss: 0.0125\n",
      "Train O/P: Epoch [3/5], Step [5080/6000], Loss: 0.0574\n",
      "Train O/P: Epoch [3/5], Step [5090/6000], Loss: 0.0539\n",
      "Train O/P: Epoch [3/5], Step [5100/6000], Loss: 0.0631\n",
      "Train O/P: Epoch [3/5], Step [5110/6000], Loss: 0.0245\n",
      "Train O/P: Epoch [3/5], Step [5120/6000], Loss: 0.0161\n",
      "Train O/P: Epoch [3/5], Step [5130/6000], Loss: 0.1303\n",
      "Train O/P: Epoch [3/5], Step [5140/6000], Loss: 0.5236\n",
      "Train O/P: Epoch [3/5], Step [5150/6000], Loss: 0.1825\n",
      "Train O/P: Epoch [3/5], Step [5160/6000], Loss: 0.0585\n",
      "Train O/P: Epoch [3/5], Step [5170/6000], Loss: 0.0348\n",
      "Train O/P: Epoch [3/5], Step [5180/6000], Loss: 0.0166\n",
      "Train O/P: Epoch [3/5], Step [5190/6000], Loss: 0.0033\n",
      "Train O/P: Epoch [3/5], Step [5200/6000], Loss: 0.0752\n",
      "Train O/P: Epoch [3/5], Step [5210/6000], Loss: 0.0319\n",
      "Train O/P: Epoch [3/5], Step [5220/6000], Loss: 0.0237\n",
      "Train O/P: Epoch [3/5], Step [5230/6000], Loss: 0.0232\n",
      "Train O/P: Epoch [3/5], Step [5240/6000], Loss: 0.1906\n",
      "Train O/P: Epoch [3/5], Step [5250/6000], Loss: 0.0314\n",
      "Train O/P: Epoch [3/5], Step [5260/6000], Loss: 0.2812\n",
      "Train O/P: Epoch [3/5], Step [5270/6000], Loss: 0.0259\n",
      "Train O/P: Epoch [3/5], Step [5280/6000], Loss: 0.4258\n",
      "Train O/P: Epoch [3/5], Step [5290/6000], Loss: 0.2815\n",
      "Train O/P: Epoch [3/5], Step [5300/6000], Loss: 0.0218\n",
      "Train O/P: Epoch [3/5], Step [5310/6000], Loss: 0.0737\n",
      "Train O/P: Epoch [3/5], Step [5320/6000], Loss: 0.0712\n",
      "Train O/P: Epoch [3/5], Step [5330/6000], Loss: 0.1304\n",
      "Train O/P: Epoch [3/5], Step [5340/6000], Loss: 0.0411\n",
      "Train O/P: Epoch [3/5], Step [5350/6000], Loss: 0.0753\n",
      "Train O/P: Epoch [3/5], Step [5360/6000], Loss: 0.0093\n",
      "Train O/P: Epoch [3/5], Step [5370/6000], Loss: 0.1342\n",
      "Train O/P: Epoch [3/5], Step [5380/6000], Loss: 0.0359\n",
      "Train O/P: Epoch [3/5], Step [5390/6000], Loss: 0.5074\n",
      "Train O/P: Epoch [3/5], Step [5400/6000], Loss: 0.0325\n",
      "Train O/P: Epoch [3/5], Step [5410/6000], Loss: 0.0300\n",
      "Train O/P: Epoch [3/5], Step [5420/6000], Loss: 0.0181\n",
      "Train O/P: Epoch [3/5], Step [5430/6000], Loss: 0.2705\n",
      "Train O/P: Epoch [3/5], Step [5440/6000], Loss: 0.0043\n",
      "Train O/P: Epoch [3/5], Step [5450/6000], Loss: 0.1021\n",
      "Train O/P: Epoch [3/5], Step [5460/6000], Loss: 0.0211\n",
      "Train O/P: Epoch [3/5], Step [5470/6000], Loss: 0.0843\n",
      "Train O/P: Epoch [3/5], Step [5480/6000], Loss: 0.1927\n",
      "Train O/P: Epoch [3/5], Step [5490/6000], Loss: 0.0107\n",
      "Train O/P: Epoch [3/5], Step [5500/6000], Loss: 0.4220\n",
      "Train O/P: Epoch [3/5], Step [5510/6000], Loss: 0.0185\n",
      "Train O/P: Epoch [3/5], Step [5520/6000], Loss: 0.0304\n",
      "Train O/P: Epoch [3/5], Step [5530/6000], Loss: 0.1228\n",
      "Train O/P: Epoch [3/5], Step [5540/6000], Loss: 0.0135\n",
      "Train O/P: Epoch [3/5], Step [5550/6000], Loss: 0.0788\n",
      "Train O/P: Epoch [3/5], Step [5560/6000], Loss: 0.0132\n",
      "Train O/P: Epoch [3/5], Step [5570/6000], Loss: 0.0532\n",
      "Train O/P: Epoch [3/5], Step [5580/6000], Loss: 0.2887\n",
      "Train O/P: Epoch [3/5], Step [5590/6000], Loss: 0.0060\n",
      "Train O/P: Epoch [3/5], Step [5600/6000], Loss: 0.1823\n",
      "Train O/P: Epoch [3/5], Step [5610/6000], Loss: 0.0204\n",
      "Train O/P: Epoch [3/5], Step [5620/6000], Loss: 0.0390\n",
      "Train O/P: Epoch [3/5], Step [5630/6000], Loss: 0.0824\n",
      "Train O/P: Epoch [3/5], Step [5640/6000], Loss: 0.0910\n",
      "Train O/P: Epoch [3/5], Step [5650/6000], Loss: 0.0352\n",
      "Train O/P: Epoch [3/5], Step [5660/6000], Loss: 0.0334\n",
      "Train O/P: Epoch [3/5], Step [5670/6000], Loss: 0.0607\n",
      "Train O/P: Epoch [3/5], Step [5680/6000], Loss: 0.0927\n",
      "Train O/P: Epoch [3/5], Step [5690/6000], Loss: 0.0339\n",
      "Train O/P: Epoch [3/5], Step [5700/6000], Loss: 0.0567\n",
      "Train O/P: Epoch [3/5], Step [5710/6000], Loss: 0.2437\n",
      "Train O/P: Epoch [3/5], Step [5720/6000], Loss: 0.0570\n",
      "Train O/P: Epoch [3/5], Step [5730/6000], Loss: 0.0088\n",
      "Train O/P: Epoch [3/5], Step [5740/6000], Loss: 0.1739\n",
      "Train O/P: Epoch [3/5], Step [5750/6000], Loss: 0.0053\n",
      "Train O/P: Epoch [3/5], Step [5760/6000], Loss: 0.0035\n",
      "Train O/P: Epoch [3/5], Step [5770/6000], Loss: 0.0627\n",
      "Train O/P: Epoch [3/5], Step [5780/6000], Loss: 0.0405\n",
      "Train O/P: Epoch [3/5], Step [5790/6000], Loss: 0.0232\n",
      "Train O/P: Epoch [3/5], Step [5800/6000], Loss: 0.2583\n",
      "Train O/P: Epoch [3/5], Step [5810/6000], Loss: 0.1356\n",
      "Train O/P: Epoch [3/5], Step [5820/6000], Loss: 0.1934\n",
      "Train O/P: Epoch [3/5], Step [5830/6000], Loss: 0.0181\n",
      "Train O/P: Epoch [3/5], Step [5840/6000], Loss: 0.3481\n",
      "Train O/P: Epoch [3/5], Step [5850/6000], Loss: 0.0925\n",
      "Train O/P: Epoch [3/5], Step [5860/6000], Loss: 0.0210\n",
      "Train O/P: Epoch [3/5], Step [5870/6000], Loss: 0.2411\n",
      "Train O/P: Epoch [3/5], Step [5880/6000], Loss: 0.0659\n",
      "Train O/P: Epoch [3/5], Step [5890/6000], Loss: 0.0416\n",
      "Train O/P: Epoch [3/5], Step [5900/6000], Loss: 0.0582\n",
      "Train O/P: Epoch [3/5], Step [5910/6000], Loss: 0.0243\n",
      "Train O/P: Epoch [3/5], Step [5920/6000], Loss: 0.0742\n",
      "Train O/P: Epoch [3/5], Step [5930/6000], Loss: 0.0506\n",
      "Train O/P: Epoch [3/5], Step [5940/6000], Loss: 0.0109\n",
      "Train O/P: Epoch [3/5], Step [5950/6000], Loss: 0.0842\n",
      "Train O/P: Epoch [3/5], Step [5960/6000], Loss: 0.0665\n",
      "Train O/P: Epoch [3/5], Step [5970/6000], Loss: 0.0311\n",
      "Train O/P: Epoch [3/5], Step [5980/6000], Loss: 0.1406\n",
      "Train O/P: Epoch [3/5], Step [5990/6000], Loss: 0.0959\n",
      "Train O/P: Epoch [3/5], Step [6000/6000], Loss: 0.0048\n",
      "Train O/P: Epoch [4/5], Step [10/6000], Loss: 0.0614\n",
      "Train O/P: Epoch [4/5], Step [20/6000], Loss: 0.2577\n",
      "Train O/P: Epoch [4/5], Step [30/6000], Loss: 0.0082\n",
      "Train O/P: Epoch [4/5], Step [40/6000], Loss: 0.2375\n",
      "Train O/P: Epoch [4/5], Step [50/6000], Loss: 0.1331\n",
      "Train O/P: Epoch [4/5], Step [60/6000], Loss: 0.0141\n",
      "Train O/P: Epoch [4/5], Step [70/6000], Loss: 0.1110\n",
      "Train O/P: Epoch [4/5], Step [80/6000], Loss: 0.0996\n",
      "Train O/P: Epoch [4/5], Step [90/6000], Loss: 0.2757\n",
      "Train O/P: Epoch [4/5], Step [100/6000], Loss: 0.2801\n",
      "Train O/P: Epoch [4/5], Step [110/6000], Loss: 0.2014\n",
      "Train O/P: Epoch [4/5], Step [120/6000], Loss: 0.1784\n",
      "Train O/P: Epoch [4/5], Step [130/6000], Loss: 0.0245\n",
      "Train O/P: Epoch [4/5], Step [140/6000], Loss: 0.3628\n",
      "Train O/P: Epoch [4/5], Step [150/6000], Loss: 0.0141\n",
      "Train O/P: Epoch [4/5], Step [160/6000], Loss: 0.0137\n",
      "Train O/P: Epoch [4/5], Step [170/6000], Loss: 0.0360\n",
      "Train O/P: Epoch [4/5], Step [180/6000], Loss: 0.0168\n",
      "Train O/P: Epoch [4/5], Step [190/6000], Loss: 0.0848\n",
      "Train O/P: Epoch [4/5], Step [200/6000], Loss: 0.0369\n",
      "Train O/P: Epoch [4/5], Step [210/6000], Loss: 0.0559\n",
      "Train O/P: Epoch [4/5], Step [220/6000], Loss: 0.0131\n",
      "Train O/P: Epoch [4/5], Step [230/6000], Loss: 0.0655\n",
      "Train O/P: Epoch [4/5], Step [240/6000], Loss: 0.0076\n",
      "Train O/P: Epoch [4/5], Step [250/6000], Loss: 0.1621\n",
      "Train O/P: Epoch [4/5], Step [260/6000], Loss: 0.2991\n",
      "Train O/P: Epoch [4/5], Step [270/6000], Loss: 0.1085\n",
      "Train O/P: Epoch [4/5], Step [280/6000], Loss: 0.0556\n",
      "Train O/P: Epoch [4/5], Step [290/6000], Loss: 0.1086\n",
      "Train O/P: Epoch [4/5], Step [300/6000], Loss: 0.0641\n",
      "Train O/P: Epoch [4/5], Step [310/6000], Loss: 0.0923\n",
      "Train O/P: Epoch [4/5], Step [320/6000], Loss: 0.0376\n",
      "Train O/P: Epoch [4/5], Step [330/6000], Loss: 0.0524\n",
      "Train O/P: Epoch [4/5], Step [340/6000], Loss: 0.0566\n",
      "Train O/P: Epoch [4/5], Step [350/6000], Loss: 0.0213\n",
      "Train O/P: Epoch [4/5], Step [360/6000], Loss: 0.0114\n",
      "Train O/P: Epoch [4/5], Step [370/6000], Loss: 0.0858\n",
      "Train O/P: Epoch [4/5], Step [380/6000], Loss: 0.0243\n",
      "Train O/P: Epoch [4/5], Step [390/6000], Loss: 0.0765\n",
      "Train O/P: Epoch [4/5], Step [400/6000], Loss: 0.0832\n",
      "Train O/P: Epoch [4/5], Step [410/6000], Loss: 0.0542\n",
      "Train O/P: Epoch [4/5], Step [420/6000], Loss: 0.2651\n",
      "Train O/P: Epoch [4/5], Step [430/6000], Loss: 0.2784\n",
      "Train O/P: Epoch [4/5], Step [440/6000], Loss: 0.0387\n",
      "Train O/P: Epoch [4/5], Step [450/6000], Loss: 0.0289\n",
      "Train O/P: Epoch [4/5], Step [460/6000], Loss: 0.4213\n",
      "Train O/P: Epoch [4/5], Step [470/6000], Loss: 0.3079\n",
      "Train O/P: Epoch [4/5], Step [480/6000], Loss: 0.1318\n",
      "Train O/P: Epoch [4/5], Step [490/6000], Loss: 0.1118\n",
      "Train O/P: Epoch [4/5], Step [500/6000], Loss: 0.0645\n",
      "Train O/P: Epoch [4/5], Step [510/6000], Loss: 0.3577\n",
      "Train O/P: Epoch [4/5], Step [520/6000], Loss: 0.0288\n",
      "Train O/P: Epoch [4/5], Step [530/6000], Loss: 0.3970\n",
      "Train O/P: Epoch [4/5], Step [540/6000], Loss: 0.0149\n",
      "Train O/P: Epoch [4/5], Step [550/6000], Loss: 0.4836\n",
      "Train O/P: Epoch [4/5], Step [560/6000], Loss: 0.0358\n",
      "Train O/P: Epoch [4/5], Step [570/6000], Loss: 0.3275\n",
      "Train O/P: Epoch [4/5], Step [580/6000], Loss: 0.0033\n",
      "Train O/P: Epoch [4/5], Step [590/6000], Loss: 0.0502\n",
      "Train O/P: Epoch [4/5], Step [600/6000], Loss: 0.0783\n",
      "Train O/P: Epoch [4/5], Step [610/6000], Loss: 0.4850\n",
      "Train O/P: Epoch [4/5], Step [620/6000], Loss: 0.0089\n",
      "Train O/P: Epoch [4/5], Step [630/6000], Loss: 0.0861\n",
      "Train O/P: Epoch [4/5], Step [640/6000], Loss: 0.2997\n",
      "Train O/P: Epoch [4/5], Step [650/6000], Loss: 0.3673\n",
      "Train O/P: Epoch [4/5], Step [660/6000], Loss: 0.0741\n",
      "Train O/P: Epoch [4/5], Step [670/6000], Loss: 0.0411\n",
      "Train O/P: Epoch [4/5], Step [680/6000], Loss: 0.0512\n",
      "Train O/P: Epoch [4/5], Step [690/6000], Loss: 0.0417\n",
      "Train O/P: Epoch [4/5], Step [700/6000], Loss: 0.3999\n",
      "Train O/P: Epoch [4/5], Step [710/6000], Loss: 0.0197\n",
      "Train O/P: Epoch [4/5], Step [720/6000], Loss: 0.2866\n",
      "Train O/P: Epoch [4/5], Step [730/6000], Loss: 0.0967\n",
      "Train O/P: Epoch [4/5], Step [740/6000], Loss: 0.0064\n",
      "Train O/P: Epoch [4/5], Step [750/6000], Loss: 0.0129\n",
      "Train O/P: Epoch [4/5], Step [760/6000], Loss: 0.0043\n",
      "Train O/P: Epoch [4/5], Step [770/6000], Loss: 0.0319\n",
      "Train O/P: Epoch [4/5], Step [780/6000], Loss: 0.0127\n",
      "Train O/P: Epoch [4/5], Step [790/6000], Loss: 0.2430\n",
      "Train O/P: Epoch [4/5], Step [800/6000], Loss: 0.2403\n",
      "Train O/P: Epoch [4/5], Step [810/6000], Loss: 0.1578\n",
      "Train O/P: Epoch [4/5], Step [820/6000], Loss: 0.0709\n",
      "Train O/P: Epoch [4/5], Step [830/6000], Loss: 0.0524\n",
      "Train O/P: Epoch [4/5], Step [840/6000], Loss: 0.2237\n",
      "Train O/P: Epoch [4/5], Step [850/6000], Loss: 0.1825\n",
      "Train O/P: Epoch [4/5], Step [860/6000], Loss: 0.1111\n",
      "Train O/P: Epoch [4/5], Step [870/6000], Loss: 0.0392\n",
      "Train O/P: Epoch [4/5], Step [880/6000], Loss: 0.0537\n",
      "Train O/P: Epoch [4/5], Step [890/6000], Loss: 1.1222\n",
      "Train O/P: Epoch [4/5], Step [900/6000], Loss: 0.0355\n",
      "Train O/P: Epoch [4/5], Step [910/6000], Loss: 0.0786\n",
      "Train O/P: Epoch [4/5], Step [920/6000], Loss: 0.0174\n",
      "Train O/P: Epoch [4/5], Step [930/6000], Loss: 0.0305\n",
      "Train O/P: Epoch [4/5], Step [940/6000], Loss: 0.0057\n",
      "Train O/P: Epoch [4/5], Step [950/6000], Loss: 0.0471\n",
      "Train O/P: Epoch [4/5], Step [960/6000], Loss: 0.0517\n",
      "Train O/P: Epoch [4/5], Step [970/6000], Loss: 0.0250\n",
      "Train O/P: Epoch [4/5], Step [980/6000], Loss: 0.0118\n",
      "Train O/P: Epoch [4/5], Step [990/6000], Loss: 0.0370\n",
      "Train O/P: Epoch [4/5], Step [1000/6000], Loss: 0.0389\n",
      "Train O/P: Epoch [4/5], Step [1010/6000], Loss: 0.0189\n",
      "Train O/P: Epoch [4/5], Step [1020/6000], Loss: 0.0912\n",
      "Train O/P: Epoch [4/5], Step [1030/6000], Loss: 0.0789\n",
      "Train O/P: Epoch [4/5], Step [1040/6000], Loss: 0.0529\n",
      "Train O/P: Epoch [4/5], Step [1050/6000], Loss: 0.1825\n",
      "Train O/P: Epoch [4/5], Step [1060/6000], Loss: 0.4145\n",
      "Train O/P: Epoch [4/5], Step [1070/6000], Loss: 0.0225\n",
      "Train O/P: Epoch [4/5], Step [1080/6000], Loss: 0.0144\n",
      "Train O/P: Epoch [4/5], Step [1090/6000], Loss: 0.1934\n",
      "Train O/P: Epoch [4/5], Step [1100/6000], Loss: 0.0016\n",
      "Train O/P: Epoch [4/5], Step [1110/6000], Loss: 0.2655\n",
      "Train O/P: Epoch [4/5], Step [1120/6000], Loss: 0.0124\n",
      "Train O/P: Epoch [4/5], Step [1130/6000], Loss: 0.0286\n",
      "Train O/P: Epoch [4/5], Step [1140/6000], Loss: 0.0683\n",
      "Train O/P: Epoch [4/5], Step [1150/6000], Loss: 0.1481\n",
      "Train O/P: Epoch [4/5], Step [1160/6000], Loss: 0.5572\n",
      "Train O/P: Epoch [4/5], Step [1170/6000], Loss: 0.1064\n",
      "Train O/P: Epoch [4/5], Step [1180/6000], Loss: 0.0671\n",
      "Train O/P: Epoch [4/5], Step [1190/6000], Loss: 0.1399\n",
      "Train O/P: Epoch [4/5], Step [1200/6000], Loss: 0.0097\n",
      "Train O/P: Epoch [4/5], Step [1210/6000], Loss: 0.0313\n",
      "Train O/P: Epoch [4/5], Step [1220/6000], Loss: 0.0139\n",
      "Train O/P: Epoch [4/5], Step [1230/6000], Loss: 0.1266\n",
      "Train O/P: Epoch [4/5], Step [1240/6000], Loss: 0.3176\n",
      "Train O/P: Epoch [4/5], Step [1250/6000], Loss: 0.0086\n",
      "Train O/P: Epoch [4/5], Step [1260/6000], Loss: 0.0338\n",
      "Train O/P: Epoch [4/5], Step [1270/6000], Loss: 0.0213\n",
      "Train O/P: Epoch [4/5], Step [1280/6000], Loss: 0.1319\n",
      "Train O/P: Epoch [4/5], Step [1290/6000], Loss: 0.0330\n",
      "Train O/P: Epoch [4/5], Step [1300/6000], Loss: 0.0703\n",
      "Train O/P: Epoch [4/5], Step [1310/6000], Loss: 0.0954\n",
      "Train O/P: Epoch [4/5], Step [1320/6000], Loss: 0.1599\n",
      "Train O/P: Epoch [4/5], Step [1330/6000], Loss: 0.2492\n",
      "Train O/P: Epoch [4/5], Step [1340/6000], Loss: 0.0154\n",
      "Train O/P: Epoch [4/5], Step [1350/6000], Loss: 0.5903\n",
      "Train O/P: Epoch [4/5], Step [1360/6000], Loss: 0.0197\n",
      "Train O/P: Epoch [4/5], Step [1370/6000], Loss: 0.0634\n",
      "Train O/P: Epoch [4/5], Step [1380/6000], Loss: 0.0506\n",
      "Train O/P: Epoch [4/5], Step [1390/6000], Loss: 0.2018\n",
      "Train O/P: Epoch [4/5], Step [1400/6000], Loss: 0.0291\n",
      "Train O/P: Epoch [4/5], Step [1410/6000], Loss: 0.2062\n",
      "Train O/P: Epoch [4/5], Step [1420/6000], Loss: 0.0180\n",
      "Train O/P: Epoch [4/5], Step [1430/6000], Loss: 0.0989\n",
      "Train O/P: Epoch [4/5], Step [1440/6000], Loss: 0.0607\n",
      "Train O/P: Epoch [4/5], Step [1450/6000], Loss: 0.0485\n",
      "Train O/P: Epoch [4/5], Step [1460/6000], Loss: 0.1504\n",
      "Train O/P: Epoch [4/5], Step [1470/6000], Loss: 0.0857\n",
      "Train O/P: Epoch [4/5], Step [1480/6000], Loss: 0.0780\n",
      "Train O/P: Epoch [4/5], Step [1490/6000], Loss: 0.1562\n",
      "Train O/P: Epoch [4/5], Step [1500/6000], Loss: 0.0243\n",
      "Train O/P: Epoch [4/5], Step [1510/6000], Loss: 0.7119\n",
      "Train O/P: Epoch [4/5], Step [1520/6000], Loss: 0.0291\n",
      "Train O/P: Epoch [4/5], Step [1530/6000], Loss: 0.1485\n",
      "Train O/P: Epoch [4/5], Step [1540/6000], Loss: 0.3402\n",
      "Train O/P: Epoch [4/5], Step [1550/6000], Loss: 0.2809\n",
      "Train O/P: Epoch [4/5], Step [1560/6000], Loss: 0.0256\n",
      "Train O/P: Epoch [4/5], Step [1570/6000], Loss: 0.0158\n",
      "Train O/P: Epoch [4/5], Step [1580/6000], Loss: 0.0552\n",
      "Train O/P: Epoch [4/5], Step [1590/6000], Loss: 0.0162\n",
      "Train O/P: Epoch [4/5], Step [1600/6000], Loss: 0.0496\n",
      "Train O/P: Epoch [4/5], Step [1610/6000], Loss: 0.0169\n",
      "Train O/P: Epoch [4/5], Step [1620/6000], Loss: 0.1739\n",
      "Train O/P: Epoch [4/5], Step [1630/6000], Loss: 0.0041\n",
      "Train O/P: Epoch [4/5], Step [1640/6000], Loss: 0.1287\n",
      "Train O/P: Epoch [4/5], Step [1650/6000], Loss: 0.2800\n",
      "Train O/P: Epoch [4/5], Step [1660/6000], Loss: 0.1512\n",
      "Train O/P: Epoch [4/5], Step [1670/6000], Loss: 0.0203\n",
      "Train O/P: Epoch [4/5], Step [1680/6000], Loss: 0.0107\n",
      "Train O/P: Epoch [4/5], Step [1690/6000], Loss: 0.1874\n",
      "Train O/P: Epoch [4/5], Step [1700/6000], Loss: 0.0347\n",
      "Train O/P: Epoch [4/5], Step [1710/6000], Loss: 0.1048\n",
      "Train O/P: Epoch [4/5], Step [1720/6000], Loss: 0.0982\n",
      "Train O/P: Epoch [4/5], Step [1730/6000], Loss: 0.0606\n",
      "Train O/P: Epoch [4/5], Step [1740/6000], Loss: 0.1928\n",
      "Train O/P: Epoch [4/5], Step [1750/6000], Loss: 0.0047\n",
      "Train O/P: Epoch [4/5], Step [1760/6000], Loss: 0.0320\n",
      "Train O/P: Epoch [4/5], Step [1770/6000], Loss: 0.0447\n",
      "Train O/P: Epoch [4/5], Step [1780/6000], Loss: 0.0297\n",
      "Train O/P: Epoch [4/5], Step [1790/6000], Loss: 0.0169\n",
      "Train O/P: Epoch [4/5], Step [1800/6000], Loss: 0.0491\n",
      "Train O/P: Epoch [4/5], Step [1810/6000], Loss: 0.2069\n",
      "Train O/P: Epoch [4/5], Step [1820/6000], Loss: 0.0329\n",
      "Train O/P: Epoch [4/5], Step [1830/6000], Loss: 0.1532\n",
      "Train O/P: Epoch [4/5], Step [1840/6000], Loss: 0.0323\n",
      "Train O/P: Epoch [4/5], Step [1850/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [4/5], Step [1860/6000], Loss: 0.1857\n",
      "Train O/P: Epoch [4/5], Step [1870/6000], Loss: 0.1836\n",
      "Train O/P: Epoch [4/5], Step [1880/6000], Loss: 0.1527\n",
      "Train O/P: Epoch [4/5], Step [1890/6000], Loss: 0.3693\n",
      "Train O/P: Epoch [4/5], Step [1900/6000], Loss: 0.0752\n",
      "Train O/P: Epoch [4/5], Step [1910/6000], Loss: 0.2993\n",
      "Train O/P: Epoch [4/5], Step [1920/6000], Loss: 0.1128\n",
      "Train O/P: Epoch [4/5], Step [1930/6000], Loss: 0.1531\n",
      "Train O/P: Epoch [4/5], Step [1940/6000], Loss: 0.1792\n",
      "Train O/P: Epoch [4/5], Step [1950/6000], Loss: 0.2200\n",
      "Train O/P: Epoch [4/5], Step [1960/6000], Loss: 0.1874\n",
      "Train O/P: Epoch [4/5], Step [1970/6000], Loss: 0.0807\n",
      "Train O/P: Epoch [4/5], Step [1980/6000], Loss: 0.0543\n",
      "Train O/P: Epoch [4/5], Step [1990/6000], Loss: 0.1658\n",
      "Train O/P: Epoch [4/5], Step [2000/6000], Loss: 0.3270\n",
      "Train O/P: Epoch [4/5], Step [2010/6000], Loss: 0.0432\n",
      "Train O/P: Epoch [4/5], Step [2020/6000], Loss: 0.0122\n",
      "Train O/P: Epoch [4/5], Step [2030/6000], Loss: 0.0857\n",
      "Train O/P: Epoch [4/5], Step [2040/6000], Loss: 0.0142\n",
      "Train O/P: Epoch [4/5], Step [2050/6000], Loss: 0.1266\n",
      "Train O/P: Epoch [4/5], Step [2060/6000], Loss: 0.0802\n",
      "Train O/P: Epoch [4/5], Step [2070/6000], Loss: 0.0508\n",
      "Train O/P: Epoch [4/5], Step [2080/6000], Loss: 0.0860\n",
      "Train O/P: Epoch [4/5], Step [2090/6000], Loss: 0.0260\n",
      "Train O/P: Epoch [4/5], Step [2100/6000], Loss: 0.1032\n",
      "Train O/P: Epoch [4/5], Step [2110/6000], Loss: 0.0202\n",
      "Train O/P: Epoch [4/5], Step [2120/6000], Loss: 0.0436\n",
      "Train O/P: Epoch [4/5], Step [2130/6000], Loss: 0.6305\n",
      "Train O/P: Epoch [4/5], Step [2140/6000], Loss: 0.0098\n",
      "Train O/P: Epoch [4/5], Step [2150/6000], Loss: 0.0622\n",
      "Train O/P: Epoch [4/5], Step [2160/6000], Loss: 0.0617\n",
      "Train O/P: Epoch [4/5], Step [2170/6000], Loss: 0.0388\n",
      "Train O/P: Epoch [4/5], Step [2180/6000], Loss: 0.0087\n",
      "Train O/P: Epoch [4/5], Step [2190/6000], Loss: 0.1282\n",
      "Train O/P: Epoch [4/5], Step [2200/6000], Loss: 0.2821\n",
      "Train O/P: Epoch [4/5], Step [2210/6000], Loss: 0.0357\n",
      "Train O/P: Epoch [4/5], Step [2220/6000], Loss: 0.0640\n",
      "Train O/P: Epoch [4/5], Step [2230/6000], Loss: 0.0601\n",
      "Train O/P: Epoch [4/5], Step [2240/6000], Loss: 0.5801\n",
      "Train O/P: Epoch [4/5], Step [2250/6000], Loss: 0.0770\n",
      "Train O/P: Epoch [4/5], Step [2260/6000], Loss: 0.0219\n",
      "Train O/P: Epoch [4/5], Step [2270/6000], Loss: 0.0296\n",
      "Train O/P: Epoch [4/5], Step [2280/6000], Loss: 0.0047\n",
      "Train O/P: Epoch [4/5], Step [2290/6000], Loss: 0.1287\n",
      "Train O/P: Epoch [4/5], Step [2300/6000], Loss: 0.0793\n",
      "Train O/P: Epoch [4/5], Step [2310/6000], Loss: 0.0654\n",
      "Train O/P: Epoch [4/5], Step [2320/6000], Loss: 0.2549\n",
      "Train O/P: Epoch [4/5], Step [2330/6000], Loss: 0.0082\n",
      "Train O/P: Epoch [4/5], Step [2340/6000], Loss: 0.0237\n",
      "Train O/P: Epoch [4/5], Step [2350/6000], Loss: 0.0054\n",
      "Train O/P: Epoch [4/5], Step [2360/6000], Loss: 0.0769\n",
      "Train O/P: Epoch [4/5], Step [2370/6000], Loss: 0.0176\n",
      "Train O/P: Epoch [4/5], Step [2380/6000], Loss: 0.0539\n",
      "Train O/P: Epoch [4/5], Step [2390/6000], Loss: 0.2038\n",
      "Train O/P: Epoch [4/5], Step [2400/6000], Loss: 0.0590\n",
      "Train O/P: Epoch [4/5], Step [2410/6000], Loss: 0.0413\n",
      "Train O/P: Epoch [4/5], Step [2420/6000], Loss: 0.1557\n",
      "Train O/P: Epoch [4/5], Step [2430/6000], Loss: 0.8207\n",
      "Train O/P: Epoch [4/5], Step [2440/6000], Loss: 0.1063\n",
      "Train O/P: Epoch [4/5], Step [2450/6000], Loss: 0.1050\n",
      "Train O/P: Epoch [4/5], Step [2460/6000], Loss: 0.0087\n",
      "Train O/P: Epoch [4/5], Step [2470/6000], Loss: 0.0661\n",
      "Train O/P: Epoch [4/5], Step [2480/6000], Loss: 0.2996\n",
      "Train O/P: Epoch [4/5], Step [2490/6000], Loss: 0.0194\n",
      "Train O/P: Epoch [4/5], Step [2500/6000], Loss: 0.0314\n",
      "Train O/P: Epoch [4/5], Step [2510/6000], Loss: 0.4835\n",
      "Train O/P: Epoch [4/5], Step [2520/6000], Loss: 0.2405\n",
      "Train O/P: Epoch [4/5], Step [2530/6000], Loss: 0.5265\n",
      "Train O/P: Epoch [4/5], Step [2540/6000], Loss: 0.1203\n",
      "Train O/P: Epoch [4/5], Step [2550/6000], Loss: 0.0091\n",
      "Train O/P: Epoch [4/5], Step [2560/6000], Loss: 0.0350\n",
      "Train O/P: Epoch [4/5], Step [2570/6000], Loss: 0.1442\n",
      "Train O/P: Epoch [4/5], Step [2580/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [4/5], Step [2590/6000], Loss: 0.1075\n",
      "Train O/P: Epoch [4/5], Step [2600/6000], Loss: 0.0314\n",
      "Train O/P: Epoch [4/5], Step [2610/6000], Loss: 0.0793\n",
      "Train O/P: Epoch [4/5], Step [2620/6000], Loss: 0.0134\n",
      "Train O/P: Epoch [4/5], Step [2630/6000], Loss: 0.0576\n",
      "Train O/P: Epoch [4/5], Step [2640/6000], Loss: 0.0982\n",
      "Train O/P: Epoch [4/5], Step [2650/6000], Loss: 0.0276\n",
      "Train O/P: Epoch [4/5], Step [2660/6000], Loss: 0.1586\n",
      "Train O/P: Epoch [4/5], Step [2670/6000], Loss: 0.0504\n",
      "Train O/P: Epoch [4/5], Step [2680/6000], Loss: 0.1739\n",
      "Train O/P: Epoch [4/5], Step [2690/6000], Loss: 0.0144\n",
      "Train O/P: Epoch [4/5], Step [2700/6000], Loss: 0.1435\n",
      "Train O/P: Epoch [4/5], Step [2710/6000], Loss: 0.0580\n",
      "Train O/P: Epoch [4/5], Step [2720/6000], Loss: 0.2486\n",
      "Train O/P: Epoch [4/5], Step [2730/6000], Loss: 0.1362\n",
      "Train O/P: Epoch [4/5], Step [2740/6000], Loss: 0.3335\n",
      "Train O/P: Epoch [4/5], Step [2750/6000], Loss: 0.0043\n",
      "Train O/P: Epoch [4/5], Step [2760/6000], Loss: 0.0385\n",
      "Train O/P: Epoch [4/5], Step [2770/6000], Loss: 0.0192\n",
      "Train O/P: Epoch [4/5], Step [2780/6000], Loss: 0.0441\n",
      "Train O/P: Epoch [4/5], Step [2790/6000], Loss: 0.2312\n",
      "Train O/P: Epoch [4/5], Step [2800/6000], Loss: 0.0085\n",
      "Train O/P: Epoch [4/5], Step [2810/6000], Loss: 0.0099\n",
      "Train O/P: Epoch [4/5], Step [2820/6000], Loss: 0.1743\n",
      "Train O/P: Epoch [4/5], Step [2830/6000], Loss: 0.0509\n",
      "Train O/P: Epoch [4/5], Step [2840/6000], Loss: 0.0309\n",
      "Train O/P: Epoch [4/5], Step [2850/6000], Loss: 0.0911\n",
      "Train O/P: Epoch [4/5], Step [2860/6000], Loss: 0.6666\n",
      "Train O/P: Epoch [4/5], Step [2870/6000], Loss: 0.0776\n",
      "Train O/P: Epoch [4/5], Step [2880/6000], Loss: 0.0944\n",
      "Train O/P: Epoch [4/5], Step [2890/6000], Loss: 0.0285\n",
      "Train O/P: Epoch [4/5], Step [2900/6000], Loss: 0.1719\n",
      "Train O/P: Epoch [4/5], Step [2910/6000], Loss: 0.0397\n",
      "Train O/P: Epoch [4/5], Step [2920/6000], Loss: 0.0191\n",
      "Train O/P: Epoch [4/5], Step [2930/6000], Loss: 0.1269\n",
      "Train O/P: Epoch [4/5], Step [2940/6000], Loss: 0.0548\n",
      "Train O/P: Epoch [4/5], Step [2950/6000], Loss: 0.0578\n",
      "Train O/P: Epoch [4/5], Step [2960/6000], Loss: 0.0440\n",
      "Train O/P: Epoch [4/5], Step [2970/6000], Loss: 0.0322\n",
      "Train O/P: Epoch [4/5], Step [2980/6000], Loss: 0.6075\n",
      "Train O/P: Epoch [4/5], Step [2990/6000], Loss: 0.0211\n",
      "Train O/P: Epoch [4/5], Step [3000/6000], Loss: 0.4012\n",
      "Train O/P: Epoch [4/5], Step [3010/6000], Loss: 0.1081\n",
      "Train O/P: Epoch [4/5], Step [3020/6000], Loss: 0.0515\n",
      "Train O/P: Epoch [4/5], Step [3030/6000], Loss: 0.0414\n",
      "Train O/P: Epoch [4/5], Step [3040/6000], Loss: 0.0260\n",
      "Train O/P: Epoch [4/5], Step [3050/6000], Loss: 0.0763\n",
      "Train O/P: Epoch [4/5], Step [3060/6000], Loss: 0.1836\n",
      "Train O/P: Epoch [4/5], Step [3070/6000], Loss: 0.1017\n",
      "Train O/P: Epoch [4/5], Step [3080/6000], Loss: 0.0918\n",
      "Train O/P: Epoch [4/5], Step [3090/6000], Loss: 0.0146\n",
      "Train O/P: Epoch [4/5], Step [3100/6000], Loss: 0.0729\n",
      "Train O/P: Epoch [4/5], Step [3110/6000], Loss: 0.3003\n",
      "Train O/P: Epoch [4/5], Step [3120/6000], Loss: 0.0328\n",
      "Train O/P: Epoch [4/5], Step [3130/6000], Loss: 0.0270\n",
      "Train O/P: Epoch [4/5], Step [3140/6000], Loss: 0.0527\n",
      "Train O/P: Epoch [4/5], Step [3150/6000], Loss: 0.0240\n",
      "Train O/P: Epoch [4/5], Step [3160/6000], Loss: 0.3743\n",
      "Train O/P: Epoch [4/5], Step [3170/6000], Loss: 0.0157\n",
      "Train O/P: Epoch [4/5], Step [3180/6000], Loss: 0.0175\n",
      "Train O/P: Epoch [4/5], Step [3190/6000], Loss: 0.0322\n",
      "Train O/P: Epoch [4/5], Step [3200/6000], Loss: 0.0197\n",
      "Train O/P: Epoch [4/5], Step [3210/6000], Loss: 0.0721\n",
      "Train O/P: Epoch [4/5], Step [3220/6000], Loss: 0.0348\n",
      "Train O/P: Epoch [4/5], Step [3230/6000], Loss: 0.0423\n",
      "Train O/P: Epoch [4/5], Step [3240/6000], Loss: 0.4060\n",
      "Train O/P: Epoch [4/5], Step [3250/6000], Loss: 0.1005\n",
      "Train O/P: Epoch [4/5], Step [3260/6000], Loss: 0.0079\n",
      "Train O/P: Epoch [4/5], Step [3270/6000], Loss: 0.3868\n",
      "Train O/P: Epoch [4/5], Step [3280/6000], Loss: 0.0083\n",
      "Train O/P: Epoch [4/5], Step [3290/6000], Loss: 0.0858\n",
      "Train O/P: Epoch [4/5], Step [3300/6000], Loss: 0.0394\n",
      "Train O/P: Epoch [4/5], Step [3310/6000], Loss: 0.0460\n",
      "Train O/P: Epoch [4/5], Step [3320/6000], Loss: 0.0435\n",
      "Train O/P: Epoch [4/5], Step [3330/6000], Loss: 0.0986\n",
      "Train O/P: Epoch [4/5], Step [3340/6000], Loss: 0.2864\n",
      "Train O/P: Epoch [4/5], Step [3350/6000], Loss: 0.1170\n",
      "Train O/P: Epoch [4/5], Step [3360/6000], Loss: 0.4699\n",
      "Train O/P: Epoch [4/5], Step [3370/6000], Loss: 0.0285\n",
      "Train O/P: Epoch [4/5], Step [3380/6000], Loss: 0.1301\n",
      "Train O/P: Epoch [4/5], Step [3390/6000], Loss: 0.0103\n",
      "Train O/P: Epoch [4/5], Step [3400/6000], Loss: 0.0667\n",
      "Train O/P: Epoch [4/5], Step [3410/6000], Loss: 0.0543\n",
      "Train O/P: Epoch [4/5], Step [3420/6000], Loss: 0.1349\n",
      "Train O/P: Epoch [4/5], Step [3430/6000], Loss: 0.1840\n",
      "Train O/P: Epoch [4/5], Step [3440/6000], Loss: 0.0133\n",
      "Train O/P: Epoch [4/5], Step [3450/6000], Loss: 0.0232\n",
      "Train O/P: Epoch [4/5], Step [3460/6000], Loss: 0.3236\n",
      "Train O/P: Epoch [4/5], Step [3470/6000], Loss: 0.0761\n",
      "Train O/P: Epoch [4/5], Step [3480/6000], Loss: 0.0175\n",
      "Train O/P: Epoch [4/5], Step [3490/6000], Loss: 0.0470\n",
      "Train O/P: Epoch [4/5], Step [3500/6000], Loss: 0.0535\n",
      "Train O/P: Epoch [4/5], Step [3510/6000], Loss: 0.1169\n",
      "Train O/P: Epoch [4/5], Step [3520/6000], Loss: 0.1383\n",
      "Train O/P: Epoch [4/5], Step [3530/6000], Loss: 0.0214\n",
      "Train O/P: Epoch [4/5], Step [3540/6000], Loss: 0.0352\n",
      "Train O/P: Epoch [4/5], Step [3550/6000], Loss: 0.0117\n",
      "Train O/P: Epoch [4/5], Step [3560/6000], Loss: 0.0235\n",
      "Train O/P: Epoch [4/5], Step [3570/6000], Loss: 0.2023\n",
      "Train O/P: Epoch [4/5], Step [3580/6000], Loss: 0.0132\n",
      "Train O/P: Epoch [4/5], Step [3590/6000], Loss: 0.0197\n",
      "Train O/P: Epoch [4/5], Step [3600/6000], Loss: 0.0360\n",
      "Train O/P: Epoch [4/5], Step [3610/6000], Loss: 0.0403\n",
      "Train O/P: Epoch [4/5], Step [3620/6000], Loss: 0.2393\n",
      "Train O/P: Epoch [4/5], Step [3630/6000], Loss: 0.1748\n",
      "Train O/P: Epoch [4/5], Step [3640/6000], Loss: 0.0161\n",
      "Train O/P: Epoch [4/5], Step [3650/6000], Loss: 0.0526\n",
      "Train O/P: Epoch [4/5], Step [3660/6000], Loss: 0.0393\n",
      "Train O/P: Epoch [4/5], Step [3670/6000], Loss: 0.0454\n",
      "Train O/P: Epoch [4/5], Step [3680/6000], Loss: 0.0182\n",
      "Train O/P: Epoch [4/5], Step [3690/6000], Loss: 0.2934\n",
      "Train O/P: Epoch [4/5], Step [3700/6000], Loss: 0.0173\n",
      "Train O/P: Epoch [4/5], Step [3710/6000], Loss: 0.0176\n",
      "Train O/P: Epoch [4/5], Step [3720/6000], Loss: 0.0888\n",
      "Train O/P: Epoch [4/5], Step [3730/6000], Loss: 0.1187\n",
      "Train O/P: Epoch [4/5], Step [3740/6000], Loss: 0.0668\n",
      "Train O/P: Epoch [4/5], Step [3750/6000], Loss: 0.0090\n",
      "Train O/P: Epoch [4/5], Step [3760/6000], Loss: 0.0202\n",
      "Train O/P: Epoch [4/5], Step [3770/6000], Loss: 0.0235\n",
      "Train O/P: Epoch [4/5], Step [3780/6000], Loss: 0.0268\n",
      "Train O/P: Epoch [4/5], Step [3790/6000], Loss: 0.1069\n",
      "Train O/P: Epoch [4/5], Step [3800/6000], Loss: 0.1482\n",
      "Train O/P: Epoch [4/5], Step [3810/6000], Loss: 0.1113\n",
      "Train O/P: Epoch [4/5], Step [3820/6000], Loss: 0.0853\n",
      "Train O/P: Epoch [4/5], Step [3830/6000], Loss: 0.3951\n",
      "Train O/P: Epoch [4/5], Step [3840/6000], Loss: 0.0223\n",
      "Train O/P: Epoch [4/5], Step [3850/6000], Loss: 0.0189\n",
      "Train O/P: Epoch [4/5], Step [3860/6000], Loss: 0.0062\n",
      "Train O/P: Epoch [4/5], Step [3870/6000], Loss: 0.0941\n",
      "Train O/P: Epoch [4/5], Step [3880/6000], Loss: 0.0849\n",
      "Train O/P: Epoch [4/5], Step [3890/6000], Loss: 0.0489\n",
      "Train O/P: Epoch [4/5], Step [3900/6000], Loss: 0.0129\n",
      "Train O/P: Epoch [4/5], Step [3910/6000], Loss: 0.1592\n",
      "Train O/P: Epoch [4/5], Step [3920/6000], Loss: 0.1027\n",
      "Train O/P: Epoch [4/5], Step [3930/6000], Loss: 0.2163\n",
      "Train O/P: Epoch [4/5], Step [3940/6000], Loss: 0.0745\n",
      "Train O/P: Epoch [4/5], Step [3950/6000], Loss: 0.0755\n",
      "Train O/P: Epoch [4/5], Step [3960/6000], Loss: 0.0578\n",
      "Train O/P: Epoch [4/5], Step [3970/6000], Loss: 0.0089\n",
      "Train O/P: Epoch [4/5], Step [3980/6000], Loss: 0.0759\n",
      "Train O/P: Epoch [4/5], Step [3990/6000], Loss: 0.0426\n",
      "Train O/P: Epoch [4/5], Step [4000/6000], Loss: 0.0820\n",
      "Train O/P: Epoch [4/5], Step [4010/6000], Loss: 0.0106\n",
      "Train O/P: Epoch [4/5], Step [4020/6000], Loss: 0.0386\n",
      "Train O/P: Epoch [4/5], Step [4030/6000], Loss: 0.4094\n",
      "Train O/P: Epoch [4/5], Step [4040/6000], Loss: 0.0044\n",
      "Train O/P: Epoch [4/5], Step [4050/6000], Loss: 0.0176\n",
      "Train O/P: Epoch [4/5], Step [4060/6000], Loss: 0.0464\n",
      "Train O/P: Epoch [4/5], Step [4070/6000], Loss: 0.2034\n",
      "Train O/P: Epoch [4/5], Step [4080/6000], Loss: 0.0501\n",
      "Train O/P: Epoch [4/5], Step [4090/6000], Loss: 0.0535\n",
      "Train O/P: Epoch [4/5], Step [4100/6000], Loss: 0.0311\n",
      "Train O/P: Epoch [4/5], Step [4110/6000], Loss: 0.0077\n",
      "Train O/P: Epoch [4/5], Step [4120/6000], Loss: 0.0430\n",
      "Train O/P: Epoch [4/5], Step [4130/6000], Loss: 0.0236\n",
      "Train O/P: Epoch [4/5], Step [4140/6000], Loss: 0.0354\n",
      "Train O/P: Epoch [4/5], Step [4150/6000], Loss: 0.0771\n",
      "Train O/P: Epoch [4/5], Step [4160/6000], Loss: 0.2195\n",
      "Train O/P: Epoch [4/5], Step [4170/6000], Loss: 0.0064\n",
      "Train O/P: Epoch [4/5], Step [4180/6000], Loss: 0.1813\n",
      "Train O/P: Epoch [4/5], Step [4190/6000], Loss: 0.0075\n",
      "Train O/P: Epoch [4/5], Step [4200/6000], Loss: 0.0080\n",
      "Train O/P: Epoch [4/5], Step [4210/6000], Loss: 0.0519\n",
      "Train O/P: Epoch [4/5], Step [4220/6000], Loss: 0.0071\n",
      "Train O/P: Epoch [4/5], Step [4230/6000], Loss: 0.0459\n",
      "Train O/P: Epoch [4/5], Step [4240/6000], Loss: 0.0350\n",
      "Train O/P: Epoch [4/5], Step [4250/6000], Loss: 0.3939\n",
      "Train O/P: Epoch [4/5], Step [4260/6000], Loss: 0.0169\n",
      "Train O/P: Epoch [4/5], Step [4270/6000], Loss: 0.0141\n",
      "Train O/P: Epoch [4/5], Step [4280/6000], Loss: 0.0074\n",
      "Train O/P: Epoch [4/5], Step [4290/6000], Loss: 0.0109\n",
      "Train O/P: Epoch [4/5], Step [4300/6000], Loss: 0.0115\n",
      "Train O/P: Epoch [4/5], Step [4310/6000], Loss: 0.0888\n",
      "Train O/P: Epoch [4/5], Step [4320/6000], Loss: 0.0689\n",
      "Train O/P: Epoch [4/5], Step [4330/6000], Loss: 0.0753\n",
      "Train O/P: Epoch [4/5], Step [4340/6000], Loss: 0.1249\n",
      "Train O/P: Epoch [4/5], Step [4350/6000], Loss: 0.0384\n",
      "Train O/P: Epoch [4/5], Step [4360/6000], Loss: 0.0269\n",
      "Train O/P: Epoch [4/5], Step [4370/6000], Loss: 0.0540\n",
      "Train O/P: Epoch [4/5], Step [4380/6000], Loss: 0.0584\n",
      "Train O/P: Epoch [4/5], Step [4390/6000], Loss: 0.1002\n",
      "Train O/P: Epoch [4/5], Step [4400/6000], Loss: 0.0168\n",
      "Train O/P: Epoch [4/5], Step [4410/6000], Loss: 0.0463\n",
      "Train O/P: Epoch [4/5], Step [4420/6000], Loss: 0.4455\n",
      "Train O/P: Epoch [4/5], Step [4430/6000], Loss: 0.0217\n",
      "Train O/P: Epoch [4/5], Step [4440/6000], Loss: 0.0118\n",
      "Train O/P: Epoch [4/5], Step [4450/6000], Loss: 0.0410\n",
      "Train O/P: Epoch [4/5], Step [4460/6000], Loss: 0.4679\n",
      "Train O/P: Epoch [4/5], Step [4470/6000], Loss: 0.2756\n",
      "Train O/P: Epoch [4/5], Step [4480/6000], Loss: 0.0172\n",
      "Train O/P: Epoch [4/5], Step [4490/6000], Loss: 0.0532\n",
      "Train O/P: Epoch [4/5], Step [4500/6000], Loss: 0.0211\n",
      "Train O/P: Epoch [4/5], Step [4510/6000], Loss: 0.5267\n",
      "Train O/P: Epoch [4/5], Step [4520/6000], Loss: 0.0352\n",
      "Train O/P: Epoch [4/5], Step [4530/6000], Loss: 0.1868\n",
      "Train O/P: Epoch [4/5], Step [4540/6000], Loss: 0.0120\n",
      "Train O/P: Epoch [4/5], Step [4550/6000], Loss: 0.0298\n",
      "Train O/P: Epoch [4/5], Step [4560/6000], Loss: 0.0276\n",
      "Train O/P: Epoch [4/5], Step [4570/6000], Loss: 0.0302\n",
      "Train O/P: Epoch [4/5], Step [4580/6000], Loss: 0.0269\n",
      "Train O/P: Epoch [4/5], Step [4590/6000], Loss: 0.0249\n",
      "Train O/P: Epoch [4/5], Step [4600/6000], Loss: 0.2608\n",
      "Train O/P: Epoch [4/5], Step [4610/6000], Loss: 0.2069\n",
      "Train O/P: Epoch [4/5], Step [4620/6000], Loss: 0.1095\n",
      "Train O/P: Epoch [4/5], Step [4630/6000], Loss: 0.0505\n",
      "Train O/P: Epoch [4/5], Step [4640/6000], Loss: 0.0341\n",
      "Train O/P: Epoch [4/5], Step [4650/6000], Loss: 0.0419\n",
      "Train O/P: Epoch [4/5], Step [4660/6000], Loss: 0.1251\n",
      "Train O/P: Epoch [4/5], Step [4670/6000], Loss: 0.1647\n",
      "Train O/P: Epoch [4/5], Step [4680/6000], Loss: 0.2240\n",
      "Train O/P: Epoch [4/5], Step [4690/6000], Loss: 0.0810\n",
      "Train O/P: Epoch [4/5], Step [4700/6000], Loss: 0.0575\n",
      "Train O/P: Epoch [4/5], Step [4710/6000], Loss: 0.2641\n",
      "Train O/P: Epoch [4/5], Step [4720/6000], Loss: 0.0623\n",
      "Train O/P: Epoch [4/5], Step [4730/6000], Loss: 0.1539\n",
      "Train O/P: Epoch [4/5], Step [4740/6000], Loss: 0.0188\n",
      "Train O/P: Epoch [4/5], Step [4750/6000], Loss: 0.0362\n",
      "Train O/P: Epoch [4/5], Step [4760/6000], Loss: 0.0816\n",
      "Train O/P: Epoch [4/5], Step [4770/6000], Loss: 0.0332\n",
      "Train O/P: Epoch [4/5], Step [4780/6000], Loss: 0.0397\n",
      "Train O/P: Epoch [4/5], Step [4790/6000], Loss: 0.0228\n",
      "Train O/P: Epoch [4/5], Step [4800/6000], Loss: 0.0735\n",
      "Train O/P: Epoch [4/5], Step [4810/6000], Loss: 0.0315\n",
      "Train O/P: Epoch [4/5], Step [4820/6000], Loss: 0.2141\n",
      "Train O/P: Epoch [4/5], Step [4830/6000], Loss: 0.0082\n",
      "Train O/P: Epoch [4/5], Step [4840/6000], Loss: 0.0247\n",
      "Train O/P: Epoch [4/5], Step [4850/6000], Loss: 0.0639\n",
      "Train O/P: Epoch [4/5], Step [4860/6000], Loss: 0.0263\n",
      "Train O/P: Epoch [4/5], Step [4870/6000], Loss: 0.2042\n",
      "Train O/P: Epoch [4/5], Step [4880/6000], Loss: 0.3347\n",
      "Train O/P: Epoch [4/5], Step [4890/6000], Loss: 0.1891\n",
      "Train O/P: Epoch [4/5], Step [4900/6000], Loss: 0.0431\n",
      "Train O/P: Epoch [4/5], Step [4910/6000], Loss: 0.0494\n",
      "Train O/P: Epoch [4/5], Step [4920/6000], Loss: 0.0432\n",
      "Train O/P: Epoch [4/5], Step [4930/6000], Loss: 0.1375\n",
      "Train O/P: Epoch [4/5], Step [4940/6000], Loss: 0.2407\n",
      "Train O/P: Epoch [4/5], Step [4950/6000], Loss: 0.3069\n",
      "Train O/P: Epoch [4/5], Step [4960/6000], Loss: 0.0075\n",
      "Train O/P: Epoch [4/5], Step [4970/6000], Loss: 0.1943\n",
      "Train O/P: Epoch [4/5], Step [4980/6000], Loss: 0.2006\n",
      "Train O/P: Epoch [4/5], Step [4990/6000], Loss: 0.0096\n",
      "Train O/P: Epoch [4/5], Step [5000/6000], Loss: 0.2201\n",
      "Train O/P: Epoch [4/5], Step [5010/6000], Loss: 0.1554\n",
      "Train O/P: Epoch [4/5], Step [5020/6000], Loss: 0.0113\n",
      "Train O/P: Epoch [4/5], Step [5030/6000], Loss: 0.0713\n",
      "Train O/P: Epoch [4/5], Step [5040/6000], Loss: 0.0801\n",
      "Train O/P: Epoch [4/5], Step [5050/6000], Loss: 0.0703\n",
      "Train O/P: Epoch [4/5], Step [5060/6000], Loss: 0.5600\n",
      "Train O/P: Epoch [4/5], Step [5070/6000], Loss: 0.0064\n",
      "Train O/P: Epoch [4/5], Step [5080/6000], Loss: 0.0707\n",
      "Train O/P: Epoch [4/5], Step [5090/6000], Loss: 0.0950\n",
      "Train O/P: Epoch [4/5], Step [5100/6000], Loss: 0.2146\n",
      "Train O/P: Epoch [4/5], Step [5110/6000], Loss: 0.0917\n",
      "Train O/P: Epoch [4/5], Step [5120/6000], Loss: 0.0654\n",
      "Train O/P: Epoch [4/5], Step [5130/6000], Loss: 0.0385\n",
      "Train O/P: Epoch [4/5], Step [5140/6000], Loss: 0.0879\n",
      "Train O/P: Epoch [4/5], Step [5150/6000], Loss: 0.0160\n",
      "Train O/P: Epoch [4/5], Step [5160/6000], Loss: 0.0198\n",
      "Train O/P: Epoch [4/5], Step [5170/6000], Loss: 0.1322\n",
      "Train O/P: Epoch [4/5], Step [5180/6000], Loss: 0.0932\n",
      "Train O/P: Epoch [4/5], Step [5190/6000], Loss: 0.1239\n",
      "Train O/P: Epoch [4/5], Step [5200/6000], Loss: 0.0064\n",
      "Train O/P: Epoch [4/5], Step [5210/6000], Loss: 0.1889\n",
      "Train O/P: Epoch [4/5], Step [5220/6000], Loss: 0.1039\n",
      "Train O/P: Epoch [4/5], Step [5230/6000], Loss: 0.0425\n",
      "Train O/P: Epoch [4/5], Step [5240/6000], Loss: 0.1122\n",
      "Train O/P: Epoch [4/5], Step [5250/6000], Loss: 0.0390\n",
      "Train O/P: Epoch [4/5], Step [5260/6000], Loss: 0.0599\n",
      "Train O/P: Epoch [4/5], Step [5270/6000], Loss: 0.0231\n",
      "Train O/P: Epoch [4/5], Step [5280/6000], Loss: 0.0908\n",
      "Train O/P: Epoch [4/5], Step [5290/6000], Loss: 0.2301\n",
      "Train O/P: Epoch [4/5], Step [5300/6000], Loss: 0.0128\n",
      "Train O/P: Epoch [4/5], Step [5310/6000], Loss: 0.3790\n",
      "Train O/P: Epoch [4/5], Step [5320/6000], Loss: 0.1212\n",
      "Train O/P: Epoch [4/5], Step [5330/6000], Loss: 0.0446\n",
      "Train O/P: Epoch [4/5], Step [5340/6000], Loss: 0.2412\n",
      "Train O/P: Epoch [4/5], Step [5350/6000], Loss: 0.0233\n",
      "Train O/P: Epoch [4/5], Step [5360/6000], Loss: 0.0622\n",
      "Train O/P: Epoch [4/5], Step [5370/6000], Loss: 0.1974\n",
      "Train O/P: Epoch [4/5], Step [5380/6000], Loss: 0.0066\n",
      "Train O/P: Epoch [4/5], Step [5390/6000], Loss: 0.0384\n",
      "Train O/P: Epoch [4/5], Step [5400/6000], Loss: 0.0078\n",
      "Train O/P: Epoch [4/5], Step [5410/6000], Loss: 0.3051\n",
      "Train O/P: Epoch [4/5], Step [5420/6000], Loss: 0.3634\n",
      "Train O/P: Epoch [4/5], Step [5430/6000], Loss: 0.1366\n",
      "Train O/P: Epoch [4/5], Step [5440/6000], Loss: 0.1173\n",
      "Train O/P: Epoch [4/5], Step [5450/6000], Loss: 0.0082\n",
      "Train O/P: Epoch [4/5], Step [5460/6000], Loss: 0.0753\n",
      "Train O/P: Epoch [4/5], Step [5470/6000], Loss: 0.0544\n",
      "Train O/P: Epoch [4/5], Step [5480/6000], Loss: 0.0280\n",
      "Train O/P: Epoch [4/5], Step [5490/6000], Loss: 0.0368\n",
      "Train O/P: Epoch [4/5], Step [5500/6000], Loss: 0.0175\n",
      "Train O/P: Epoch [4/5], Step [5510/6000], Loss: 0.0978\n",
      "Train O/P: Epoch [4/5], Step [5520/6000], Loss: 0.0451\n",
      "Train O/P: Epoch [4/5], Step [5530/6000], Loss: 0.0275\n",
      "Train O/P: Epoch [4/5], Step [5540/6000], Loss: 0.2881\n",
      "Train O/P: Epoch [4/5], Step [5550/6000], Loss: 0.0047\n",
      "Train O/P: Epoch [4/5], Step [5560/6000], Loss: 0.0129\n",
      "Train O/P: Epoch [4/5], Step [5570/6000], Loss: 0.1598\n",
      "Train O/P: Epoch [4/5], Step [5580/6000], Loss: 0.0533\n",
      "Train O/P: Epoch [4/5], Step [5590/6000], Loss: 0.2908\n",
      "Train O/P: Epoch [4/5], Step [5600/6000], Loss: 0.0853\n",
      "Train O/P: Epoch [4/5], Step [5610/6000], Loss: 0.0396\n",
      "Train O/P: Epoch [4/5], Step [5620/6000], Loss: 0.0163\n",
      "Train O/P: Epoch [4/5], Step [5630/6000], Loss: 0.3162\n",
      "Train O/P: Epoch [4/5], Step [5640/6000], Loss: 0.0895\n",
      "Train O/P: Epoch [4/5], Step [5650/6000], Loss: 0.0205\n",
      "Train O/P: Epoch [4/5], Step [5660/6000], Loss: 0.3678\n",
      "Train O/P: Epoch [4/5], Step [5670/6000], Loss: 0.0219\n",
      "Train O/P: Epoch [4/5], Step [5680/6000], Loss: 0.3899\n",
      "Train O/P: Epoch [4/5], Step [5690/6000], Loss: 0.1008\n",
      "Train O/P: Epoch [4/5], Step [5700/6000], Loss: 0.0202\n",
      "Train O/P: Epoch [4/5], Step [5710/6000], Loss: 0.0996\n",
      "Train O/P: Epoch [4/5], Step [5720/6000], Loss: 0.0267\n",
      "Train O/P: Epoch [4/5], Step [5730/6000], Loss: 0.0406\n",
      "Train O/P: Epoch [4/5], Step [5740/6000], Loss: 0.0808\n",
      "Train O/P: Epoch [4/5], Step [5750/6000], Loss: 0.0625\n",
      "Train O/P: Epoch [4/5], Step [5760/6000], Loss: 0.0087\n",
      "Train O/P: Epoch [4/5], Step [5770/6000], Loss: 0.0083\n",
      "Train O/P: Epoch [4/5], Step [5780/6000], Loss: 0.3562\n",
      "Train O/P: Epoch [4/5], Step [5790/6000], Loss: 0.0131\n",
      "Train O/P: Epoch [4/5], Step [5800/6000], Loss: 0.0230\n",
      "Train O/P: Epoch [4/5], Step [5810/6000], Loss: 0.1553\n",
      "Train O/P: Epoch [4/5], Step [5820/6000], Loss: 0.0436\n",
      "Train O/P: Epoch [4/5], Step [5830/6000], Loss: 0.0215\n",
      "Train O/P: Epoch [4/5], Step [5840/6000], Loss: 0.2030\n",
      "Train O/P: Epoch [4/5], Step [5850/6000], Loss: 0.0179\n",
      "Train O/P: Epoch [4/5], Step [5860/6000], Loss: 0.2864\n",
      "Train O/P: Epoch [4/5], Step [5870/6000], Loss: 0.0570\n",
      "Train O/P: Epoch [4/5], Step [5880/6000], Loss: 0.0321\n",
      "Train O/P: Epoch [4/5], Step [5890/6000], Loss: 0.0063\n",
      "Train O/P: Epoch [4/5], Step [5900/6000], Loss: 0.0422\n",
      "Train O/P: Epoch [4/5], Step [5910/6000], Loss: 0.2307\n",
      "Train O/P: Epoch [4/5], Step [5920/6000], Loss: 0.0045\n",
      "Train O/P: Epoch [4/5], Step [5930/6000], Loss: 0.0883\n",
      "Train O/P: Epoch [4/5], Step [5940/6000], Loss: 0.0297\n",
      "Train O/P: Epoch [4/5], Step [5950/6000], Loss: 0.0236\n",
      "Train O/P: Epoch [4/5], Step [5960/6000], Loss: 0.0435\n",
      "Train O/P: Epoch [4/5], Step [5970/6000], Loss: 0.0623\n",
      "Train O/P: Epoch [4/5], Step [5980/6000], Loss: 0.0506\n",
      "Train O/P: Epoch [4/5], Step [5990/6000], Loss: 0.0513\n",
      "Train O/P: Epoch [4/5], Step [6000/6000], Loss: 0.0768\n",
      "Train O/P: Epoch [5/5], Step [10/6000], Loss: 0.0090\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [20/6000], Loss: 0.4600\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [30/6000], Loss: 0.2434\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [40/6000], Loss: 0.4019\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [50/6000], Loss: 0.2461\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [60/6000], Loss: 0.0789\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [70/6000], Loss: 0.1734\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [80/6000], Loss: 0.0117\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [90/6000], Loss: 0.0229\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [100/6000], Loss: 0.0689\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [110/6000], Loss: 0.1240\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [120/6000], Loss: 0.0672\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [130/6000], Loss: 0.0147\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [140/6000], Loss: 0.0685\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [150/6000], Loss: 0.0689\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [160/6000], Loss: 0.3312\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [170/6000], Loss: 0.0935\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [180/6000], Loss: 0.2746\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [190/6000], Loss: 0.0558\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [200/6000], Loss: 0.0244\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [210/6000], Loss: 0.0315\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [220/6000], Loss: 0.0226\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [230/6000], Loss: 0.0812\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [240/6000], Loss: 0.4280\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [250/6000], Loss: 0.1059\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [260/6000], Loss: 0.0252\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [270/6000], Loss: 0.0228\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [280/6000], Loss: 0.5848\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [290/6000], Loss: 0.0556\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [300/6000], Loss: 0.0155\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [310/6000], Loss: 0.0056\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [320/6000], Loss: 0.3793\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [330/6000], Loss: 0.0189\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [340/6000], Loss: 0.1730\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [350/6000], Loss: 0.0175\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [360/6000], Loss: 0.2557\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [370/6000], Loss: 0.0417\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [380/6000], Loss: 0.0182\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [390/6000], Loss: 0.0230\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [400/6000], Loss: 0.0984\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [410/6000], Loss: 0.0339\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [420/6000], Loss: 0.1195\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [430/6000], Loss: 0.0550\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [440/6000], Loss: 0.4241\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [450/6000], Loss: 0.4428\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [460/6000], Loss: 0.0399\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [470/6000], Loss: 0.2158\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [480/6000], Loss: 0.0662\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [490/6000], Loss: 0.5126\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [500/6000], Loss: 0.2705\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [510/6000], Loss: 0.0079\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [520/6000], Loss: 0.0151\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [530/6000], Loss: 0.1737\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [540/6000], Loss: 0.0927\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [550/6000], Loss: 0.0871\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [560/6000], Loss: 0.0383\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [570/6000], Loss: 0.0162\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [580/6000], Loss: 0.0479\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [590/6000], Loss: 0.2477\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [600/6000], Loss: 0.1445\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [610/6000], Loss: 0.2386\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [620/6000], Loss: 0.0590\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [630/6000], Loss: 0.2879\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [640/6000], Loss: 0.0321\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [650/6000], Loss: 0.1245\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [660/6000], Loss: 0.0674\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [670/6000], Loss: 0.0085\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [680/6000], Loss: 0.0516\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [690/6000], Loss: 0.1851\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [700/6000], Loss: 0.0960\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [710/6000], Loss: 0.0133\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [720/6000], Loss: 0.0261\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [730/6000], Loss: 0.1948\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [740/6000], Loss: 0.0156\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [750/6000], Loss: 0.0813\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [760/6000], Loss: 0.2223\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [770/6000], Loss: 0.0298\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [780/6000], Loss: 0.0830\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [790/6000], Loss: 0.0289\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [800/6000], Loss: 0.0334\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [810/6000], Loss: 0.0054\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [820/6000], Loss: 0.3928\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [830/6000], Loss: 0.0294\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [840/6000], Loss: 0.0307\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [850/6000], Loss: 0.1583\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [860/6000], Loss: 0.1041\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [870/6000], Loss: 0.0366\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [880/6000], Loss: 0.0725\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [890/6000], Loss: 0.0428\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [900/6000], Loss: 0.2321\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [910/6000], Loss: 0.0391\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [920/6000], Loss: 0.0283\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [930/6000], Loss: 0.2245\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [940/6000], Loss: 0.3131\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [950/6000], Loss: 0.0614\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [960/6000], Loss: 0.2685\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [970/6000], Loss: 0.1197\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [980/6000], Loss: 0.0055\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [990/6000], Loss: 0.0663\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1000/6000], Loss: 0.0938\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1010/6000], Loss: 0.1209\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1020/6000], Loss: 0.2374\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1030/6000], Loss: 0.0179\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1040/6000], Loss: 0.0176\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1050/6000], Loss: 0.0603\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1060/6000], Loss: 0.0247\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1070/6000], Loss: 0.0120\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1080/6000], Loss: 0.0886\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1090/6000], Loss: 0.0649\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1100/6000], Loss: 0.0218\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1110/6000], Loss: 0.1514\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1120/6000], Loss: 0.0388\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1130/6000], Loss: 0.6607\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1140/6000], Loss: 0.0365\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1150/6000], Loss: 0.0379\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1160/6000], Loss: 0.0313\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1170/6000], Loss: 0.0168\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1180/6000], Loss: 0.0580\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1190/6000], Loss: 0.0112\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1200/6000], Loss: 0.1152\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1210/6000], Loss: 0.0106\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1220/6000], Loss: 0.0662\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1230/6000], Loss: 0.0130\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1240/6000], Loss: 0.1106\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1250/6000], Loss: 0.2191\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1260/6000], Loss: 0.2679\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1270/6000], Loss: 0.0185\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1280/6000], Loss: 0.0192\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1290/6000], Loss: 0.0168\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1300/6000], Loss: 0.1145\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1310/6000], Loss: 0.0900\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1320/6000], Loss: 0.4263\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1330/6000], Loss: 0.1378\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1340/6000], Loss: 0.0252\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1350/6000], Loss: 0.0155\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1360/6000], Loss: 0.5677\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1370/6000], Loss: 0.0201\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1380/6000], Loss: 0.0424\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1390/6000], Loss: 0.0444\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1400/6000], Loss: 0.1418\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1410/6000], Loss: 0.0268\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1420/6000], Loss: 0.0423\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1430/6000], Loss: 0.0127\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1440/6000], Loss: 0.0273\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1450/6000], Loss: 0.0142\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1460/6000], Loss: 0.0394\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1470/6000], Loss: 0.0060\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1480/6000], Loss: 0.0301\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1490/6000], Loss: 0.1949\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1500/6000], Loss: 0.1424\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1510/6000], Loss: 0.0662\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1520/6000], Loss: 0.0478\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1530/6000], Loss: 0.0465\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1540/6000], Loss: 0.0478\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1550/6000], Loss: 0.0258\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1560/6000], Loss: 0.0218\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1570/6000], Loss: 0.2484\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1580/6000], Loss: 0.2695\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1590/6000], Loss: 0.0074\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1600/6000], Loss: 0.1605\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1610/6000], Loss: 0.0396\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1620/6000], Loss: 0.0812\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1630/6000], Loss: 0.0113\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1640/6000], Loss: 0.3792\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1650/6000], Loss: 0.0820\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1660/6000], Loss: 0.1870\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1670/6000], Loss: 0.0584\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1680/6000], Loss: 0.0286\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1690/6000], Loss: 0.0481\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1700/6000], Loss: 0.0269\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1710/6000], Loss: 0.0194\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1720/6000], Loss: 0.4530\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1730/6000], Loss: 0.0089\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1740/6000], Loss: 0.0164\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1750/6000], Loss: 0.1271\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1760/6000], Loss: 0.1321\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1770/6000], Loss: 0.0703\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1780/6000], Loss: 0.0448\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1790/6000], Loss: 0.0655\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1800/6000], Loss: 0.3005\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1810/6000], Loss: 0.1261\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1820/6000], Loss: 0.2085\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1830/6000], Loss: 0.5071\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1840/6000], Loss: 0.0080\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1850/6000], Loss: 0.0386\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1860/6000], Loss: 0.0519\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1870/6000], Loss: 0.0285\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1880/6000], Loss: 0.0493\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1890/6000], Loss: 0.0516\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1900/6000], Loss: 0.0339\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1910/6000], Loss: 0.0816\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1920/6000], Loss: 0.2046\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1930/6000], Loss: 0.0517\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1940/6000], Loss: 0.0568\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1950/6000], Loss: 0.0150\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1960/6000], Loss: 0.5339\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1970/6000], Loss: 0.3738\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1980/6000], Loss: 0.1795\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [1990/6000], Loss: 0.0082\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2000/6000], Loss: 0.0806\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2010/6000], Loss: 0.0265\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2020/6000], Loss: 0.0255\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2030/6000], Loss: 0.0488\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2040/6000], Loss: 0.0307\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2050/6000], Loss: 0.0577\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2060/6000], Loss: 0.0376\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2070/6000], Loss: 0.0276\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2080/6000], Loss: 0.4773\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2090/6000], Loss: 0.0652\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2100/6000], Loss: 0.0871\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2110/6000], Loss: 0.0473\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2120/6000], Loss: 0.0577\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2130/6000], Loss: 0.0126\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2140/6000], Loss: 0.0463\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2150/6000], Loss: 0.1740\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2160/6000], Loss: 0.0112\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2170/6000], Loss: 0.1183\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2180/6000], Loss: 0.0886\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2190/6000], Loss: 0.0495\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2200/6000], Loss: 0.0254\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2210/6000], Loss: 0.0679\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2220/6000], Loss: 0.1525\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2230/6000], Loss: 0.0539\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2240/6000], Loss: 0.0186\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2250/6000], Loss: 0.0134\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2260/6000], Loss: 0.0036\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2270/6000], Loss: 0.1902\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2280/6000], Loss: 0.1985\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2290/6000], Loss: 0.2074\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2300/6000], Loss: 0.2422\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2310/6000], Loss: 0.0414\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2320/6000], Loss: 0.0744\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2330/6000], Loss: 0.0562\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2340/6000], Loss: 0.0539\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2350/6000], Loss: 0.0101\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2360/6000], Loss: 0.0047\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2370/6000], Loss: 0.1112\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2380/6000], Loss: 0.0164\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2390/6000], Loss: 0.0112\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2400/6000], Loss: 0.4165\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2410/6000], Loss: 0.1329\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2420/6000], Loss: 0.1169\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2430/6000], Loss: 0.0823\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2440/6000], Loss: 0.1994\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2450/6000], Loss: 0.0839\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2460/6000], Loss: 0.0174\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2470/6000], Loss: 0.0353\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2480/6000], Loss: 0.0396\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2490/6000], Loss: 0.0260\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2500/6000], Loss: 0.0264\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2510/6000], Loss: 0.1782\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2520/6000], Loss: 0.0958\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2530/6000], Loss: 0.0670\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2540/6000], Loss: 0.0363\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2550/6000], Loss: 0.0282\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2560/6000], Loss: 0.2675\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2570/6000], Loss: 0.0348\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2580/6000], Loss: 0.0219\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2590/6000], Loss: 0.2882\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2600/6000], Loss: 0.1922\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2610/6000], Loss: 0.0717\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2620/6000], Loss: 0.1710\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2630/6000], Loss: 0.1134\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2640/6000], Loss: 0.1036\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2650/6000], Loss: 0.3549\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2660/6000], Loss: 0.3538\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2670/6000], Loss: 0.1201\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2680/6000], Loss: 0.0580\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2690/6000], Loss: 0.5954\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2700/6000], Loss: 0.0117\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2710/6000], Loss: 0.0612\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2720/6000], Loss: 0.0404\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2730/6000], Loss: 0.0288\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2740/6000], Loss: 0.0969\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2750/6000], Loss: 0.2646\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2760/6000], Loss: 0.2687\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2770/6000], Loss: 0.0419\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2780/6000], Loss: 0.1322\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2790/6000], Loss: 0.0453\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2800/6000], Loss: 0.1429\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2810/6000], Loss: 0.0163\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2820/6000], Loss: 0.0506\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2830/6000], Loss: 0.0175\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2840/6000], Loss: 0.0233\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2850/6000], Loss: 0.0043\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2860/6000], Loss: 0.0298\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2870/6000], Loss: 0.2427\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2880/6000], Loss: 0.0804\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2890/6000], Loss: 0.0029\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2900/6000], Loss: 0.0187\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2910/6000], Loss: 0.1783\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2920/6000], Loss: 0.0190\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2930/6000], Loss: 0.0259\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2940/6000], Loss: 0.0798\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2950/6000], Loss: 0.0152\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2960/6000], Loss: 0.0377\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2970/6000], Loss: 0.0575\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2980/6000], Loss: 0.0148\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [2990/6000], Loss: 0.0627\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3000/6000], Loss: 0.2704\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3010/6000], Loss: 0.0138\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3020/6000], Loss: 0.2178\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3030/6000], Loss: 0.1129\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3040/6000], Loss: 0.0428\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3050/6000], Loss: 0.2312\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3060/6000], Loss: 0.0345\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3070/6000], Loss: 0.0110\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3080/6000], Loss: 0.0580\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3090/6000], Loss: 0.0579\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3100/6000], Loss: 0.0293\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3110/6000], Loss: 0.1290\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3120/6000], Loss: 0.1101\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3130/6000], Loss: 0.1836\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3140/6000], Loss: 0.3364\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3150/6000], Loss: 0.0113\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3160/6000], Loss: 0.0286\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3170/6000], Loss: 0.0432\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3180/6000], Loss: 0.0327\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3190/6000], Loss: 0.0343\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3200/6000], Loss: 0.2063\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3210/6000], Loss: 0.1635\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3220/6000], Loss: 0.0934\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3230/6000], Loss: 0.1296\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3240/6000], Loss: 0.0704\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3250/6000], Loss: 0.0789\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3260/6000], Loss: 0.0870\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3270/6000], Loss: 0.0050\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3280/6000], Loss: 0.0838\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3290/6000], Loss: 0.0096\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3300/6000], Loss: 0.4723\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3310/6000], Loss: 0.1541\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3320/6000], Loss: 0.0886\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3330/6000], Loss: 0.0428\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3340/6000], Loss: 0.0559\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3350/6000], Loss: 0.0551\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3360/6000], Loss: 0.0372\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3370/6000], Loss: 0.0745\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3380/6000], Loss: 0.0545\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3390/6000], Loss: 0.0168\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3400/6000], Loss: 0.2461\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3410/6000], Loss: 0.0424\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3420/6000], Loss: 0.0286\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3430/6000], Loss: 0.0394\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3440/6000], Loss: 0.0696\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3450/6000], Loss: 0.2262\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3460/6000], Loss: 0.0978\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3470/6000], Loss: 0.0119\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3480/6000], Loss: 0.0850\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3490/6000], Loss: 0.0235\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3500/6000], Loss: 0.0296\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3510/6000], Loss: 0.0266\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3520/6000], Loss: 0.0494\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3530/6000], Loss: 0.4456\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3540/6000], Loss: 0.5672\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3550/6000], Loss: 0.1376\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3560/6000], Loss: 0.0092\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3570/6000], Loss: 0.0140\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3580/6000], Loss: 0.0059\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3590/6000], Loss: 0.1346\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3600/6000], Loss: 0.0295\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3610/6000], Loss: 0.0412\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3620/6000], Loss: 0.1820\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3630/6000], Loss: 0.1780\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3640/6000], Loss: 0.1501\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3650/6000], Loss: 0.1256\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3660/6000], Loss: 0.2003\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3670/6000], Loss: 0.1129\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3680/6000], Loss: 0.0443\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3690/6000], Loss: 0.0541\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3700/6000], Loss: 0.1937\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3710/6000], Loss: 0.2132\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3720/6000], Loss: 0.0193\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3730/6000], Loss: 0.1240\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3740/6000], Loss: 0.0072\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3750/6000], Loss: 0.2582\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3760/6000], Loss: 0.0184\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3770/6000], Loss: 0.3326\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3780/6000], Loss: 0.0581\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3790/6000], Loss: 0.0536\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3800/6000], Loss: 0.0109\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3810/6000], Loss: 0.1444\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3820/6000], Loss: 0.0226\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3830/6000], Loss: 0.0172\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3840/6000], Loss: 0.0258\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3850/6000], Loss: 0.0217\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3860/6000], Loss: 0.0665\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3870/6000], Loss: 0.0898\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3880/6000], Loss: 0.2883\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3890/6000], Loss: 0.0813\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3900/6000], Loss: 0.0194\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3910/6000], Loss: 0.0684\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3920/6000], Loss: 0.0077\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3930/6000], Loss: 0.1288\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3940/6000], Loss: 0.1013\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3950/6000], Loss: 0.2984\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3960/6000], Loss: 0.0180\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3970/6000], Loss: 0.0783\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3980/6000], Loss: 0.0184\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [3990/6000], Loss: 0.1200\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4000/6000], Loss: 0.1193\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4010/6000], Loss: 0.1020\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4020/6000], Loss: 0.0116\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4030/6000], Loss: 0.1071\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4040/6000], Loss: 0.0299\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4050/6000], Loss: 0.0065\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4060/6000], Loss: 0.0306\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4070/6000], Loss: 0.1099\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4080/6000], Loss: 0.1159\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4090/6000], Loss: 0.0631\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4100/6000], Loss: 0.0302\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4110/6000], Loss: 0.0708\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4120/6000], Loss: 0.0052\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4130/6000], Loss: 0.0159\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4140/6000], Loss: 0.5856\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4150/6000], Loss: 0.0151\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4160/6000], Loss: 0.1260\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4170/6000], Loss: 0.1658\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4180/6000], Loss: 0.0847\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4190/6000], Loss: 0.0285\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4200/6000], Loss: 0.0695\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4210/6000], Loss: 0.0404\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4220/6000], Loss: 0.0435\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4230/6000], Loss: 0.0859\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4240/6000], Loss: 0.0482\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4250/6000], Loss: 0.1798\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4260/6000], Loss: 0.0526\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4270/6000], Loss: 0.3374\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4280/6000], Loss: 0.0455\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4290/6000], Loss: 0.1596\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4300/6000], Loss: 0.0100\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4310/6000], Loss: 0.0943\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4320/6000], Loss: 0.4533\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4330/6000], Loss: 0.2056\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4340/6000], Loss: 0.0114\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4350/6000], Loss: 0.1393\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4360/6000], Loss: 0.1141\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4370/6000], Loss: 0.1144\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4380/6000], Loss: 0.0302\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4390/6000], Loss: 0.1518\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4400/6000], Loss: 0.0112\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4410/6000], Loss: 0.0171\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4420/6000], Loss: 0.0481\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4430/6000], Loss: 0.4005\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4440/6000], Loss: 0.0059\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4450/6000], Loss: 0.0346\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4460/6000], Loss: 0.0904\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4470/6000], Loss: 0.0066\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4480/6000], Loss: 0.3692\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4490/6000], Loss: 0.0572\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4500/6000], Loss: 0.0096\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4510/6000], Loss: 0.0138\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4520/6000], Loss: 0.0195\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4530/6000], Loss: 0.0424\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4540/6000], Loss: 0.1927\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4550/6000], Loss: 0.1061\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4560/6000], Loss: 0.2812\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4570/6000], Loss: 0.0346\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4580/6000], Loss: 0.2393\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4590/6000], Loss: 0.0159\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4600/6000], Loss: 0.0567\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4610/6000], Loss: 0.0557\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4620/6000], Loss: 0.0174\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4630/6000], Loss: 0.0353\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4640/6000], Loss: 0.0823\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4650/6000], Loss: 0.0219\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4660/6000], Loss: 0.0241\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4670/6000], Loss: 0.1616\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4680/6000], Loss: 0.0725\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4690/6000], Loss: 0.1924\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4700/6000], Loss: 0.0162\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4710/6000], Loss: 0.1243\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4720/6000], Loss: 0.1272\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4730/6000], Loss: 0.0416\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4740/6000], Loss: 0.0265\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4750/6000], Loss: 0.1670\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4760/6000], Loss: 0.0524\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4770/6000], Loss: 0.0992\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4780/6000], Loss: 0.0779\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4790/6000], Loss: 0.1665\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4800/6000], Loss: 0.1140\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4810/6000], Loss: 0.0201\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4820/6000], Loss: 0.0187\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4830/6000], Loss: 0.0193\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4840/6000], Loss: 0.0304\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4850/6000], Loss: 0.0229\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4860/6000], Loss: 0.0034\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4870/6000], Loss: 0.1003\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4880/6000], Loss: 0.1910\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4890/6000], Loss: 0.0365\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4900/6000], Loss: 0.1437\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4910/6000], Loss: 0.0723\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4920/6000], Loss: 0.0033\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4930/6000], Loss: 0.0023\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4940/6000], Loss: 0.0054\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4950/6000], Loss: 0.2671\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4960/6000], Loss: 0.0186\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4970/6000], Loss: 0.1048\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4980/6000], Loss: 0.1806\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [4990/6000], Loss: 0.0708\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5000/6000], Loss: 0.0113\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5010/6000], Loss: 0.2518\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5020/6000], Loss: 0.0571\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5030/6000], Loss: 0.3389\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5040/6000], Loss: 0.0480\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5050/6000], Loss: 0.0229\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5060/6000], Loss: 0.0851\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5070/6000], Loss: 0.0143\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5080/6000], Loss: 0.0099\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5090/6000], Loss: 0.1285\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5100/6000], Loss: 0.0424\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5110/6000], Loss: 0.4066\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5120/6000], Loss: 0.2386\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5130/6000], Loss: 0.0299\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5140/6000], Loss: 0.1990\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5150/6000], Loss: 0.1273\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5160/6000], Loss: 0.0203\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5170/6000], Loss: 0.0426\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5180/6000], Loss: 0.0482\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5190/6000], Loss: 0.0134\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5200/6000], Loss: 0.0119\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5210/6000], Loss: 0.0199\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5220/6000], Loss: 0.0596\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5230/6000], Loss: 0.0299\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5240/6000], Loss: 0.0354\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5250/6000], Loss: 0.0345\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5260/6000], Loss: 0.1399\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5270/6000], Loss: 0.1023\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5280/6000], Loss: 0.0598\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5290/6000], Loss: 0.0274\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5300/6000], Loss: 0.0100\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5310/6000], Loss: 0.0081\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5320/6000], Loss: 0.1285\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5330/6000], Loss: 0.1667\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5340/6000], Loss: 0.0515\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5350/6000], Loss: 0.0635\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5360/6000], Loss: 0.0453\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5370/6000], Loss: 0.2388\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5380/6000], Loss: 0.0421\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5390/6000], Loss: 0.0446\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5400/6000], Loss: 0.1486\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5410/6000], Loss: 0.5645\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5420/6000], Loss: 0.2316\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5430/6000], Loss: 0.0301\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5440/6000], Loss: 0.3182\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5450/6000], Loss: 0.0918\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5460/6000], Loss: 0.0797\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5470/6000], Loss: 0.0485\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5480/6000], Loss: 0.0549\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5490/6000], Loss: 0.0274\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5500/6000], Loss: 0.0308\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5510/6000], Loss: 0.4003\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5520/6000], Loss: 0.0303\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5530/6000], Loss: 0.2663\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5540/6000], Loss: 0.0146\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5550/6000], Loss: 0.0630\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5560/6000], Loss: 0.0570\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5570/6000], Loss: 0.0295\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5580/6000], Loss: 0.0377\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5590/6000], Loss: 0.0154\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5600/6000], Loss: 0.0470\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5610/6000], Loss: 0.0084\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5620/6000], Loss: 0.3628\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5630/6000], Loss: 0.0990\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5640/6000], Loss: 0.1311\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5650/6000], Loss: 0.1575\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5660/6000], Loss: 0.1779\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5670/6000], Loss: 0.2326\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5680/6000], Loss: 1.0438\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5690/6000], Loss: 0.0186\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5700/6000], Loss: 0.2984\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5710/6000], Loss: 0.1751\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5720/6000], Loss: 0.0624\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5730/6000], Loss: 0.0790\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5740/6000], Loss: 0.1154\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5750/6000], Loss: 0.1030\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5760/6000], Loss: 0.0553\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5770/6000], Loss: 0.3058\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5780/6000], Loss: 0.0229\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5790/6000], Loss: 0.3040\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5800/6000], Loss: 0.0311\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5810/6000], Loss: 0.0082\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5820/6000], Loss: 0.0952\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5830/6000], Loss: 0.0319\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5840/6000], Loss: 0.0595\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5850/6000], Loss: 0.0231\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5860/6000], Loss: 0.0335\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5870/6000], Loss: 0.0983\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5880/6000], Loss: 0.0857\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5890/6000], Loss: 0.0904\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5900/6000], Loss: 0.0280\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5910/6000], Loss: 0.0343\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5920/6000], Loss: 0.1045\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5930/6000], Loss: 0.0357\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5940/6000], Loss: 0.0150\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5950/6000], Loss: 0.0646\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5960/6000], Loss: 0.1078\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5970/6000], Loss: 0.0017\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5980/6000], Loss: 0.1215\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [5990/6000], Loss: 0.0195\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [6000/6000], Loss: 0.0094\n",
      "Max Epoch Reached\n",
      "Accuracy of the network on the test images: 96.3% & Test Loss: 0.012160540507535915 \n",
      "Total no of parameters in Model :34622 for with batch size:385\n",
      "strated\n",
      "Train O/P: Epoch [1/5], Step [10/156], Loss: 2.1389\n",
      "Train O/P: Epoch [1/5], Step [20/156], Loss: 1.4823\n",
      "Train O/P: Epoch [1/5], Step [30/156], Loss: 0.7864\n",
      "Train O/P: Epoch [1/5], Step [40/156], Loss: 0.5191\n",
      "Train O/P: Epoch [1/5], Step [50/156], Loss: 0.4499\n",
      "Train O/P: Epoch [1/5], Step [60/156], Loss: 0.3972\n",
      "Train O/P: Epoch [1/5], Step [70/156], Loss: 0.4104\n",
      "Train O/P: Epoch [1/5], Step [80/156], Loss: 0.4316\n",
      "Train O/P: Epoch [1/5], Step [90/156], Loss: 0.3149\n",
      "Train O/P: Epoch [1/5], Step [100/156], Loss: 0.2966\n",
      "Train O/P: Epoch [1/5], Step [110/156], Loss: 0.2360\n",
      "Train O/P: Epoch [1/5], Step [120/156], Loss: 0.3159\n",
      "Train O/P: Epoch [1/5], Step [130/156], Loss: 0.2181\n",
      "Train O/P: Epoch [1/5], Step [140/156], Loss: 0.2797\n",
      "Train O/P: Epoch [1/5], Step [150/156], Loss: 0.2480\n",
      "Train O/P: Epoch [2/5], Step [10/156], Loss: 0.2157\n",
      "Train O/P: Epoch [2/5], Step [20/156], Loss: 0.1569\n",
      "Train O/P: Epoch [2/5], Step [30/156], Loss: 0.1835\n",
      "Train O/P: Epoch [2/5], Step [40/156], Loss: 0.1615\n",
      "Train O/P: Epoch [2/5], Step [50/156], Loss: 0.2221\n",
      "Train O/P: Epoch [2/5], Step [60/156], Loss: 0.1841\n",
      "Train O/P: Epoch [2/5], Step [70/156], Loss: 0.1795\n",
      "Train O/P: Epoch [2/5], Step [80/156], Loss: 0.2245\n",
      "Train O/P: Epoch [2/5], Step [90/156], Loss: 0.1604\n",
      "Train O/P: Epoch [2/5], Step [100/156], Loss: 0.1853\n",
      "Train O/P: Epoch [2/5], Step [110/156], Loss: 0.1576\n",
      "Train O/P: Epoch [2/5], Step [120/156], Loss: 0.1953\n",
      "Train O/P: Epoch [2/5], Step [130/156], Loss: 0.1944\n",
      "Train O/P: Epoch [2/5], Step [140/156], Loss: 0.1333\n",
      "Train O/P: Epoch [2/5], Step [150/156], Loss: 0.1716\n",
      "Train O/P: Epoch [3/5], Step [10/156], Loss: 0.1434\n",
      "Train O/P: Epoch [3/5], Step [20/156], Loss: 0.1377\n",
      "Train O/P: Epoch [3/5], Step [30/156], Loss: 0.1226\n",
      "Train O/P: Epoch [3/5], Step [40/156], Loss: 0.1578\n",
      "Train O/P: Epoch [3/5], Step [50/156], Loss: 0.1423\n",
      "Train O/P: Epoch [3/5], Step [60/156], Loss: 0.1816\n",
      "Train O/P: Epoch [3/5], Step [70/156], Loss: 0.0966\n",
      "Train O/P: Epoch [3/5], Step [80/156], Loss: 0.1816\n",
      "Train O/P: Epoch [3/5], Step [90/156], Loss: 0.1672\n",
      "Train O/P: Epoch [3/5], Step [100/156], Loss: 0.1027\n",
      "Train O/P: Epoch [3/5], Step [110/156], Loss: 0.0882\n",
      "Train O/P: Epoch [3/5], Step [120/156], Loss: 0.1054\n",
      "Train O/P: Epoch [3/5], Step [130/156], Loss: 0.1098\n",
      "Train O/P: Epoch [3/5], Step [140/156], Loss: 0.1395\n",
      "Train O/P: Epoch [3/5], Step [150/156], Loss: 0.1310\n",
      "Train O/P: Epoch [4/5], Step [10/156], Loss: 0.1589\n",
      "Train O/P: Epoch [4/5], Step [20/156], Loss: 0.0852\n",
      "Train O/P: Epoch [4/5], Step [30/156], Loss: 0.1037\n",
      "Train O/P: Epoch [4/5], Step [40/156], Loss: 0.1271\n",
      "Train O/P: Epoch [4/5], Step [50/156], Loss: 0.1195\n",
      "Train O/P: Epoch [4/5], Step [60/156], Loss: 0.1170\n",
      "Train O/P: Epoch [4/5], Step [70/156], Loss: 0.1013\n",
      "Train O/P: Epoch [4/5], Step [80/156], Loss: 0.1204\n",
      "Train O/P: Epoch [4/5], Step [90/156], Loss: 0.1336\n",
      "Train O/P: Epoch [4/5], Step [100/156], Loss: 0.0933\n",
      "Train O/P: Epoch [4/5], Step [110/156], Loss: 0.0939\n",
      "Train O/P: Epoch [4/5], Step [120/156], Loss: 0.1286\n",
      "Train O/P: Epoch [4/5], Step [130/156], Loss: 0.1017\n",
      "Train O/P: Epoch [4/5], Step [140/156], Loss: 0.1064\n",
      "Train O/P: Epoch [4/5], Step [150/156], Loss: 0.1660\n",
      "Train O/P: Epoch [5/5], Step [10/156], Loss: 0.0779\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [20/156], Loss: 0.1263\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [30/156], Loss: 0.0984\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [40/156], Loss: 0.0802\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [50/156], Loss: 0.1002\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [60/156], Loss: 0.1302\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [70/156], Loss: 0.1398\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [80/156], Loss: 0.0738\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [90/156], Loss: 0.1088\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [100/156], Loss: 0.1067\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [110/156], Loss: 0.1080\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [120/156], Loss: 0.1677\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [130/156], Loss: 0.0860\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [140/156], Loss: 0.1299\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [150/156], Loss: 0.1094\n",
      "Max Epoch Reached\n",
      "Accuracy of the network on the test images: 97.4% & Test Loss: 0.0002445988159626722 \n",
      "Total no of parameters in Model :34622 for with batch size:760\n",
      "strated\n",
      "Train O/P: Epoch [1/5], Step [10/79], Loss: 2.1151\n",
      "Train O/P: Epoch [1/5], Step [20/79], Loss: 1.4228\n",
      "Train O/P: Epoch [1/5], Step [30/79], Loss: 0.7258\n",
      "Train O/P: Epoch [1/5], Step [40/79], Loss: 0.4890\n",
      "Train O/P: Epoch [1/5], Step [50/79], Loss: 0.4061\n",
      "Train O/P: Epoch [1/5], Step [60/79], Loss: 0.4150\n",
      "Train O/P: Epoch [1/5], Step [70/79], Loss: 0.3489\n",
      "Train O/P: Epoch [2/5], Step [10/79], Loss: 0.3072\n",
      "Train O/P: Epoch [2/5], Step [20/79], Loss: 0.3272\n",
      "Train O/P: Epoch [2/5], Step [30/79], Loss: 0.2880\n",
      "Train O/P: Epoch [2/5], Step [40/79], Loss: 0.2857\n",
      "Train O/P: Epoch [2/5], Step [50/79], Loss: 0.2558\n",
      "Train O/P: Epoch [2/5], Step [60/79], Loss: 0.2665\n",
      "Train O/P: Epoch [2/5], Step [70/79], Loss: 0.2387\n",
      "Train O/P: Epoch [3/5], Step [10/79], Loss: 0.1688\n",
      "Train O/P: Epoch [3/5], Step [20/79], Loss: 0.2029\n",
      "Train O/P: Epoch [3/5], Step [30/79], Loss: 0.1918\n",
      "Train O/P: Epoch [3/5], Step [40/79], Loss: 0.1848\n",
      "Train O/P: Epoch [3/5], Step [50/79], Loss: 0.1762\n",
      "Train O/P: Epoch [3/5], Step [60/79], Loss: 0.2221\n",
      "Train O/P: Epoch [3/5], Step [70/79], Loss: 0.1521\n",
      "Train O/P: Epoch [4/5], Step [10/79], Loss: 0.1624\n",
      "Train O/P: Epoch [4/5], Step [20/79], Loss: 0.1759\n",
      "Train O/P: Epoch [4/5], Step [30/79], Loss: 0.1853\n",
      "Train O/P: Epoch [4/5], Step [40/79], Loss: 0.1572\n",
      "Train O/P: Epoch [4/5], Step [50/79], Loss: 0.1382\n",
      "Train O/P: Epoch [4/5], Step [60/79], Loss: 0.1304\n",
      "Train O/P: Epoch [4/5], Step [70/79], Loss: 0.1334\n",
      "Train O/P: Epoch [5/5], Step [10/79], Loss: 0.1692\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [20/79], Loss: 0.1158\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [30/79], Loss: 0.1194\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [40/79], Loss: 0.1022\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [50/79], Loss: 0.1125\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [60/79], Loss: 0.1548\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [70/79], Loss: 0.1155\n",
      "Max Epoch Reached\n",
      "Accuracy of the network on the test images: 97.13% & Test Loss: 0.00015568225048482418 \n",
      "Total no of parameters in Model :34622 for with batch size:1135\n",
      "strated\n",
      "Train O/P: Epoch [1/5], Step [10/53], Loss: 2.1104\n",
      "Train O/P: Epoch [1/5], Step [20/53], Loss: 1.3982\n",
      "Train O/P: Epoch [1/5], Step [30/53], Loss: 0.6768\n",
      "Train O/P: Epoch [1/5], Step [40/53], Loss: 0.4800\n",
      "Train O/P: Epoch [1/5], Step [50/53], Loss: 0.4184\n",
      "Train O/P: Epoch [2/5], Step [10/53], Loss: 0.3814\n",
      "Train O/P: Epoch [2/5], Step [20/53], Loss: 0.3340\n",
      "Train O/P: Epoch [2/5], Step [30/53], Loss: 0.3081\n",
      "Train O/P: Epoch [2/5], Step [40/53], Loss: 0.3100\n",
      "Train O/P: Epoch [2/5], Step [50/53], Loss: 0.2555\n",
      "Train O/P: Epoch [3/5], Step [10/53], Loss: 0.2659\n",
      "Train O/P: Epoch [3/5], Step [20/53], Loss: 0.2622\n",
      "Train O/P: Epoch [3/5], Step [30/53], Loss: 0.2498\n",
      "Train O/P: Epoch [3/5], Step [40/53], Loss: 0.2628\n",
      "Train O/P: Epoch [3/5], Step [50/53], Loss: 0.2492\n",
      "Train O/P: Epoch [4/5], Step [10/53], Loss: 0.2071\n",
      "Train O/P: Epoch [4/5], Step [20/53], Loss: 0.2227\n",
      "Train O/P: Epoch [4/5], Step [30/53], Loss: 0.1802\n",
      "Train O/P: Epoch [4/5], Step [40/53], Loss: 0.1698\n",
      "Train O/P: Epoch [4/5], Step [50/53], Loss: 0.1936\n",
      "Train O/P: Epoch [5/5], Step [10/53], Loss: 0.1841\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [20/53], Loss: 0.1550\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [30/53], Loss: 0.1893\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [40/53], Loss: 0.1422\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [50/53], Loss: 0.1536\n",
      "Max Epoch Reached\n",
      "Accuracy of the network on the test images: 96.15% & Test Loss: 0.00011980664879083633 \n",
      "Total no of parameters in Model :34622 for with batch size:1510\n",
      "strated\n",
      "Train O/P: Epoch [1/5], Step [10/40], Loss: 2.1107\n",
      "Train O/P: Epoch [1/5], Step [20/40], Loss: 1.3205\n",
      "Train O/P: Epoch [1/5], Step [30/40], Loss: 0.6664\n",
      "Train O/P: Epoch [1/5], Step [40/40], Loss: 0.4591\n",
      "Train O/P: Epoch [2/5], Step [10/40], Loss: 0.4368\n",
      "Train O/P: Epoch [2/5], Step [20/40], Loss: 0.4026\n",
      "Train O/P: Epoch [2/5], Step [30/40], Loss: 0.3684\n",
      "Train O/P: Epoch [2/5], Step [40/40], Loss: 0.2628\n",
      "Train O/P: Epoch [3/5], Step [10/40], Loss: 0.2701\n",
      "Train O/P: Epoch [3/5], Step [20/40], Loss: 0.2584\n",
      "Train O/P: Epoch [3/5], Step [30/40], Loss: 0.2935\n",
      "Train O/P: Epoch [3/5], Step [40/40], Loss: 0.2378\n",
      "Train O/P: Epoch [4/5], Step [10/40], Loss: 0.2362\n",
      "Train O/P: Epoch [4/5], Step [20/40], Loss: 0.2366\n",
      "Train O/P: Epoch [4/5], Step [30/40], Loss: 0.1995\n",
      "Train O/P: Epoch [4/5], Step [40/40], Loss: 0.1861\n",
      "Train O/P: Epoch [5/5], Step [10/40], Loss: 0.1728\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [20/40], Loss: 0.1764\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [30/40], Loss: 0.1667\n",
      "Max Epoch Reached\n",
      "Train O/P: Epoch [5/5], Step [40/40], Loss: 0.1628\n",
      "Max Epoch Reached\n",
      "Accuracy of the network on the test images: 95.65% & Test Loss: 0.00010675652548670769 \n"
     ]
    }
   ],
   "source": [
    "modelsTrainEpochArr = []\n",
    "modelsTrainLossArr = []\n",
    "modelsTrainAccArr = []\n",
    "modelsTestLossArr = []\n",
    "modelsTestAccArr = []\n",
    "modelsSensitivityArr=[]\n",
    "\n",
    "for i in range (len(batchArr)):\n",
    "    torch.manual_seed(1)\n",
    "    \n",
    "    j=copy.deepcopy(i) \n",
    "    j = Model()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(j.parameters(), lr=0.0015, weight_decay = 1e-2)\n",
    "\n",
    "    max_epochs = 5\n",
    "    train_batch_size = int(batchArr[i])\n",
    "\n",
    "    a=[]\n",
    "    for k in j.parameters():\n",
    "        a.append(torch.numel(k))\n",
    "    print(f'Total no of parameters in Model :{np.sum(a)} for with batch size:{train_batch_size}')\n",
    "\n",
    "    train_epoch,train_losses,train_acc,sensitivity = trainFunc(j,max_epochs,train_batch_size)\n",
    "\n",
    "    test_batch_size = int(batchArr[i])\n",
    "\n",
    "    testAcc, testLoss = testFunction(j,loss_func,test_batch_size)\n",
    "\n",
    "    #sensitivity = sensitivityFunc(j)\n",
    "    \n",
    "    modelsTrainEpochArr.append(train_epoch)\n",
    "    modelsTrainLossArr.append(train_losses)\n",
    "    modelsTrainAccArr.append(train_acc)\n",
    "    modelsTestAccArr.append(testAcc)\n",
    "    modelsTestLossArr.append(testLoss)\n",
    "    modelsSensitivityArr.append(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modelsTrainAccArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.3, 97.4, 97.13, 96.15, 95.65]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsTestAccArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanScore(dataArr):\n",
    "    meanModelData = []\n",
    "    for i in range (len(dataArr)):\n",
    "        meanScore = np.mean(dataArr[i])\n",
    "        meanModelData.append(meanScore)\n",
    "    return meanModelData\n",
    "\n",
    "def minScore(dataArr):\n",
    "    minModelScore = []\n",
    "    for i in range (len(dataArr)):\n",
    "        minScore = np.mean(dataArr[i])\n",
    "        minModelScore.append(minScore)\n",
    "    return minModelScore\n",
    "\n",
    "def maxScore(dataArr):\n",
    "    maxModelScore = []\n",
    "    for i in range (len(dataArr)):\n",
    "        maxScore = np.max(dataArr[i])\n",
    "        maxModelScore.append(maxScore)\n",
    "    return maxModelScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.07428467145655304],\n",
       " [0.3775946944952011],\n",
       " [0.2603247379884124],\n",
       " [0.14023217058274895],\n",
       " [0.12070254189893603]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsSensitivityArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13600840546058413, 0.23363729227238741, 0.3315702487773533, 0.41174194894309313, 0.48081375047564506]\n"
     ]
    }
   ],
   "source": [
    "print(minScore(modelsTrainLossArr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(batchArr,minScore(modelsTrainLossArr),color=\"Blue\", marker=\"o\",linestyle='dashed')\n",
    "ax.plot(batchArr,modelsTestLossArr,color=\"Blue\", marker=\"v\")\n",
    "ax.legend(['Train Loss','Test Loss'],loc=\"upper right\")\n",
    "ax.set_xlabel(\"Batch\",color=\"Green\")\n",
    "#ax.set_xscale('log')\n",
    "ax.set_ylabel(\"CrossEntropy Loss\",color = \"blue\")\n",
    "ax.set_title(\"Loss,Sensitivity Vs Batch Size\",color=\"g\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(batchArr,modelsSensitivityArr,color=\"red\")\n",
    "ax2.set_xlabel(\"Batch\",color=\"Green\")\n",
    "ax2.set_ylabel(\"Sensitivity\",color = \"red\")\n",
    "ax2.legend(['Sensitivity'],loc=\"center left\")\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/Diff Batch Graph HW1_3.2Loss.jpg',\n",
    "#             format='jpeg',\n",
    "#             dpi=100,\n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(batchArr,minScore(modelsTrainAccArr),color=\"Blue\", marker=\"o\",linestyle='dashed')\n",
    "ax.plot(batchArr,modelsTestAccArr,color=\"Blue\", marker=\"v\")\n",
    "ax.legend(['Train Acc','Test Acc'],loc=\"upper right\")\n",
    "ax.set_xlabel(\"Batch\",color=\"Green\")\n",
    "#ax.set_xscale('log')\n",
    "ax.set_ylabel(\"CrossEntropy Loss\",color = \"blue\")\n",
    "ax.set_title(\"Accuracy,Sensitivity Vs Batch Size\",color=\"g\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(batchArr,modelsSensitivityArr,color=\"red\")\n",
    "ax2.set_xlabel(\"Batch\",color=\"Green\")\n",
    "ax2.set_ylabel(\"Sensitivity\",color = \"red\")\n",
    "ax2.legend(['Sensitivity'],loc=\"center left\")\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/Diff Batch Graph HW1_3.2Acc.jpg',\n",
    "#             format='jpeg',\n",
    "#             dpi=100,\n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
