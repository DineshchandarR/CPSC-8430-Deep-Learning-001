{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d55a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(42)\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from autograd_lib import autograd_lib\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856504ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "result_folder = \"finalResult_with_hessian4_final1\"\n",
    "\n",
    "if not os.path.exists(result_folder):\n",
    "    os.mkdir(result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37952a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_func = lambda x : (torch.sin(5*np.pi*x)) /(5*np.pi*x) \n",
    "num_of_rows = 300\n",
    "X= torch.unsqueeze(torch.linspace(-1,1,num_of_rows),dim=1)\n",
    "Y = Y_func(X)\n",
    "dataset = TensorDataset(X,Y)\n",
    "data_loader = DataLoader(dataset,1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92633c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(X, Y, color = \"red\")\n",
    "plt.title('Non-Linear Function Plotting')\n",
    "plt.xlabel('Independent varible')\n",
    "plt.ylabel('Dependent varible')\n",
    "plt.savefig(result_folder+'/func1_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9beb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathRegressor(nn.Module):\n",
    "    def __init__(self, num_hidden=128):\n",
    "        super().__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(1, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    def training_step(self, batch,loss_fn):\n",
    "        inputs, targets = batch \n",
    "        out = self(inputs)                 # Generate predictions\n",
    "        loss = loss_fn(out, targets)    # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch,loss_fn):\n",
    "        inputs, targets = batch \n",
    "        out = self(inputs)                 # Generate predictions\n",
    "        loss = loss_fn(out, targets)    # Calculate loss\n",
    "        return {'val_loss': loss.detach()}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def train_step(self, batch,loss_fn):\n",
    "        inputs, targets = batch \n",
    "        out = self(inputs)                 # Generate predictions\n",
    "        loss = loss_fn(out, targets)    # Calculate loss\n",
    "        return {'train_loss': loss.detach()}\n",
    "    \n",
    "    def train_epoch_end(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'train_loss': epoch_loss.item()}\n",
    "    \n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bceda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MathRegressor(nn.Module):\n",
    "#     def __init__(self, num_hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.regressor = nn.Sequential(\n",
    "#             nn.Linear(1, 10),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(10, 18),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(18, 15),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(15, 4),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(4,1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.regressor(x)\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "#     def training_step(self, batch,loss_fn):\n",
    "#         inputs, targets = batch \n",
    "#         out = self(inputs)                 # Generate predictions\n",
    "#         loss = loss_fn(out, targets)    # Calculate loss\n",
    "#         return loss\n",
    "    \n",
    "#     def validation_step(self, batch,loss_fn):\n",
    "#         inputs, targets = batch \n",
    "#         out = self(inputs)                 # Generate predictions\n",
    "#         loss = loss_fn(out, targets)    # Calculate loss\n",
    "#         return {'val_loss': loss.detach()}\n",
    "    \n",
    "#     def validation_epoch_end(self, outputs):\n",
    "#         batch_losses = [x['val_loss'] for x in outputs]\n",
    "#         epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "#         return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "#     def train_step(self, batch,loss_fn):\n",
    "#         inputs, targets = batch \n",
    "#         out = self(inputs)                 # Generate predictions\n",
    "#         loss = loss_fn(out, targets)    # Calculate loss\n",
    "#         return {'train_loss': loss.detach()}\n",
    "    \n",
    "#     def train_epoch_end(self, outputs):\n",
    "#         batch_losses = [x['train_loss'] for x in outputs]\n",
    "#         epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "#         return {'train_loss': epoch_loss.item()}\n",
    "    \n",
    "    \n",
    "#     def epoch_end(self, epoch, result):\n",
    "#         print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956ab334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_norm(model, criterion, train, target):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    output = model(train)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = []\n",
    "    for p in model.regressor.children():\n",
    "        if isinstance(p, nn.Linear):\n",
    "            param_norm = p.weight.grad.norm(2).item()\n",
    "            grads.append(param_norm)\n",
    "\n",
    "    grad_mean = np.mean(grads) \n",
    "\n",
    "    return grad_mean\n",
    "\n",
    "def save_activations(layer, A, _):\n",
    "    activations[layer] = A\n",
    "\n",
    "def compute_hess(layer, _, B):\n",
    "    A = activations[layer]\n",
    "    BA = torch.einsum('nl,ni->nli', B, A) \n",
    "    hess[layer] += torch.einsum('nli,nkj->likj', BA, BA)\n",
    "    \n",
    "def compute_minimum_ratio(model, criterion, train, target):\n",
    "    model.zero_grad()\n",
    "    \n",
    "    with autograd_lib.module_hook(save_activations):\n",
    "        output = model(train)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "    with autograd_lib.module_hook(compute_hess):\n",
    "        autograd_lib.backward_hessian(output, loss='LeastSquares')\n",
    "\n",
    "    layer_hess = list(hess.values())\n",
    "    minimum_ratio = []\n",
    "\n",
    "    for h in layer_hess:\n",
    "        size = h.shape[0] * h.shape[1]\n",
    "        h = h.reshape(size, size)\n",
    "        h_eig = torch.symeig(h).eigenvalues \n",
    "        num_greater = torch.sum(h_eig > 0).item()\n",
    "        minimum_ratio.append(num_greater / len(h_eig))\n",
    "\n",
    "    ratio_mean = np.mean(minimum_ratio) \n",
    "\n",
    "    return ratio_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfad0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_minimal_ratio(model,criterion):\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "    gradient_norm = compute_gradient_norm(model, criterion, X, Y)\n",
    "    minimum_ratio = compute_minimum_ratio(model, criterion, X, Y)\n",
    "\n",
    "    print('gradient norm: {}, minimum ratio: {}'.format(gradient_norm, minimum_ratio))\n",
    "    result = {}\n",
    "    result[\"grad_norm\"] = gradient_norm\n",
    "    result[\"ratio\"] = minimum_ratio\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e38ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "def evaluate(model,loss_fn, val_loader):\n",
    "    outputs = [model.validation_step(batch,loss_fn) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def evaluate2(model,loss_fn, train_loader):\n",
    "    outputs = [model.train_step(batch,loss_fn) for batch in train_loader]\n",
    "    return model.train_epoch_end(outputs)\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    grad_all=0.0\n",
    "    grad =0\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grad = (p.grad.cpu().data.numpy()**2).sum()\n",
    "            \n",
    "        grad_all+=grad\n",
    "        \n",
    "    grad_norm=grad_all ** 0.5\n",
    "    return grad_norm\n",
    "\n",
    "\n",
    "def fit(epochs, lr, model, data_loader, criterion,opt_func):\n",
    "    history = []\n",
    "    comparing_epoch_loss =1000.0\n",
    "    grad_norm_per_epoch={}\n",
    "#     autograd_lib.register(model)\n",
    "#     activations = defaultdict(int)\n",
    "#     hess = defaultdict(float)\n",
    "    \n",
    "#     train_history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "#         grad_norm_per_epoch[epoch] = get_grad_norm(model)\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "    \n",
    "#         if epoch > 900 and epoch%100 ==0:\n",
    "#             print(\"Comparing result:\", (comparing_epoch_loss - result[\"val_loss\"]))\n",
    "#             if (comparing_epoch_loss - result[\"val_loss\"])  < 0.000001:\n",
    "# #                 print(\"Comparing result:\", (comparing_epoch_loss - result[\"val_loss\"]))\n",
    "#                 break\n",
    "#             comparing_epoch_loss=result[\"val_loss\"]\n",
    "        \n",
    "        # Training Phase \n",
    "        prediction = model(X)\n",
    "        loss = criterion(prediction, Y)     # must be (1. nn output, 2. target)\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        \n",
    "        \n",
    "        \n",
    "#             grad_norm_per_epoch[epoch] = get_grad_norm(model)\n",
    "        \n",
    "        grad_norm_per_epoch[epoch] = get_norm_minimal_ratio(model,criterion)\n",
    "        \n",
    "        \n",
    "        optimizer.step() \n",
    "        \n",
    "            \n",
    "            \n",
    "#             if epoch %100 == 0:\n",
    "#                 print(\"grad_norm is :\", grad_norm_per_epoch[epoch])\n",
    "#             if grad_norm_per_epoch[epoch] == 1e-3 :\n",
    "#                 return history,grad_norm_per_epoch,model\n",
    "        optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model,criterion, data_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "        if epoch == 900:\n",
    "            comparing_epoch_loss= result[\"val_loss\"]\n",
    "        \n",
    "#         res2 = evaluate2(model,train_loader)\n",
    "#         train_history.append(res2)\n",
    "    return history,grad_norm_per_epoch,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a77cd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initial Parameters\n",
    "num_of_rows = 300\n",
    "lr = 0.0004\n",
    "gamma_lr_scheduler = 0.1 \n",
    "weight_decay = 1e-4\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam\n",
    "num_epochs =2500\n",
    "criterion_name = \"MSE_LOSS_\"\n",
    "optimizer_name = \"ADAM_opt\"\n",
    "filename = criterion_name+ optimizer_name+\".png\"\n",
    "grad_norm_name = \"_grad_norm_name1_2.png\"\n",
    "result_folder_name = \"result3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d32ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam\n",
    "num_epochs =2000\n",
    "criterion_name = \"MSE_LOSS_\"\n",
    "optimizer_name = \"ADAM_opt\"\n",
    "input_size=1\n",
    "output_size=1\n",
    "model= MathRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "633cc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "autograd_lib.register(model)\n",
    "activations = defaultdict(int)\n",
    "hess = defaultdict(float)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d077eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.24811480939388275}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1 = evaluate(model,criterion,data_loader)\n",
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b36eb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = criterion_name+ optimizer_name+\".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "201af232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,target = X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb8bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient norm: 6.794032394886017, minimum ratio: 0.6484375\n",
      "Epoch [0], val_loss: 2.5906\n",
      "gradient norm: 6.8550320863723755, minimum ratio: 0.671875\n",
      "Epoch [1], val_loss: 2.6329\n",
      "gradient norm: 6.916284471750259, minimum ratio: 0.66015625\n",
      "Epoch [2], val_loss: 2.6757\n",
      "gradient norm: 6.977556988596916, minimum ratio: 0.66015625\n",
      "Epoch [3], val_loss: 2.7188\n",
      "gradient norm: 7.038907676935196, minimum ratio: 0.65625\n",
      "Epoch [4], val_loss: 2.7623\n",
      "gradient norm: 7.100486725568771, minimum ratio: 0.66796875\n",
      "Epoch [5], val_loss: 2.8062\n",
      "gradient norm: 7.162134662270546, minimum ratio: 0.65234375\n",
      "Epoch [6], val_loss: 2.8506\n",
      "gradient norm: 7.223933607339859, minimum ratio: 0.68359375\n",
      "Epoch [7], val_loss: 2.8953\n",
      "gradient norm: 7.285853073000908, minimum ratio: 0.65625\n",
      "Epoch [8], val_loss: 2.9404\n",
      "gradient norm: 7.348037227988243, minimum ratio: 0.671875\n",
      "Epoch [9], val_loss: 2.9859\n",
      "gradient norm: 7.4102038741111755, minimum ratio: 0.6640625\n",
      "Epoch [10], val_loss: 3.0319\n",
      "gradient norm: 7.472532317042351, minimum ratio: 0.67578125\n",
      "Epoch [11], val_loss: 3.0782\n",
      "gradient norm: 7.534908279776573, minimum ratio: 0.66796875\n",
      "Epoch [12], val_loss: 3.1249\n",
      "gradient norm: 7.597563058137894, minimum ratio: 0.66015625\n",
      "Epoch [13], val_loss: 3.1721\n",
      "gradient norm: 7.660313382744789, minimum ratio: 0.64453125\n",
      "Epoch [14], val_loss: 3.2197\n",
      "gradient norm: 7.723257407546043, minimum ratio: 0.6328125\n",
      "Epoch [15], val_loss: 3.2677\n",
      "gradient norm: 7.786462709307671, minimum ratio: 0.6640625\n",
      "Epoch [16], val_loss: 3.3161\n",
      "gradient norm: 7.849740639328957, minimum ratio: 0.66015625\n",
      "Epoch [17], val_loss: 3.3649\n",
      "gradient norm: 7.913162395358086, minimum ratio: 0.65625\n",
      "Epoch [18], val_loss: 3.4142\n",
      "gradient norm: 7.9766756147146225, minimum ratio: 0.65234375\n",
      "Epoch [19], val_loss: 3.4638\n",
      "gradient norm: 8.040358930826187, minimum ratio: 0.63671875\n",
      "Epoch [20], val_loss: 3.5140\n",
      "gradient norm: 8.104326859116554, minimum ratio: 0.65625\n",
      "Epoch [21], val_loss: 3.5645\n",
      "gradient norm: 8.168388918042183, minimum ratio: 0.66796875\n",
      "Epoch [22], val_loss: 3.6155\n",
      "gradient norm: 8.2325409501791, minimum ratio: 0.65625\n",
      "Epoch [23], val_loss: 3.6669\n",
      "gradient norm: 8.296886295080185, minimum ratio: 0.65625\n",
      "Epoch [24], val_loss: 3.7187\n",
      "gradient norm: 8.361432626843452, minimum ratio: 0.63671875\n",
      "Epoch [25], val_loss: 3.7710\n",
      "gradient norm: 8.426295563578606, minimum ratio: 0.64453125\n",
      "Epoch [26], val_loss: 3.8238\n",
      "gradient norm: 8.491263881325722, minimum ratio: 0.65625\n",
      "Epoch [27], val_loss: 3.8770\n",
      "gradient norm: 8.556424111127853, minimum ratio: 0.671875\n",
      "Epoch [28], val_loss: 3.9306\n",
      "gradient norm: 8.621848329901695, minimum ratio: 0.67578125\n",
      "Epoch [29], val_loss: 3.9847\n",
      "gradient norm: 8.687350362539291, minimum ratio: 0.6484375\n",
      "Epoch [30], val_loss: 4.0392\n",
      "gradient norm: 8.75303652882576, minimum ratio: 0.6484375\n",
      "Epoch [31], val_loss: 4.0942\n",
      "gradient norm: 8.818954095244408, minimum ratio: 0.66796875\n",
      "Epoch [32], val_loss: 4.1497\n",
      "gradient norm: 8.884972557425499, minimum ratio: 0.6796875\n",
      "Epoch [33], val_loss: 4.2056\n",
      "gradient norm: 8.95130044221878, minimum ratio: 0.6484375\n",
      "Epoch [34], val_loss: 4.2620\n",
      "gradient norm: 9.018030121922493, minimum ratio: 0.6640625\n",
      "Epoch [35], val_loss: 4.3189\n",
      "gradient norm: 9.084856063127518, minimum ratio: 0.66015625\n",
      "Epoch [36], val_loss: 4.3762\n",
      "gradient norm: 9.151728793978691, minimum ratio: 0.66796875\n",
      "Epoch [37], val_loss: 4.4340\n",
      "gradient norm: 9.21884272992611, minimum ratio: 0.6484375\n",
      "Epoch [38], val_loss: 4.4923\n",
      "gradient norm: 9.286166951060295, minimum ratio: 0.64453125\n",
      "Epoch [39], val_loss: 4.5511\n",
      "gradient norm: 9.35361947119236, minimum ratio: 0.66796875\n",
      "Epoch [40], val_loss: 4.6103\n",
      "gradient norm: 9.421258434653282, minimum ratio: 0.671875\n",
      "Epoch [41], val_loss: 4.6701\n",
      "gradient norm: 9.489293038845062, minimum ratio: 0.6640625\n",
      "Epoch [42], val_loss: 4.7303\n",
      "gradient norm: 9.55761468410492, minimum ratio: 0.65625\n",
      "Epoch [43], val_loss: 4.7910\n",
      "gradient norm: 9.62602598965168, minimum ratio: 0.6640625\n",
      "Epoch [44], val_loss: 4.8523\n",
      "gradient norm: 9.694795593619347, minimum ratio: 0.66796875\n",
      "Epoch [45], val_loss: 4.9140\n",
      "gradient norm: 9.763586089015007, minimum ratio: 0.6640625\n",
      "Epoch [46], val_loss: 4.9762\n",
      "gradient norm: 9.832585290074348, minimum ratio: 0.66796875\n",
      "Epoch [47], val_loss: 5.0389\n",
      "gradient norm: 9.902066618204117, minimum ratio: 0.671875\n",
      "Epoch [48], val_loss: 5.1022\n",
      "gradient norm: 9.97161528468132, minimum ratio: 0.64453125\n",
      "Epoch [49], val_loss: 5.1659\n",
      "gradient norm: 10.04132342338562, minimum ratio: 0.63671875\n",
      "Epoch [50], val_loss: 5.2302\n",
      "gradient norm: 10.11139315366745, minimum ratio: 0.65625\n",
      "Epoch [51], val_loss: 5.2950\n",
      "gradient norm: 10.181563347578049, minimum ratio: 0.66015625\n",
      "Epoch [52], val_loss: 5.3603\n",
      "gradient norm: 10.251967430114746, minimum ratio: 0.66796875\n",
      "Epoch [53], val_loss: 5.4261\n",
      "gradient norm: 10.322806566953659, minimum ratio: 0.671875\n",
      "Epoch [54], val_loss: 5.4925\n",
      "gradient norm: 10.394038677215576, minimum ratio: 0.67578125\n",
      "Epoch [55], val_loss: 5.5594\n",
      "gradient norm: 10.464983493089676, minimum ratio: 0.65625\n",
      "Epoch [56], val_loss: 5.6268\n",
      "gradient norm: 10.536263823509216, minimum ratio: 0.6640625\n",
      "Epoch [57], val_loss: 5.6948\n",
      "gradient norm: 10.607882767915726, minimum ratio: 0.6640625\n",
      "Epoch [58], val_loss: 5.7633\n",
      "gradient norm: 10.67992216348648, minimum ratio: 0.640625\n",
      "Epoch [59], val_loss: 5.8323\n",
      "gradient norm: 10.75214609503746, minimum ratio: 0.6875\n",
      "Epoch [60], val_loss: 5.9019\n",
      "gradient norm: 10.824616640806198, minimum ratio: 0.67578125\n",
      "Epoch [61], val_loss: 5.9721\n",
      "gradient norm: 10.897099107503891, minimum ratio: 0.6640625\n",
      "Epoch [62], val_loss: 6.0428\n",
      "gradient norm: 10.970109790563583, minimum ratio: 0.6328125\n",
      "Epoch [63], val_loss: 6.1141\n",
      "gradient norm: 11.043434828519821, minimum ratio: 0.6640625\n",
      "Epoch [64], val_loss: 6.1859\n",
      "gradient norm: 11.116934210062027, minimum ratio: 0.671875\n",
      "Epoch [65], val_loss: 6.2583\n",
      "gradient norm: 11.190619587898254, minimum ratio: 0.66015625\n",
      "Epoch [66], val_loss: 6.3313\n",
      "gradient norm: 11.264501512050629, minimum ratio: 0.66796875\n",
      "Epoch [67], val_loss: 6.4049\n",
      "gradient norm: 11.338847875595093, minimum ratio: 0.67578125\n",
      "Epoch [68], val_loss: 6.4790\n",
      "gradient norm: 11.413333863019943, minimum ratio: 0.640625\n",
      "Epoch [69], val_loss: 6.5537\n",
      "gradient norm: 11.488132268190384, minimum ratio: 0.6640625\n",
      "Epoch [70], val_loss: 6.6290\n",
      "gradient norm: 11.563077241182327, minimum ratio: 0.6875\n",
      "Epoch [71], val_loss: 6.7049\n",
      "gradient norm: 11.638188183307648, minimum ratio: 0.6640625\n",
      "Epoch [72], val_loss: 6.7814\n",
      "gradient norm: 11.713734418153763, minimum ratio: 0.6796875\n",
      "Epoch [73], val_loss: 6.8585\n",
      "gradient norm: 11.789833754301071, minimum ratio: 0.67578125\n",
      "Epoch [74], val_loss: 6.9361\n",
      "gradient norm: 11.865842640399933, minimum ratio: 0.67578125\n",
      "Epoch [75], val_loss: 7.0144\n",
      "gradient norm: 11.942279368638992, minimum ratio: 0.6484375\n",
      "Epoch [76], val_loss: 7.0933\n",
      "gradient norm: 12.018891334533691, minimum ratio: 0.6640625\n",
      "Epoch [77], val_loss: 7.1728\n",
      "gradient norm: 12.095498710870743, minimum ratio: 0.6484375\n",
      "Epoch [78], val_loss: 7.2529\n",
      "gradient norm: 12.172665655612946, minimum ratio: 0.66796875\n",
      "Epoch [79], val_loss: 7.3337\n",
      "gradient norm: 12.25036934018135, minimum ratio: 0.703125\n",
      "Epoch [80], val_loss: 7.4150\n",
      "gradient norm: 12.328154057264328, minimum ratio: 0.6875\n",
      "Epoch [81], val_loss: 7.4970\n",
      "gradient norm: 12.406206667423248, minimum ratio: 0.65234375\n",
      "Epoch [82], val_loss: 7.5796\n",
      "gradient norm: 12.484526485204697, minimum ratio: 0.671875\n",
      "Epoch [83], val_loss: 7.6629\n",
      "gradient norm: 12.56333839893341, minimum ratio: 0.66796875\n",
      "Epoch [84], val_loss: 7.7467\n",
      "gradient norm: 12.642229408025742, minimum ratio: 0.66015625\n",
      "Epoch [85], val_loss: 7.8313\n",
      "gradient norm: 12.721280127763748, minimum ratio: 0.6640625\n",
      "Epoch [86], val_loss: 7.9164\n",
      "gradient norm: 12.800547927618027, minimum ratio: 0.6484375\n",
      "Epoch [87], val_loss: 8.0022\n",
      "gradient norm: 12.8803032040596, minimum ratio: 0.66015625\n",
      "Epoch [88], val_loss: 8.0887\n",
      "gradient norm: 12.960389971733093, minimum ratio: 0.65234375\n",
      "Epoch [89], val_loss: 8.1758\n",
      "gradient norm: 13.040716081857681, minimum ratio: 0.640625\n",
      "Epoch [90], val_loss: 8.2635\n",
      "gradient norm: 13.121417760848999, minimum ratio: 0.6953125\n",
      "Epoch [91], val_loss: 8.3520\n",
      "gradient norm: 13.202124744653702, minimum ratio: 0.66015625\n",
      "Epoch [92], val_loss: 8.4411\n",
      "gradient norm: 13.283559620380402, minimum ratio: 0.66796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93], val_loss: 8.5308\n",
      "gradient norm: 13.365202069282532, minimum ratio: 0.6640625\n",
      "Epoch [94], val_loss: 8.6213\n",
      "gradient norm: 13.446912169456482, minimum ratio: 0.6640625\n",
      "Epoch [95], val_loss: 8.7124\n",
      "gradient norm: 13.528890669345856, minimum ratio: 0.67578125\n",
      "Epoch [96], val_loss: 8.8042\n",
      "gradient norm: 13.611084163188934, minimum ratio: 0.6796875\n",
      "Epoch [97], val_loss: 8.8967\n",
      "gradient norm: 13.69374230504036, minimum ratio: 0.640625\n",
      "Epoch [98], val_loss: 8.9899\n",
      "gradient norm: 13.777151316404343, minimum ratio: 0.67578125\n",
      "Epoch [99], val_loss: 9.0838\n",
      "gradient norm: 13.860296547412872, minimum ratio: 0.66796875\n",
      "Epoch [100], val_loss: 9.1784\n",
      "gradient norm: 13.94383955001831, minimum ratio: 0.640625\n",
      "Epoch [101], val_loss: 9.2737\n",
      "gradient norm: 14.027676314115524, minimum ratio: 0.66015625\n",
      "Epoch [102], val_loss: 9.3698\n",
      "gradient norm: 14.111709475517273, minimum ratio: 0.671875\n",
      "Epoch [103], val_loss: 9.4665\n",
      "gradient norm: 14.19635733962059, minimum ratio: 0.66796875\n",
      "Epoch [104], val_loss: 9.5640\n",
      "gradient norm: 14.281289875507355, minimum ratio: 0.6796875\n",
      "Epoch [105], val_loss: 9.6621\n",
      "gradient norm: 14.366414159536362, minimum ratio: 0.6796875\n",
      "Epoch [106], val_loss: 9.7610\n",
      "gradient norm: 14.451964735984802, minimum ratio: 0.65625\n",
      "Epoch [107], val_loss: 9.8606\n",
      "gradient norm: 14.537631660699844, minimum ratio: 0.67578125\n",
      "Epoch [108], val_loss: 9.9610\n",
      "gradient norm: 14.623913198709488, minimum ratio: 0.6796875\n",
      "Epoch [109], val_loss: 10.0621\n",
      "gradient norm: 14.710400730371475, minimum ratio: 0.6796875\n",
      "Epoch [110], val_loss: 10.1639\n",
      "gradient norm: 14.797034293413162, minimum ratio: 0.6796875\n",
      "Epoch [111], val_loss: 10.2665\n",
      "gradient norm: 14.88417398929596, minimum ratio: 0.65625\n",
      "Epoch [112], val_loss: 10.3698\n",
      "gradient norm: 14.971456557512283, minimum ratio: 0.6640625\n",
      "Epoch [113], val_loss: 10.4739\n",
      "gradient norm: 15.059488743543625, minimum ratio: 0.6953125\n",
      "Epoch [114], val_loss: 10.5788\n",
      "gradient norm: 15.147494375705719, minimum ratio: 0.671875\n",
      "Epoch [115], val_loss: 10.6844\n",
      "gradient norm: 15.23582649230957, minimum ratio: 0.65234375\n",
      "Epoch [116], val_loss: 10.7908\n",
      "gradient norm: 15.324252635240555, minimum ratio: 0.68359375\n",
      "Epoch [117], val_loss: 10.8980\n",
      "gradient norm: 15.413503229618073, minimum ratio: 0.6640625\n",
      "Epoch [118], val_loss: 11.0059\n",
      "gradient norm: 15.502860426902771, minimum ratio: 0.66015625\n",
      "Epoch [119], val_loss: 11.1146\n",
      "gradient norm: 15.592409908771515, minimum ratio: 0.65625\n",
      "Epoch [120], val_loss: 11.2241\n",
      "gradient norm: 15.682450950145721, minimum ratio: 0.65625\n",
      "Epoch [121], val_loss: 11.3344\n",
      "gradient norm: 15.772639095783234, minimum ratio: 0.66015625\n",
      "Epoch [122], val_loss: 11.4455\n",
      "gradient norm: 15.863215208053589, minimum ratio: 0.640625\n",
      "Epoch [123], val_loss: 11.5575\n",
      "gradient norm: 15.9547518491745, minimum ratio: 0.6796875\n",
      "Epoch [124], val_loss: 11.6702\n",
      "gradient norm: 16.046024978160858, minimum ratio: 0.640625\n",
      "Epoch [125], val_loss: 11.7837\n",
      "gradient norm: 16.137780129909515, minimum ratio: 0.64453125\n",
      "Epoch [126], val_loss: 11.8981\n",
      "gradient norm: 16.229713797569275, minimum ratio: 0.6640625\n",
      "Epoch [127], val_loss: 12.0132\n",
      "gradient norm: 16.322112560272217, minimum ratio: 0.66796875\n",
      "Epoch [128], val_loss: 12.1292\n",
      "gradient norm: 16.41483783721924, minimum ratio: 0.66796875\n",
      "Epoch [129], val_loss: 12.2461\n",
      "gradient norm: 16.508281409740448, minimum ratio: 0.66015625\n",
      "Epoch [130], val_loss: 12.3637\n",
      "gradient norm: 16.60179829597473, minimum ratio: 0.640625\n",
      "Epoch [131], val_loss: 12.4822\n",
      "gradient norm: 16.6951841711998, minimum ratio: 0.640625\n",
      "Epoch [132], val_loss: 12.6016\n",
      "gradient norm: 16.789321422576904, minimum ratio: 0.671875\n",
      "Epoch [133], val_loss: 12.7218\n",
      "gradient norm: 16.883836328983307, minimum ratio: 0.66015625\n",
      "Epoch [134], val_loss: 12.8429\n",
      "gradient norm: 16.97859436273575, minimum ratio: 0.65234375\n",
      "Epoch [135], val_loss: 12.9648\n",
      "gradient norm: 17.073850274086, minimum ratio: 0.671875\n",
      "Epoch [136], val_loss: 13.0876\n",
      "gradient norm: 17.169524610042572, minimum ratio: 0.6796875\n",
      "Epoch [137], val_loss: 13.2112\n",
      "gradient norm: 17.26543891429901, minimum ratio: 0.64453125\n",
      "Epoch [138], val_loss: 13.3358\n",
      "gradient norm: 17.3620485663414, minimum ratio: 0.66796875\n",
      "Epoch [139], val_loss: 13.4612\n",
      "gradient norm: 17.458532631397247, minimum ratio: 0.640625\n",
      "Epoch [140], val_loss: 13.5875\n",
      "gradient norm: 17.555463016033173, minimum ratio: 0.671875\n",
      "Epoch [141], val_loss: 13.7147\n",
      "gradient norm: 17.652749717235565, minimum ratio: 0.65234375\n",
      "Epoch [142], val_loss: 13.8428\n",
      "gradient norm: 17.75068187713623, minimum ratio: 0.65234375\n",
      "Epoch [143], val_loss: 13.9717\n",
      "gradient norm: 17.849080801010132, minimum ratio: 0.6484375\n",
      "Epoch [144], val_loss: 14.1017\n",
      "gradient norm: 17.947337687015533, minimum ratio: 0.671875\n",
      "Epoch [145], val_loss: 14.2325\n",
      "gradient norm: 18.0461083650589, minimum ratio: 0.66796875\n",
      "Epoch [146], val_loss: 14.3642\n",
      "gradient norm: 18.14499044418335, minimum ratio: 0.65234375\n",
      "Epoch [147], val_loss: 14.4968\n",
      "gradient norm: 18.245007574558258, minimum ratio: 0.65625\n",
      "Epoch [148], val_loss: 14.6304\n",
      "gradient norm: 18.34516131877899, minimum ratio: 0.65234375\n",
      "Epoch [149], val_loss: 14.7649\n",
      "gradient norm: 18.44508296251297, minimum ratio: 0.66796875\n",
      "Epoch [150], val_loss: 14.9004\n",
      "gradient norm: 18.545848488807678, minimum ratio: 0.6640625\n",
      "Epoch [151], val_loss: 15.0368\n",
      "gradient norm: 18.64720094203949, minimum ratio: 0.68359375\n",
      "Epoch [152], val_loss: 15.1741\n",
      "gradient norm: 18.748850882053375, minimum ratio: 0.63671875\n",
      "Epoch [153], val_loss: 15.3124\n",
      "gradient norm: 18.85059404373169, minimum ratio: 0.66796875\n",
      "Epoch [154], val_loss: 15.4517\n",
      "gradient norm: 18.95281273126602, minimum ratio: 0.6484375\n",
      "Epoch [155], val_loss: 15.5919\n",
      "gradient norm: 19.055347800254822, minimum ratio: 0.6484375\n",
      "Epoch [156], val_loss: 15.7331\n",
      "gradient norm: 19.15834951400757, minimum ratio: 0.65625\n",
      "Epoch [157], val_loss: 15.8753\n",
      "gradient norm: 19.261979520320892, minimum ratio: 0.65625\n",
      "Epoch [158], val_loss: 16.0185\n",
      "gradient norm: 19.365936636924744, minimum ratio: 0.6640625\n",
      "Epoch [159], val_loss: 16.1626\n",
      "gradient norm: 19.470129549503326, minimum ratio: 0.6875\n",
      "Epoch [160], val_loss: 16.3078\n",
      "gradient norm: 19.57456809282303, minimum ratio: 0.69140625\n",
      "Epoch [161], val_loss: 16.4539\n",
      "gradient norm: 19.679566085338593, minimum ratio: 0.66015625\n",
      "Epoch [162], val_loss: 16.6010\n",
      "gradient norm: 19.784708499908447, minimum ratio: 0.63671875\n",
      "Epoch [163], val_loss: 16.7492\n",
      "gradient norm: 19.890449821949005, minimum ratio: 0.67578125\n",
      "Epoch [164], val_loss: 16.8983\n",
      "gradient norm: 19.9965797662735, minimum ratio: 0.66796875\n",
      "Epoch [165], val_loss: 17.0485\n",
      "gradient norm: 20.102811872959137, minimum ratio: 0.6328125\n",
      "Epoch [166], val_loss: 17.1997\n",
      "gradient norm: 20.20991486310959, minimum ratio: 0.66015625\n",
      "Epoch [167], val_loss: 17.3520\n",
      "gradient norm: 20.31737130880356, minimum ratio: 0.6640625\n",
      "Epoch [168], val_loss: 17.5053\n",
      "gradient norm: 20.425378561019897, minimum ratio: 0.62890625\n",
      "Epoch [169], val_loss: 17.6596\n",
      "gradient norm: 20.53334379196167, minimum ratio: 0.65234375\n",
      "Epoch [170], val_loss: 17.8150\n",
      "gradient norm: 20.641665160655975, minimum ratio: 0.6328125\n",
      "Epoch [171], val_loss: 17.9714\n",
      "gradient norm: 20.750670909881592, minimum ratio: 0.640625\n",
      "Epoch [172], val_loss: 18.1289\n",
      "gradient norm: 20.860167026519775, minimum ratio: 0.65234375\n",
      "Epoch [173], val_loss: 18.2874\n",
      "gradient norm: 20.97045660018921, minimum ratio: 0.6640625\n",
      "Epoch [174], val_loss: 18.4471\n",
      "gradient norm: 21.08056676387787, minimum ratio: 0.65234375\n",
      "Epoch [175], val_loss: 18.6078\n",
      "gradient norm: 21.190791249275208, minimum ratio: 0.66015625\n",
      "Epoch [176], val_loss: 18.7696\n",
      "gradient norm: 21.30157619714737, minimum ratio: 0.6640625\n",
      "Epoch [177], val_loss: 18.9324\n",
      "gradient norm: 21.41324692964554, minimum ratio: 0.65234375\n",
      "Epoch [178], val_loss: 19.0964\n",
      "gradient norm: 21.524877607822418, minimum ratio: 0.6484375\n",
      "Epoch [179], val_loss: 19.2615\n",
      "gradient norm: 21.637293219566345, minimum ratio: 0.62890625\n",
      "Epoch [180], val_loss: 19.4277\n",
      "gradient norm: 21.750047981739044, minimum ratio: 0.640625\n",
      "Epoch [181], val_loss: 19.5950\n",
      "gradient norm: 21.86303859949112, minimum ratio: 0.6640625\n",
      "Epoch [182], val_loss: 19.7634\n",
      "gradient norm: 21.97650182247162, minimum ratio: 0.65625\n",
      "Epoch [183], val_loss: 19.9329\n",
      "gradient norm: 22.09014517068863, minimum ratio: 0.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184], val_loss: 20.1036\n",
      "gradient norm: 22.204712212085724, minimum ratio: 0.6796875\n",
      "Epoch [185], val_loss: 20.2754\n",
      "gradient norm: 22.31958943605423, minimum ratio: 0.6640625\n",
      "Epoch [186], val_loss: 20.4484\n",
      "gradient norm: 22.43469524383545, minimum ratio: 0.66796875\n",
      "Epoch [187], val_loss: 20.6225\n",
      "gradient norm: 22.550527095794678, minimum ratio: 0.64453125\n",
      "Epoch [188], val_loss: 20.7978\n",
      "gradient norm: 22.666279196739197, minimum ratio: 0.65625\n",
      "Epoch [189], val_loss: 20.9742\n",
      "gradient norm: 22.782846093177795, minimum ratio: 0.6640625\n",
      "Epoch [190], val_loss: 21.1519\n",
      "gradient norm: 22.899579346179962, minimum ratio: 0.66015625\n",
      "Epoch [191], val_loss: 21.3306\n",
      "gradient norm: 23.017061948776245, minimum ratio: 0.66796875\n",
      "Epoch [192], val_loss: 21.5106\n",
      "gradient norm: 23.134754061698914, minimum ratio: 0.6953125\n",
      "Epoch [193], val_loss: 21.6917\n",
      "gradient norm: 23.253042340278625, minimum ratio: 0.65625\n",
      "Epoch [194], val_loss: 21.8741\n",
      "gradient norm: 23.371673464775085, minimum ratio: 0.6640625\n",
      "Epoch [195], val_loss: 22.0577\n",
      "gradient norm: 23.490951418876648, minimum ratio: 0.6640625\n",
      "Epoch [196], val_loss: 22.2424\n",
      "gradient norm: 23.610412180423737, minimum ratio: 0.66015625\n"
     ]
    }
   ],
   "source": [
    "history_1,grad_norm_1,model_1  = fit(num_epochs, lr, model_1, data_loader, criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_norm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "687c3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses_1 = [r['val_loss'] for r in history_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e2f5c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_losses_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f062c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_ratio_eps = [i['ratio'] for i in grad_norm_1.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f17a6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(minimal_ratio_eps,val_losses_1)\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('minimal ratio')\n",
    "plt.title('loss_vs_minimal ratio');\n",
    "plt.plot()\n",
    "plt.savefig(\"loss_vs_minimal ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e1036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
