{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5ad7f7870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=600, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M1(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M2, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 150)\n",
    "        self.fc3 = nn.Linear(150, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M3(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M3, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M4(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M4, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M5, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M6(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M6, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 90)\n",
    "        self.fc3 = nn.Linear(90, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M7(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M7, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M8(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M8, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 210)\n",
    "        self.fc3 = nn.Linear(210, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M9(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M9, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M10(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M10, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 300)\n",
    "        self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "max_epochs = 15\n",
    "learning_rate = 0.001\n",
    "kernel_size = 4\n",
    "num_epochs = 10\n",
    "dropout = 0.25\n",
    "#weight_decay_val = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 1: 25550\n"
     ]
    }
   ],
   "source": [
    "m1 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m1.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m1_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 1:', m1_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 2: 28600\n"
     ]
    }
   ],
   "source": [
    "m2 = M2()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m2_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 2:', m2_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 3: 24330\n"
     ]
    }
   ],
   "source": [
    "m3 = M3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m3_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 3:', m3_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 4: 26770\n"
     ]
    }
   ],
   "source": [
    "m4 = M4()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m4.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m4_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 4:', m4_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 5: 22500\n"
     ]
    }
   ],
   "source": [
    "m5 = M5()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m5.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m5_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 5:', m5_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 6: 24940\n"
     ]
    }
   ],
   "source": [
    "m6 = M6()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m6.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m6.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m6_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 6:', m6_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 7: 31650\n"
     ]
    }
   ],
   "source": [
    "m7 = M7()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m7.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m7.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m7_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 7:', m7_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 8: 32260\n"
     ]
    }
   ],
   "source": [
    "m8 = M8()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m8.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m8.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m8_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 8:', m8_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 9: 34700\n"
     ]
    }
   ],
   "source": [
    "m9 = M9()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m9.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m9.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m9_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 9:', m9_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 10: 37750\n"
     ]
    }
   ],
   "source": [
    "m10 = M10()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m10.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m10.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m10_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 10:', m10_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs):\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    not_converged =True\n",
    "    epoch = 0\n",
    "    while not_converged:\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print (f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                train_epoch.append(epoch)\n",
    "                train_losses.append(loss.item())\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Accuracy : {acc} %')\n",
    "                train_acc.append(acc)\n",
    "\n",
    "                if epoch == num_epochs:\n",
    "                        print(\"Max Epoch Reached\")\n",
    "                        not_converged = False\n",
    "                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n",
    "                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n",
    "                        print(\"Convergeance reached for loss:\",loss_arr[-1])\n",
    "                        not_converged = False\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "def testFunc(model): \n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        for images, labels in test_loader:\n",
    "            prediction = model(images)\n",
    "            tLoss = loss_func(prediction, labels)\n",
    "            testLoss += tLoss\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        testLoss /= len(test_loader.dataset)\n",
    "        netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network:{model} on the test images: {netTest_acc1} % & loss of the network:{testLoss:.4f}')\n",
    "        return netTest_acc1,testLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/100], Loss: 0.4273\n",
      "Epoch [1/10], Accuracy : 62.946666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1901\n",
      "Epoch [2/10], Accuracy : 90.885 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1356\n",
      "Epoch [3/10], Accuracy : 94.385 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1161\n",
      "Epoch [4/10], Accuracy : 95.885 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0940\n",
      "Epoch [5/10], Accuracy : 96.52 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0702\n",
      "Epoch [6/10], Accuracy : 97.02666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1066\n",
      "Epoch [7/10], Accuracy : 97.32666666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0661\n",
      "Epoch [8/10], Accuracy : 97.625 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0765\n",
      "Epoch [9/10], Accuracy : 97.73666666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0621\n",
      "Epoch [10/10], Accuracy : 97.99 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "M1train_epoch,M1train_losses,M1train_acc = trainFunc(m1,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model2 Test\n",
      "Total no of parameters in Model 2: 28600\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3794\n",
      "Epoch [1/10], Accuracy : 64.415 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2229\n",
      "Epoch [2/10], Accuracy : 91.1 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1928\n",
      "Epoch [3/10], Accuracy : 94.04166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1614\n",
      "Epoch [4/10], Accuracy : 95.3 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1044\n",
      "Epoch [5/10], Accuracy : 96.035 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1387\n",
      "Epoch [6/10], Accuracy : 96.48166666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1265\n",
      "Epoch [7/10], Accuracy : 96.745 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1372\n",
      "Epoch [8/10], Accuracy : 97.14833333333333 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0803\n",
      "Epoch [9/10], Accuracy : 97.255 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.1074\n",
      "Epoch [10/10], Accuracy : 97.42333333333333 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model3 Test\n",
      "Total no of parameters in Model 3: 24330\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4004\n",
      "Epoch [1/10], Accuracy : 61.156666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2400\n",
      "Epoch [2/10], Accuracy : 91.18166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1466\n",
      "Epoch [3/10], Accuracy : 94.21833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1370\n",
      "Epoch [4/10], Accuracy : 95.52166666666666 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1335\n",
      "Epoch [5/10], Accuracy : 96.015 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0948\n",
      "Epoch [6/10], Accuracy : 96.66666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0982\n",
      "Epoch [7/10], Accuracy : 96.82166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0754\n",
      "Epoch [8/10], Accuracy : 97.16666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0570\n",
      "Epoch [9/10], Accuracy : 97.32833333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.1072\n",
      "Epoch [10/10], Accuracy : 97.54333333333334 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model4 Test\n",
      "Total no of parameters in Model 4: 26770\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4402\n",
      "Epoch [1/10], Accuracy : 61.361666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2234\n",
      "Epoch [2/10], Accuracy : 89.70166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1558\n",
      "Epoch [3/10], Accuracy : 93.69166666666666 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1353\n",
      "Epoch [4/10], Accuracy : 95.095 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1086\n",
      "Epoch [5/10], Accuracy : 95.84 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0809\n",
      "Epoch [6/10], Accuracy : 96.41 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0906\n",
      "Epoch [7/10], Accuracy : 96.70166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1060\n",
      "Epoch [8/10], Accuracy : 97.01666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.1113\n",
      "Epoch [9/10], Accuracy : 97.19 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0754\n",
      "Epoch [10/10], Accuracy : 97.36666666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model5 Test\n",
      "Total no of parameters in Model 5: 22500\n",
      "Epoch [1/10], Step [100/100], Loss: 0.5135\n",
      "Epoch [1/10], Accuracy : 59.001666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2682\n",
      "Epoch [2/10], Accuracy : 88.37666666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.2607\n",
      "Epoch [3/10], Accuracy : 92.56 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1528\n",
      "Epoch [4/10], Accuracy : 94.32666666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.2001\n",
      "Epoch [5/10], Accuracy : 95.06666666666666 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0963\n",
      "Epoch [6/10], Accuracy : 95.745 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1498\n",
      "Epoch [7/10], Accuracy : 96.145 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0939\n",
      "Epoch [8/10], Accuracy : 96.37833333333333 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0800\n",
      "Epoch [9/10], Accuracy : 96.705 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0844\n",
      "Epoch [10/10], Accuracy : 97.02833333333334 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model6 Test\n",
      "Total no of parameters in Model 6: 24940\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3842\n",
      "Epoch [1/10], Accuracy : 63.605 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2447\n",
      "Epoch [2/10], Accuracy : 90.80333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1930\n",
      "Epoch [3/10], Accuracy : 94.14333333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1765\n",
      "Epoch [4/10], Accuracy : 95.42833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0994\n",
      "Epoch [5/10], Accuracy : 96.15333333333334 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1130\n",
      "Epoch [6/10], Accuracy : 96.55333333333333 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0884\n",
      "Epoch [7/10], Accuracy : 96.87333333333333 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1011\n",
      "Epoch [8/10], Accuracy : 97.08 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0830\n",
      "Epoch [9/10], Accuracy : 97.30166666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0728\n",
      "Epoch [10/10], Accuracy : 97.41666666666667 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model7 Test\n",
      "Total no of parameters in Model 7: 31650\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3875\n",
      "Epoch [1/10], Accuracy : 65.11666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1978\n",
      "Epoch [2/10], Accuracy : 91.30333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1965\n",
      "Epoch [3/10], Accuracy : 94.37666666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1364\n",
      "Epoch [4/10], Accuracy : 95.56166666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0971\n",
      "Epoch [5/10], Accuracy : 96.23833333333333 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1066\n",
      "Epoch [6/10], Accuracy : 96.72166666666666 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0653\n",
      "Epoch [7/10], Accuracy : 97.06166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1024\n",
      "Epoch [8/10], Accuracy : 97.285 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0793\n",
      "Epoch [9/10], Accuracy : 97.335 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0674\n",
      "Epoch [10/10], Accuracy : 97.475 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model8 Test\n",
      "Total no of parameters in Model 8: 32260\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3935\n",
      "Epoch [1/10], Accuracy : 69.86666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2225\n",
      "Epoch [2/10], Accuracy : 91.64333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1885\n",
      "Epoch [3/10], Accuracy : 94.29833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1406\n",
      "Epoch [4/10], Accuracy : 95.26333333333334 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1296\n",
      "Epoch [5/10], Accuracy : 95.81166666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0982\n",
      "Epoch [6/10], Accuracy : 96.425 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1046\n",
      "Epoch [7/10], Accuracy : 96.65166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0840\n",
      "Epoch [8/10], Accuracy : 96.72666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.1152\n",
      "Epoch [9/10], Accuracy : 97.14166666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0715\n",
      "Epoch [10/10], Accuracy : 97.21 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model9 Test\n",
      "Total no of parameters in Model 9: 34700\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3939\n",
      "Epoch [1/10], Accuracy : 69.21833333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2505\n",
      "Epoch [2/10], Accuracy : 91.2 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1768\n",
      "Epoch [3/10], Accuracy : 94.135 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1439\n",
      "Epoch [4/10], Accuracy : 95.28 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1449\n",
      "Epoch [5/10], Accuracy : 95.935 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1247\n",
      "Epoch [6/10], Accuracy : 96.38666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1194\n",
      "Epoch [7/10], Accuracy : 96.64833333333333 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1269\n",
      "Epoch [8/10], Accuracy : 97.045 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0877\n",
      "Epoch [9/10], Accuracy : 97.24166666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0941\n",
      "Epoch [10/10], Accuracy : 97.36166666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model10 Test\n",
      "Total no of parameters in Model 10: 37750\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3956\n",
      "Epoch [1/10], Accuracy : 68.88 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1665\n",
      "Epoch [2/10], Accuracy : 91.27666666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1970\n",
      "Epoch [3/10], Accuracy : 94.09166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1589\n",
      "Epoch [4/10], Accuracy : 95.28833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1062\n",
      "Epoch [5/10], Accuracy : 95.84166666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1180\n",
      "Epoch [6/10], Accuracy : 96.27666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1045\n",
      "Epoch [7/10], Accuracy : 96.58 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0958\n",
      "Epoch [8/10], Accuracy : 96.95666666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0922\n",
      "Epoch [9/10], Accuracy : 97.19666666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0651\n",
      "Epoch [10/10], Accuracy : 97.27166666666666 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel2 Test\")\n",
    "m2 = M2()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m2_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 2:', m2_TotalPrams)\n",
    "\n",
    "M2train_epoch,M2train_losses,M2train_acc = trainFunc(m2,num_epochs)\n",
    "\n",
    "print(\"\\nModel3 Test\")\n",
    "m3 = M3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m3_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 3:', m3_TotalPrams)\n",
    "M3train_epoch,M3train_losses,M3train_acc = trainFunc(m3,num_epochs)\n",
    "print(\"\\nModel4 Test\")\n",
    "m4 = M4()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m4.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m4_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 4:', m4_TotalPrams)\n",
    "M4train_epoch,M4train_losses,M4train_acc = trainFunc(m4,num_epochs)\n",
    "print(\"\\nModel5 Test\")\n",
    "m5 = M5()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m5.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m5_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 5:', m5_TotalPrams)\n",
    "M5train_epoch,M5train_losses,M5train_acc = trainFunc(m5,num_epochs)\n",
    "\n",
    "print(\"\\nModel6 Test\")\n",
    "m6 = M6()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m6.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m6.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m6_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 6:', m6_TotalPrams)\n",
    "M6train_epoch,M6train_losses,M6train_acc = trainFunc(m6,num_epochs)\n",
    "\n",
    "print(\"\\nModel7 Test\")\n",
    "m7 = M7()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m7.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m7.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m7_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 7:', m7_TotalPrams)\n",
    "M7train_epoch,M7train_losses,M7train_acc = trainFunc(m7,num_epochs)\n",
    "\n",
    "print(\"\\nModel8 Test\")\n",
    "m8 = M8()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m8.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m8.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m8_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 8:', m8_TotalPrams)\n",
    "M8train_epoch,M8train_losses,M8train_acc = trainFunc(m8,num_epochs)\n",
    "\n",
    "print(\"\\nModel9 Test\")\n",
    "m9 = M9()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m9.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m9.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m9_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 9:', m9_TotalPrams)\n",
    "M9train_epoch,M9train_losses,M9train_acc = trainFunc(m9,num_epochs)\n",
    "\n",
    "print(\"\\nModel10 Test\")\n",
    "m10 = M10()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m10.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m10.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m10_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 10:', m10_TotalPrams)\n",
    "M10train_epoch,M10train_losses,M10train_acc = trainFunc(m10,num_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:M1(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ") on the test images: 91.47 % & loss of the network:0.0029\n",
      "Accuracy of the network:M2(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=150, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=10, bias=True)\n",
      ") on the test images: 97.57 % & loss of the network:0.0008\n",
      "Accuracy of the network:M3(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=80, bias=True)\n",
      "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
      ") on the test images: 97.69 % & loss of the network:0.0008\n",
      "Accuracy of the network:M4(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ") on the test images: 97.59 % & loss of the network:0.0008\n",
      "Accuracy of the network:M5(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
      ") on the test images: 97.38 % & loss of the network:0.0009\n",
      "Accuracy of the network:M6(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=90, bias=True)\n",
      "  (fc3): Linear(in_features=90, out_features=10, bias=True)\n",
      ") on the test images: 97.55 % & loss of the network:0.0008\n",
      "Accuracy of the network:M7(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ") on the test images: 97.86 % & loss of the network:0.0007\n",
      "Accuracy of the network:M8(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=210, bias=True)\n",
      "  (fc3): Linear(in_features=210, out_features=10, bias=True)\n",
      ") on the test images: 97.6 % & loss of the network:0.0008\n",
      "Accuracy of the network:M9(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=250, bias=True)\n",
      "  (fc3): Linear(in_features=250, out_features=10, bias=True)\n",
      ") on the test images: 96.95 % & loss of the network:0.0009\n",
      "Accuracy of the network:M10(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=10, bias=True)\n",
      ") on the test images: 97.62 % & loss of the network:0.0008\n"
     ]
    }
   ],
   "source": [
    "M1netTest_acc1,M1testLoss = testFunc(m1)\n",
    "M2netTest_acc1,M2testLoss = testFunc(m2)\n",
    "M3netTest_acc1,M3testLoss = testFunc(m3)\n",
    "M4netTest_acc1,M4testLoss = testFunc(m4)\n",
    "M5netTest_acc1,M5testLoss = testFunc(m5)\n",
    "M6netTest_acc1,M6testLoss = testFunc(m6)\n",
    "M7netTest_acc1,M7testLoss = testFunc(m7)\n",
    "M8netTest_acc1,M8testLoss = testFunc(m8)\n",
    "M9netTest_acc1,M9testLoss = testFunc(m9)\n",
    "M10netTest_acc1,M10testLoss = testFunc(m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAevElEQVR4nO3de5QU9Z338feXAR0HCBhAl4swkyhGGO7DRV0vLCYC+gRNjrsqKmjMHJ7oRvNEHmHJycUTn5iYVcJZIotZPRHHeGHVeDbswmpwJT4CDopGBR4GGGTAjcMoiAxegO/zR9VI0/bMdE/3TFdPfV7n9JnuX92+XdNVn65LV5m7IyIi8dMl3wWIiEh+KABERGJKASAiElMKABGRmFIAiIjElAJARCSmFAAiIjGlAJCsmVmtmV3UwdOcb2YvpGjva2afmFm5mZ1gZv9oZnVm9qGZ7TCze1sYp5vZwbDf3WZ2j5kVte87yY6ZXWhmdfmuQwqTAkAK1TLgHDMrS2q/Evizu78BzAcqgAlAT2Ay8Gor4x3l7j2AKcDVwLczKcrMumbSf74VWr2SWwoAaTdmdqKZLTSzPeFjoZmdGHbra2b/Zmb7zOw9M1tjZl3CbreH38APmNkWM5uSPG53rwP+CFyb1Ok64Lfh8/HAU+6+xwO17v5QOrW7+2ZgDVBuZl82sz+aWYOZ7TWzKjPrnfA+a8OaXwcOmllXM5tnZtvC9/CWmV2e0P9sM3vRzO4N3/92MzsnbN9lZu+a2ayk+fhLM3vbzP5iZkvM7CQz6w78OzAg3Gr50MwGmFmXhOk3mNnjZvbFcFyl4ZbOt8zsbeCPZlZsZg+H/e4zs5fN7NR05pMUNgWAtKcFwCRgNDCK4Jv4D8Ju3wfqgH7AqcA/AG5mZwI3A+PdvSdwMVDbzPh/S0IAhMOOBn4XNq0F/peZfcfMRpiZpVu4mQ0DziPYYjDgZ8AA4CzgNODHSYNcBVwC9Hb3w8C2cPhewE+Ah82sf0L/E4HXgT7AI8CjBIF1OnAN8E9m1iPs9+fA0PC9nQ4MBH7o7geBacAed+8RPvYA3wUuAy4Ia34fWJxU7wXhe7kYmBXWeVpYzxzgULrzSgqYu+uhR1YPghX0RSnatwHTE15fDNSGz+8Afg+cnjTM6cC7wEVAt1amWwJ8AJwTvr4T+H1C9yLgJuBF4GNgDzCrhfF5OL73w9p/CnRJ0d9lwKtJ7/+GVmrdCMwIn88GtiZ0GxFO+9SEtgaCFb4BB4EvJ3Q7G9gRPr8QqEua1iZgSsLr/sCnQFegNJzWlxK63wD8X2Bkvj9LenTsQ1sA0p4GADsTXu8M2wDuBmqAVeEukHkA7l4D3ErwDftdM3vUzAaQgrs3Ak8A14Xf7mdybPcP7n7E3Re7+7lAb4KAeMDMzmqh5rHufrK7f9ndf+DuR83slLCO3Wb2AfAw0DdpuF2JL8zsOjPbGO5S2QeUJw3zl4Tnh8J6k9t6EGwhlQAbEsb1H2F7c4YATyX0vwk4QrCllareZcBK4NFwV90vzKxbC+OXTkIBIO1pD8HKqMngsA13P+Du33f3LwH/g2BXzZSw2yPu/tfhsE6wC6Q5vwX+FvgqwYHef0vVk7sfcvfFBN/uh2X4Pn4W1jHS3b9AsIsmeXfSZ5fVNbMhwP0Eu7L6uHtv4I0Uw6RjL0EYDHf33uGjlwcHqo+bboJdwLSE/nu7e7G7705Vr7t/6u4/cfdhwDnApQTHUqSTUwBIrnQLDyY2PboS7Iv/gZn1M7O+wA8Jvj1jZpea2enhN/cPCL6hHjGzM83sb8KDxR8RrPyOtDDdNcA+YCnwqLt/0tTBzG4NT5M8KTwwO4sgJFo7EyhZT+BDYJ+ZDQTmttJ/d4IVbH1Yx/UEWwAZc/ejBGFyr5mdEo5voJldHPbyF6CPmfVKGGwJcGcYRITzf0Zz0zCzyeExkiKC/8WntDzPpZNQAEiurCBYWTc9fkywD72a4GDnn4FXwjaAM4BnCVasLwG/dvfngROBuwi++f43cArBAeKU3N2Bhwi2FpLP8DkE/GM4nr0ExwO+6e7bM3xvPwHGAvuBPwBPttSzu78VTvclghX0CILjEG11O8HusrXhLqhngTPDaW0mCNrt4S6fAcCvgGcIdq8dIDgYPrGF8f8VsJxg5b8J+C/CoJbOzYLlR0RE4kZbACIiMaUAEBGJKQWAiEhMKQBERGIqkheC6tu3r5eWlua7DBGRgrFhw4a97t7SDwQ/J5IBUFpaSnV1db7LEBEpGGa2s/W+jqddQCIiMaUAEBGJKQWAiEhMKQBERGJKASAiElMKABGJlKoqKC2FLl2Cv1VV+a6o84rkaaAiEk9VVVBZCY2NweudO4PXADNn5q+uzkpbACISGQsWHFv5N2lsDNol9xQAIhIZb7+dWbtkRwEgIpExeHBm7ZIdBYCIRMadd0JJyfFtJSVBu+SeAkBEImPmTFi6FIYMAbPg79KlOgDcXnQWkIhEysyZWuF3FG0BiIjElAJARCSmFAAiIjGlABARiSkFgIhITCkARERiSgEgIhJTCgARkZhSAIiIxJQCQAqKbhYikjtpBYCZTTWzLWZWY2bzUnQ3M1sUdn/dzMYmdPuemb1pZm+Y2e/MrDiXb6CJVgydX9PNQnbuBPdjNwvR/1qkbVoNADMrAhYD04BhwFVmNiypt2nAGeGjErgvHHYg8F2gwt3LgSLgypxVH9KKIR50sxCR3EpnC2ACUOPu2939E+BRYEZSPzOAhzywFuhtZv3Dbl2Bk8ysK1AC7MlR7Z/RiiEedLMQkdxKJwAGArsSXteFba324+67gV8CbwPvAPvdfVWqiZhZpZlVm1l1fX19uvUDWjHEhW4WIpJb6QSApWjzdPoxs5MJtg7KgAFAdzO7JtVE3H2pu1e4e0W/fv3SKOsYrRjiQTcLEcmtdAKgDjgt4fUgPr8bp7l+LgJ2uHu9u38KPAmc0/ZyU9OKIR50sxCR3EonAF4GzjCzMjM7geAg7jNJ/TwDXBeeDTSJYFfPOwS7fiaZWYmZGTAF2JTD+gGtGOJk5kyorYWjR4O/+h+LtF2rdwRz98NmdjOwkuAsngfc/U0zmxN2XwKsAKYDNUAjcH3YbZ2ZLQdeAQ4DrwJL2+ON6C5CIiKZMffk3fn5V1FR4dXV1fkuQ0SkYJjZBnevyGQY/RJYRCSmFADSLP26WqRza/UYgMRT06+rm35g1/TratCxFpHOQlsAkpJ+XS3S+SkAJCX9ulqk81MASEr6dbVI56cAkJT062qRzk8BEBFRO+NGv64W6fx0FlAERPWMG/26WqRz0xZABOiMGxHJBwVABOiMG8mlqO1OlOhSAESAzriRXNHtUSUTCoAI0Bk3kivanSiZUABEgM64kVzR7kTJhM4CigidcSO5MHhwsNsnVbtIMm0BiHQi2p0omVAAiHQi2p0omdAuIJFORrsTJV3aAhARiSkFgIhITCkARERiSgEgIhJTCgARkZhSAIiIxJQCQCTCdGVPaU8KAJGI0pU94yNfQa8AEIkoXdkzHvIZ9AoAkYjSlT3jIZ9BrwAQiSjdKCge8hn0CgCRiNKVPeMhn0GvABCJKF3ZMx7yGfQKgAKmUwQ7v5kzobYWjh4N/mrl3/nkM+h1OegC1XTmQNPBo6YzB0ArCZFCk69LeGsLoEDpFEERyZYCoEDpFEERyZYCoEDpFEERyVZaAWBmU81si5nVmNm8FN3NzBaF3V83s7EJ3Xqb2XIz22xmm8zs7Fy+gbjSKYIikq1WA8DMioDFwDRgGHCVmQ1L6m0acEb4qATuS+j2K+A/3P0rwChgUw7qjj2dIigi2UrnLKAJQI27bwcws0eBGcBbCf3MAB5ydwfWht/6+wMHgfOB2QDu/gnwSe7Kjzfd/FtEspHOLqCBwK6E13VhWzr9fAmoBx40s1fN7Ddm1j3VRMys0syqzay6vr4+7TcgIiJtk04AWIo2T7OfrsBY4D53H0OwRfC5YwgA7r7U3SvcvaJfv35plCUiItlIJwDqgNMSXg8C9qTZTx1Q5+7rwvblBIEgIiJ5lk4AvAycYWZlZnYCcCXwTFI/zwDXhWcDTQL2u/s77v7fwC4zOzPsbwrHHzsQEZE8aTUA3P0wcDOwkuAMnsfd/U0zm2Nmc8LeVgDbgRrgfuA7CaP4e6DKzF4HRgP/J3flR5eu0yMiUWfBiTvRUlFR4dXV1fkuo82Sr9MDwTn6Ok1TRNqLmW1w94pMhtEvgduBrtMjIoVAAdAOdJ0eESkECoB2oOv0iEghUAC0A12nR0QKgQKgHeg6PSJSCHRHsHai6/SISNRpC0BEJKYUACIiMaUAEBGJKQWAiEhMKQBERGJKASAiElMKABGRmNLvAESkQ3z66afU1dXx0Ucf5buUglZcXMygQYPo1q1b1uNSAIhIh6irq6Nnz56UlpZiluoustIad6ehoYG6ujrKysqyHp92AYlIh/joo4/o06ePVv5ZMDP69OmTs60oBYCIdBit/LOXy3moABARiSkFgIjEwr59+/j1r3+d8XDTp09n3759GQ83e/Zsli9fnvFwHUkBICKRVFUFpaXQpUvwt6oqu/E1FwBHjhxpcbgVK1bQu3fv7CYeUQoAEYmcqiqorISdO8E9+FtZmV0IzJs3j23btjF69GjGjx/P5MmTufrqqxkxYgQAl112GePGjWP48OEsXbr0s+FKS0vZu3cvtbW1nHXWWXz7299m+PDhfO1rX+PQoUNpTfu5555jzJgxjBgxghtuuIGPP/74s5qGDRvGyJEjue222wB44oknKC8vZ9SoUZx//vltf8PpcPfIPcaNG+ci0rm89dZbafc7ZIh7sOo//jFkSNunv2PHDh8+fLi7u69evdpLSkp8+/btn3VvaGhwd/fGxkYfPny47927N6xliNfX1/uOHTu8qKjIX331VXd3v+KKK3zZsmXNTm/WrFn+xBNP+KFDh3zQoEG+ZcsWd3e/9tpr/d577/WGhgYfOnSoHz161N3d33//fXd3Ly8v97q6uuPakqWal0C1Z7iu1RaAiETO229n1t4WEyZMOO5c+kWLFjFq1CgmTZrErl272Lp16+eGKSsrY/To0QCMGzeO2traVqezZcsWysrKGDp0KACzZs3ihRde4Atf+ALFxcXceOONPPnkk5SE95E999xzmT17Nvfff3+ru6eypQAQkcgZPDiz9rbo3r37Z8+ff/55nn32WV566SVee+01xowZk/Jc+xNPPPGz50VFRRw+fLjV6QRfzj+va9eurF+/nm9+85s8/fTTTJ06FYAlS5bw05/+lF27djF69GgaGhoyfWtpUwCISOTceSeEX4g/U1IStLdVz549OXDgQMpu+/fv5+STT6akpITNmzezdu3atk8oyVe+8hVqa2upqakBYNmyZVxwwQV8+OGH7N+/n+nTp7Nw4UI2btwIwLZt25g4cSJ33HEHffv2ZdeuXTmrJZkuBSEikdN0P+0FC4LdPoMHByv/bO6z3adPH84991zKy8s56aSTOPXUUz/rNnXqVJYsWcLIkSM588wzmTRpUpbv4Jji4mIefPBBrrjiCg4fPsz48eOZM2cO7733HjNmzOCjjz7C3bn33nsBmDt3Llu3bsXdmTJlCqNGjcpZLcmsuc2TfKqoqPDq6up8lyEiObRp0ybOOuusfJfRKaSal2a2wd0rMhmPdgGJiMSUdgGJiGThpptu4sUXXzyu7ZZbbuH666/PU0XpUwCIiGRh8eLF+S6hzbQLSEQkphQAIiIxpQAQEYkpBYCISEwpAEQkFtp6PwCAhQsX0tjY2GI/TVcNLSQKABGJph1V8HQpPNIl+LsjuxsCtHcAFCIFgIhEz44qWF8JjTsBD/6ur8wqBBLvBzB37lzuvvtuxo8fz8iRI/nRj34EwMGDB7nkkksYNWoU5eXlPPbYYyxatIg9e/YwefJkJk+enNa07rnnHsrLyykvL2fhwoXNjrupruR7AnSUtH4HYGZTgV8BRcBv3P2upO4Wdp8ONAKz3f2VhO5FQDWw290vzVHtItJZvbYAjiR94z7SGLSXte2CQHfddRdvvPEGGzduZNWqVSxfvpz169fj7nz961/nhRdeoL6+ngEDBvCHP/wBCC4S16tXL+655x5Wr15N3759W53Ohg0bePDBB1m3bh3uzsSJE7ngggvYvn3758b93nvv8dRTT7F582bMrE23nsxGq1sA4cp7MTANGAZcZWbDknqbBpwRPiqB+5K63wJsyrpaEYmHxmYu/N9ce4ZWrVrFqlWrGDNmDGPHjmXz5s1s3bqVESNG8Oyzz3L77bezZs0aevXqlfG4//SnP3H55ZfTvXt3evTowTe+8Q3WrFmTctzN3ROgo6SzC2gCUOPu2939E+BRYEZSPzOAh8Ib06wFeptZfwAzGwRcAvwmh3WLSGdW0syF/5trz5C7M3/+fDZu3MjGjRupqanhW9/6FkOHDmXDhg2MGDGC+fPnc8cdd7Rp3KmkGndz9wToKOkEwEAg8YLUdWFbuv0sBP43cLSliZhZpZlVm1l1fX19GmWJSKc16k4oSvo2XFQStLdR4v0ALr74Yh544AE+/PBDAHbv3s27777Lnj17KCkp4ZprruG2227jlVde+dywrTn//PN5+umnaWxs5ODBgzz11FOcd955Kcfd3D0BOko6xwAsRVtyxKXsx8wuBd519w1mdmFLE3H3pcBSCC4HnUZdItJZNe3nf21BsNunZHCw8m/j/n84/n4A06ZN4+qrr+bss88GoEePHjz88MPU1NQwd+5cunTpQrdu3bjvvmBvdmVlJdOmTaN///6sXr26xemMHTuW2bNnM2HCBABuvPFGxowZw8qVKz837gMHDqS8J0BHafV+AGZ2NvBjd784fD0fwN1/ltDPPwPPu/vvwtdbgAuB7wLXAoeBYuALwJPufk1L09T9AEQ6H90PIHc68n4ALwNnmFmZmZ0AXAk8k9TPM8B1FpgE7Hf3d9x9vrsPcvfScLg/trbyFxGRjtHqLiB3P2xmNwMrCU4DfcDd3zSzOWH3JcAKglNAawhOA43+hbBFRNpg4sSJfPzxx8e1LVu2jBEjRuSporZL63cA7r6CYCWf2LYk4bkDN7UyjueB5zOuUEQ6DXcn+NlQ4Vq3bl1ep5/L2/jql8Ai0iGKi4tpaGjI6QosbtydhoYGiouLczI+3RFMRDrEoEGDqKurQ6d5Z6e4uJhBgwblZFwKABHpEN26daOsrCzfZUgC7QISEYkpBYCISEwpAEREYkoBICISUwoAEZGYUgCIiMSUAkBEJKYUACIiMaUAEBGJKQWAiEhMKQBERGJKASAiElMKABGRmFIAiIjElAJARCSmFAAiIjGlABARiSkFgIhITCkARERiSgEgIhJTCgARkZhSAIiIxJQCQEQkphQAIiIxpQAQEYkpBYCISEwpAEREYkoBICISUwoAEZGYUgCIiMSUAkBEJKYUACIiMaUAEBGJqbQCwMymmtkWM6sxs3kpupuZLQq7v25mY8P208xstZltMrM3zeyWXL8BERFpm1YDwMyKgMXANGAYcJWZDUvqbRpwRvioBO4L2w8D33f3s4BJwE0phhURkTxIZwtgAlDj7tvd/RPgUWBGUj8zgIc8sBbobWb93f0dd38FwN0PAJuAgTmsX0RE2iidABgI7Ep4XcfnV+Kt9mNmpcAYYF2qiZhZpZlVm1l1fX19GmWJiEg20gkAS9HmmfRjZj2AfwVudfcPUk3E3Ze6e4W7V/Tr1y+NskREJBvpBEAdcFrC60HAnnT7MbNuBCv/Knd/su2liohILqUTAC8DZ5hZmZmdAFwJPJPUzzPAdeHZQJOA/e7+jpkZ8C/AJne/J6eVi4hIVrq21oO7Hzazm4GVQBHwgLu/aWZzwu5LgBXAdKAGaASuDwc/F7gW+LOZbQzb/sHdV+T0XYiISMbMPXl3fv5VVFR4dXV1vssQESkYZrbB3SsyGUa/BBYRiSkFgIhITCkARERiSgEgIhJTCgARkZhSAIiIxJQCQEQkphQAIiIxpQAQEYkpBYCISEwpAEREYkoBICISUwoAEZGYUgCIiMSUAkBEJKYUACIiMaUAEBGJKQWAiEhMKQBERGJKASAiElMKABGRmFIAiIjElAJARCSmFAAiIjGlABARiSkFgIhITCkARERiSgEgIhJTCgARkZhSAIiIxJQCoJDtqIKnS+GRLsHfHVX5rkhECkjXfBcgbbSjCtZXwpHG4HXjzuA1QNnM/NUlIgVDWwCF6rUFx1b+TY40Bu0iImlQABSqxrczaxcRSaIAKFQlgzNrFykUOrbVYTpPAETtQ5NpPZn2P+pOKCo5vq2oJGjPlajNU4hmTe2pLe+3kOdR07Gtxp2AHzu2VUjvoS3y9D9LKwDMbKqZbTGzGjObl6K7mdmisPvrZjY23WFzImofmkzraUv9ZTNhwlIoGQJY8HfC0twdAI7aPI1qTe2pLe+30OdRHI9t5fF/Zu7ecg9mRcD/A74K1AEvA1e5+1sJ/UwH/h6YDkwEfuXuE9MZNpWKigqvrq5O/108XRrOvCQlQ+Cy2vTHkyuZ1hO1+kE1RUFb3m+hz6NHugCp1kkGVx/t6Go6Ro7+Z2a2wd0rMpl0OlsAE4Aad9/u7p8AjwIzkvqZATzkgbVAbzPrn+aw2YvaAdFM64la/S1NWzV1nLa830KfR3E8tpXH/1k6ATAQ2JXwui5sS6efdIbNXtQ+NJnWE7X6W5q2auo4bXm/hT6POuLYVtTk8X+WTgBYirbkbbTm+kln2GAEZpVmVm1m1fX19WmUlSBqH5pM64la/aCaoqAt77fQ51F7H9uKojz+z9L5JXAdcFrC60HAnjT7OSGNYQFw96XAUgiOAaRR1zFNH47XFgSbTSWDg5mXrw9NpvVErX7VFA1teb+dYR6VzSyserOVx/9ZOgeBuxIcyJ0C7CY4kHu1u7+Z0M8lwM0cOwi8yN0npDNsKhkfBBYRibm2HARudQvA3Q+b2c3ASqAIeMDd3zSzOWH3JcAKgpV/DdAIXN/SsJkUKCIi7aPVLYB80BaAiEhm2us0UBER6YQUACIiMaUAEBGJqUgeAzCzeiD5t9F9gb15KCddqi87Ua4vyrWB6stWZ6lviLv3y2TEkQyAVMysOtMDHB1J9WUnyvVFuTZQfdmKc33aBSQiElMKABGRmCqkAFia7wJaofqyE+X6olwbqL5sxba+gjkGICIiuVVIWwAiIpJDCgARkbhy9w57EFwaejWwCXgTuCVsvxvYDLwOPAX0ThhmPsFF5rYAFye0jwP+HHZbxLHdWScCj4Xt64DSbOtL6H4bwf0M+nZ0fS3VRnA7zi1h+y+iNO+A0cBaYCNQDUzIU33FwHrgtbC+n4TtXwT+E9ga/j05YvVFZdlIWV8Ulo3W6iMay0dz/9/R5HH5yGqFnukD6A+MDZ/3JLhU9DDga0DXsP3nwM/D58PCGXYiUAZsA4rCbuuBswluOvPvwLSw/TvAkvD5lcBj2dYXvj6N4KqmO5s+5B1ZXwvzbjLwLHBi2O2UKM07YFXC+KcDz+epPgN6hM+7ESwgk4BfAPPC9nl5/Ow1V19Ulo2U9UVh2Whl/kVl+WiuvrwuHx0aAClmyu+Brya1XQ5Uhc/nA/MTuq0M33h/YHNC+1XAPyf2Ez7vSvALOsu2PmA5MAqoTfiQ562+ptqAx4GLUnSPxLwLx/l3CdN6JN/1ASXAKwT3rtgC9A/b+wNbolRfFJeN5PqI3rKR+P+N3PKRVF9el4+8HQMws1JgDEESJrqBINWg5XsN16VoP24Ydz8M7Af6ZFOfmX0d2O3uryX1lpf6kubdUOA8M1tnZv9lZuPzWVuK+m4F7jazXcAvCT7YeanPzIrMbCPwLvCf7r4OONXd3wnH+Q5wSsTqS5TXZSNVfVFaNpqZf5FZPpqp71byuHzkJQDMrAfwr8Ct7v5BQvsC4DBQ1dSUYnBvob2lYdpUX1jPAuCHqXrt6PpSzLuuwMkEm5NzgcfNzPJRWzP1/U/ge+5+GvA94F9amVa71efuR9x9NMGtSSeYWXkLvUeqvigsGynqG0mElo1m5l9klo9m6svr8tHhAWBm3QhWEFXu/mRC+yzgUmCmh9swNH+v4brweXL7ccOEt6TsBbyXRX1fJtgH95qZ1YbTesXM/qqj62tm3tUBT3pgPXCU4OJRUZh3ALOApudPABOSp9VR9TVx933A88BU4C9m1j8cZ3+Cb2dRqi8yy0aK+mYQkWWjmfqmEqHlo5n68rt8ZLr/KpsHQUI9BCxMap8KvAX0S2ofzvEHQrZz7EDIywSp3nQgZHrYfhPHHwh5PNv6kvqp5dh+zg6rr4V5Nwe4I3w+lGAT0KIy7wjOCrowfD4F2JCn/20/wjNogJOANQQr1bs5/iDwLyJWX1SWjZT1RWHZaGX+RWX5aK6+vC4f7bayb2Ym/DXBJsnrBKc9beTYvYR3JbQtSRhmAcER8C2ER7vD9grgjbDbP3HsVKhigiStITha/qVs62vuQ96R9bUw704AHg6n9QrwN1Gad2H7hvDDvA4Yl6f6RgKvhvW9AfwwbO8DPEdwGuhzwBcjVl9Ulo2U9UVh2Whl/kVl+WiuvrwuH7oUhIhITOmXwCIiMaUAEBGJKQWAiEhMKQBERGJKASAiElMKABGRmFIAiIjE1P8HTivWdbougA8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss vs param\n",
    "model_TrainLoss = [np.min(M1train_losses),np.min(M2train_losses),\n",
    "              np.min(M3train_losses),np.min(M4train_losses),\n",
    "              np.min(M5train_losses),np.min(M6train_losses),\n",
    "              np.min(M7train_losses),np.min(M8train_losses),\n",
    "              np.min(M9train_losses),np.min(M10train_losses)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_Testloss = [M1testLoss,M2testLoss,M3testLoss,M4testLoss,M5testLoss,\n",
    "                  M6testLoss,M7testLoss,M8testLoss,M9testLoss,M10testLoss     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainLoss,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_Testloss,color=\"orange\")\n",
    "plt.legend(['train_loss','test_loss'])\n",
    "plt.title('Loss VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0029),\n",
       " tensor(0.0008),\n",
       " tensor(0.0008),\n",
       " tensor(0.0008),\n",
       " tensor(0.0009),\n",
       " tensor(0.0008),\n",
       " tensor(0.0007),\n",
       " tensor(0.0008),\n",
       " tensor(0.0009),\n",
       " tensor(0.0008)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Acc vs param\n",
    "model_TrainAcc = [np.min(M1train_acc),np.min(M1train_acc),\n",
    "              np.min(M1train_acc),np.min(M1train_acc),\n",
    "              np.min(M1train_acc),np.min(M1train_acc),\n",
    "              np.min(M1train_acc),np.min(M1train_acc),\n",
    "              np.min(M1train_acc),np.min(M1train_acc)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_TestAcc = [M1netTest_acc1,M2netTest_acc1,M3netTest_acc1,M4netTest_acc1,M5netTest_acc1,\n",
    "                  M6netTest_acc1,M7netTest_acc1,M8netTest_acc1,M9netTest_acc1,M10netTest_acc1     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainAcc,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_TestAcc,color=\"orange\")\n",
    "plt.legend(['train_acc','test_acc'])\n",
    "plt.title('Accuracy VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
