{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5ad7f7870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=600, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M1(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M2, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 150)\n",
    "        self.fc3 = nn.Linear(150, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M3(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M3, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M4(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M4, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M5, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M6(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M6, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 90)\n",
    "        self.fc3 = nn.Linear(90, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M7(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M7, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M8(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M8, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 210)\n",
    "        self.fc3 = nn.Linear(210, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M9(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M9, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M10(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M10, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 300)\n",
    "        self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "max_epochs = 15\n",
    "learning_rate = 0.001\n",
    "kernel_size = 4\n",
    "num_epochs = 10\n",
    "dropout = 0.25\n",
    "#weight_decay_val = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 1: 25550\n"
     ]
    }
   ],
   "source": [
    "m1 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m1.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m1_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 1:', m1_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 2: 28600\n"
     ]
    }
   ],
   "source": [
    "m2 = M2()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m2_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 2:', m2_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 3: 24330\n"
     ]
    }
   ],
   "source": [
    "m3 = M3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m3_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 3:', m3_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 4: 26770\n"
     ]
    }
   ],
   "source": [
    "m4 = M4()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m4.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m4_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 4:', m4_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 5: 22500\n"
     ]
    }
   ],
   "source": [
    "m5 = M5()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m5.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m5_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 5:', m5_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 6: 24940\n"
     ]
    }
   ],
   "source": [
    "m6 = M6()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m6.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m6.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m6_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 6:', m6_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 7: 31650\n"
     ]
    }
   ],
   "source": [
    "m7 = M7()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m7.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m7.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m7_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 7:', m7_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 8: 32260\n"
     ]
    }
   ],
   "source": [
    "m8 = M8()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m8.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m8.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m8_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 8:', m8_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 9: 34700\n"
     ]
    }
   ],
   "source": [
    "m9 = M9()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m9.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m9.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m9_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 9:', m9_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters in Model 10: 37750\n"
     ]
    }
   ],
   "source": [
    "m10 = M10()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m10.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m10.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m10_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 10:', m10_TotalPrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs):\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    not_converged =True\n",
    "    epoch = 0\n",
    "    while not_converged:\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print (f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                train_epoch.append(epoch)\n",
    "                train_losses.append(loss.item())\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Accuracy : {acc} %')\n",
    "                train_acc.append(acc)\n",
    "\n",
    "                if epoch == num_epochs:\n",
    "                        print(\"Max Epoch Reached\")\n",
    "                        not_converged = False\n",
    "                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n",
    "                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n",
    "                        print(\"Convergeance reached for loss:\",loss_arr[-1])\n",
    "                        not_converged = False\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "def testFunc(model): \n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        for images, labels in test_loader:\n",
    "            prediction = model(images)\n",
    "            tLoss = loss_func(prediction, labels)\n",
    "            testLoss += tLoss\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        testLoss /= len(test_loader.dataset)\n",
    "        netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network:{model} on the test images: {netTest_acc1} % & loss of the network:{testLoss:.4f}')\n",
    "        return netTest_acc1,testLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/100], Loss: 0.4273\n",
      "Epoch [1/10], Accuracy : 62.946666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1901\n",
      "Epoch [2/10], Accuracy : 90.885 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1356\n",
      "Epoch [3/10], Accuracy : 94.385 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1161\n",
      "Epoch [4/10], Accuracy : 95.885 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0940\n",
      "Epoch [5/10], Accuracy : 96.52 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0702\n",
      "Epoch [6/10], Accuracy : 97.02666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1066\n",
      "Epoch [7/10], Accuracy : 97.32666666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0661\n",
      "Epoch [8/10], Accuracy : 97.625 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0765\n",
      "Epoch [9/10], Accuracy : 97.73666666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0621\n",
      "Epoch [10/10], Accuracy : 97.99 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "M1train_epoch,M1train_losses,M1train_acc = trainFunc(m1,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model2 Test\n",
      "Total no of parameters in Model 2: 28600\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3794\n",
      "Epoch [1/10], Accuracy : 64.415 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2229\n",
      "Epoch [2/10], Accuracy : 91.1 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1928\n",
      "Epoch [3/10], Accuracy : 94.04166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1614\n",
      "Epoch [4/10], Accuracy : 95.3 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1044\n",
      "Epoch [5/10], Accuracy : 96.035 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1387\n",
      "Epoch [6/10], Accuracy : 96.48166666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1265\n",
      "Epoch [7/10], Accuracy : 96.745 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1372\n",
      "Epoch [8/10], Accuracy : 97.14833333333333 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0803\n",
      "Epoch [9/10], Accuracy : 97.255 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.1074\n",
      "Epoch [10/10], Accuracy : 97.42333333333333 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model3 Test\n",
      "Total no of parameters in Model 3: 24330\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4004\n",
      "Epoch [1/10], Accuracy : 61.156666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2400\n",
      "Epoch [2/10], Accuracy : 91.18166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1466\n",
      "Epoch [3/10], Accuracy : 94.21833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1370\n",
      "Epoch [4/10], Accuracy : 95.52166666666666 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1335\n",
      "Epoch [5/10], Accuracy : 96.015 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0948\n",
      "Epoch [6/10], Accuracy : 96.66666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0982\n",
      "Epoch [7/10], Accuracy : 96.82166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0754\n",
      "Epoch [8/10], Accuracy : 97.16666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0570\n",
      "Epoch [9/10], Accuracy : 97.32833333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.1072\n",
      "Epoch [10/10], Accuracy : 97.54333333333334 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model4 Test\n",
      "Total no of parameters in Model 4: 26770\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4402\n",
      "Epoch [1/10], Accuracy : 61.361666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2234\n",
      "Epoch [2/10], Accuracy : 89.70166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1558\n",
      "Epoch [3/10], Accuracy : 93.69166666666666 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1353\n",
      "Epoch [4/10], Accuracy : 95.095 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1086\n",
      "Epoch [5/10], Accuracy : 95.84 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0809\n",
      "Epoch [6/10], Accuracy : 96.41 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0906\n",
      "Epoch [7/10], Accuracy : 96.70166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1060\n",
      "Epoch [8/10], Accuracy : 97.01666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.1113\n",
      "Epoch [9/10], Accuracy : 97.19 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0754\n",
      "Epoch [10/10], Accuracy : 97.36666666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model5 Test\n",
      "Total no of parameters in Model 5: 22500\n",
      "Epoch [1/10], Step [100/100], Loss: 0.5135\n",
      "Epoch [1/10], Accuracy : 59.001666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2682\n",
      "Epoch [2/10], Accuracy : 88.37666666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.2607\n",
      "Epoch [3/10], Accuracy : 92.56 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1528\n",
      "Epoch [4/10], Accuracy : 94.32666666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.2001\n",
      "Epoch [5/10], Accuracy : 95.06666666666666 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0963\n",
      "Epoch [6/10], Accuracy : 95.745 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1498\n",
      "Epoch [7/10], Accuracy : 96.145 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0939\n",
      "Epoch [8/10], Accuracy : 96.37833333333333 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0800\n",
      "Epoch [9/10], Accuracy : 96.705 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0844\n",
      "Epoch [10/10], Accuracy : 97.02833333333334 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model6 Test\n",
      "Total no of parameters in Model 6: 24940\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3842\n",
      "Epoch [1/10], Accuracy : 63.605 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2447\n",
      "Epoch [2/10], Accuracy : 90.80333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1930\n",
      "Epoch [3/10], Accuracy : 94.14333333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1765\n",
      "Epoch [4/10], Accuracy : 95.42833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0994\n",
      "Epoch [5/10], Accuracy : 96.15333333333334 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1130\n",
      "Epoch [6/10], Accuracy : 96.55333333333333 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0884\n",
      "Epoch [7/10], Accuracy : 96.87333333333333 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1011\n",
      "Epoch [8/10], Accuracy : 97.08 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0830\n",
      "Epoch [9/10], Accuracy : 97.30166666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0728\n",
      "Epoch [10/10], Accuracy : 97.41666666666667 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model7 Test\n",
      "Total no of parameters in Model 7: 31650\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3875\n",
      "Epoch [1/10], Accuracy : 65.11666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1978\n",
      "Epoch [2/10], Accuracy : 91.30333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1965\n",
      "Epoch [3/10], Accuracy : 94.37666666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1364\n",
      "Epoch [4/10], Accuracy : 95.56166666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0971\n",
      "Epoch [5/10], Accuracy : 96.23833333333333 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1066\n",
      "Epoch [6/10], Accuracy : 96.72166666666666 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0653\n",
      "Epoch [7/10], Accuracy : 97.06166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1024\n",
      "Epoch [8/10], Accuracy : 97.285 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0793\n",
      "Epoch [9/10], Accuracy : 97.335 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0674\n",
      "Epoch [10/10], Accuracy : 97.475 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model8 Test\n",
      "Total no of parameters in Model 8: 32260\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3935\n",
      "Epoch [1/10], Accuracy : 69.86666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2225\n",
      "Epoch [2/10], Accuracy : 91.64333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1885\n",
      "Epoch [3/10], Accuracy : 94.29833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1406\n",
      "Epoch [4/10], Accuracy : 95.26333333333334 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1296\n",
      "Epoch [5/10], Accuracy : 95.81166666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0982\n",
      "Epoch [6/10], Accuracy : 96.425 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1046\n",
      "Epoch [7/10], Accuracy : 96.65166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0840\n",
      "Epoch [8/10], Accuracy : 96.72666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.1152\n",
      "Epoch [9/10], Accuracy : 97.14166666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0715\n",
      "Epoch [10/10], Accuracy : 97.21 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model9 Test\n",
      "Total no of parameters in Model 9: 34700\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3939\n",
      "Epoch [1/10], Accuracy : 69.21833333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2505\n",
      "Epoch [2/10], Accuracy : 91.2 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1768\n",
      "Epoch [3/10], Accuracy : 94.135 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1439\n",
      "Epoch [4/10], Accuracy : 95.28 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1449\n",
      "Epoch [5/10], Accuracy : 95.935 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1247\n",
      "Epoch [6/10], Accuracy : 96.38666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1194\n",
      "Epoch [7/10], Accuracy : 96.64833333333333 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1269\n",
      "Epoch [8/10], Accuracy : 97.045 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0877\n",
      "Epoch [9/10], Accuracy : 97.24166666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0941\n",
      "Epoch [10/10], Accuracy : 97.36166666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model10 Test\n",
      "Total no of parameters in Model 10: 37750\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3956\n",
      "Epoch [1/10], Accuracy : 68.88 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1665\n",
      "Epoch [2/10], Accuracy : 91.27666666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1970\n",
      "Epoch [3/10], Accuracy : 94.09166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1589\n",
      "Epoch [4/10], Accuracy : 95.28833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1062\n",
      "Epoch [5/10], Accuracy : 95.84166666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1180\n",
      "Epoch [6/10], Accuracy : 96.27666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1045\n",
      "Epoch [7/10], Accuracy : 96.58 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0958\n",
      "Epoch [8/10], Accuracy : 96.95666666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0922\n",
      "Epoch [9/10], Accuracy : 97.19666666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0651\n",
      "Epoch [10/10], Accuracy : 97.27166666666666 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel2 Test\")\n",
    "m2 = M2()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m2_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 2:', m2_TotalPrams)\n",
    "\n",
    "M2train_epoch,M2train_losses,M2train_acc = trainFunc(m2,num_epochs)\n",
    "\n",
    "print(\"\\nModel3 Test\")\n",
    "m3 = M3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m3_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 3:', m3_TotalPrams)\n",
    "M3train_epoch,M3train_losses,M3train_acc = trainFunc(m3,num_epochs)\n",
    "print(\"\\nModel4 Test\")\n",
    "m4 = M4()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m4.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m4_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 4:', m4_TotalPrams)\n",
    "M4train_epoch,M4train_losses,M4train_acc = trainFunc(m4,num_epochs)\n",
    "print(\"\\nModel5 Test\")\n",
    "m5 = M5()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m5.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m5_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 5:', m5_TotalPrams)\n",
    "M5train_epoch,M5train_losses,M5train_acc = trainFunc(m5,num_epochs)\n",
    "\n",
    "print(\"\\nModel6 Test\")\n",
    "m6 = M6()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m6.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m6.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m6_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 6:', m6_TotalPrams)\n",
    "M6train_epoch,M6train_losses,M6train_acc = trainFunc(m6,num_epochs)\n",
    "\n",
    "print(\"\\nModel7 Test\")\n",
    "m7 = M7()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m7.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m7.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m7_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 7:', m7_TotalPrams)\n",
    "M7train_epoch,M7train_losses,M7train_acc = trainFunc(m7,num_epochs)\n",
    "\n",
    "print(\"\\nModel8 Test\")\n",
    "m8 = M8()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m8.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m8.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m8_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 8:', m8_TotalPrams)\n",
    "M8train_epoch,M8train_losses,M8train_acc = trainFunc(m8,num_epochs)\n",
    "\n",
    "print(\"\\nModel9 Test\")\n",
    "m9 = M9()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m9.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m9.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m9_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 9:', m9_TotalPrams)\n",
    "M9train_epoch,M9train_losses,M9train_acc = trainFunc(m9,num_epochs)\n",
    "\n",
    "print(\"\\nModel10 Test\")\n",
    "m10 = M10()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m10.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m10.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m10_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 10:', m10_TotalPrams)\n",
    "M10train_epoch,M10train_losses,M10train_acc = trainFunc(m10,num_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:M1(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ") on the test images: 91.47 % & loss of the network:0.0029\n",
      "Accuracy of the network:M2(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=150, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=10, bias=True)\n",
      ") on the test images: 97.57 % & loss of the network:0.0008\n",
      "Accuracy of the network:M3(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=80, bias=True)\n",
      "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
      ") on the test images: 97.69 % & loss of the network:0.0008\n",
      "Accuracy of the network:M4(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ") on the test images: 97.59 % & loss of the network:0.0008\n",
      "Accuracy of the network:M5(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
      ") on the test images: 97.38 % & loss of the network:0.0009\n",
      "Accuracy of the network:M6(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=90, bias=True)\n",
      "  (fc3): Linear(in_features=90, out_features=10, bias=True)\n",
      ") on the test images: 97.55 % & loss of the network:0.0008\n",
      "Accuracy of the network:M7(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ") on the test images: 97.86 % & loss of the network:0.0007\n",
      "Accuracy of the network:M8(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=210, bias=True)\n",
      "  (fc3): Linear(in_features=210, out_features=10, bias=True)\n",
      ") on the test images: 97.6 % & loss of the network:0.0008\n",
      "Accuracy of the network:M9(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=250, bias=True)\n",
      "  (fc3): Linear(in_features=250, out_features=10, bias=True)\n",
      ") on the test images: 96.95 % & loss of the network:0.0009\n",
      "Accuracy of the network:M10(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=10, bias=True)\n",
      ") on the test images: 97.62 % & loss of the network:0.0008\n"
     ]
    }
   ],
   "source": [
    "M1netTest_acc1,M1testLoss = testFunc(m1)\n",
    "M2netTest_acc1,M2testLoss = testFunc(m2)\n",
    "M3netTest_acc1,M3testLoss = testFunc(m3)\n",
    "M4netTest_acc1,M4testLoss = testFunc(m4)\n",
    "M5netTest_acc1,M5testLoss = testFunc(m5)\n",
    "M6netTest_acc1,M6testLoss = testFunc(m6)\n",
    "M7netTest_acc1,M7testLoss = testFunc(m7)\n",
    "M8netTest_acc1,M8testLoss = testFunc(m8)\n",
    "M9netTest_acc1,M9testLoss = testFunc(m9)\n",
    "M10netTest_acc1,M10testLoss = testFunc(m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss vs param\n",
    "model_TrainLoss = [np.min(M1train_losses),np.min(M2train_losses),\n",
    "              np.min(M3train_losses),np.min(M4train_losses),\n",
    "              np.min(M5train_losses),np.min(M6train_losses),\n",
    "              np.min(M7train_losses),np.min(M8train_losses),\n",
    "              np.min(M9train_losses),np.min(M10train_losses)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_Testloss = [M1testLoss,M2testLoss,M3testLoss,M4testLoss,M5testLoss,\n",
    "                  M6testLoss,M7testLoss,M8testLoss,M9testLoss,M10testLoss     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainLoss,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_Testloss,color=\"orange\")\n",
    "plt.legend(['train_loss','test_loss'])\n",
    "plt.title('Loss VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0029),\n",
       " tensor(0.0008),\n",
       " tensor(0.0008),\n",
       " tensor(0.0008),\n",
       " tensor(0.0009),\n",
       " tensor(0.0008),\n",
       " tensor(0.0007),\n",
       " tensor(0.0008),\n",
       " tensor(0.0009),\n",
       " tensor(0.0008)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Acc vs param\n",
    "model_TrainAcc = [np.max(M1train_acc),np.max(M1train_acc),\n",
    "              np.max(M1train_acc),np.max(M1train_acc),\n",
    "              np.max(M1train_acc),np.max(M1train_acc),\n",
    "              np.max(M1train_acc),np.max(M1train_acc),\n",
    "              np.max(M1train_acc),np.max(M1train_acc)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_TestAcc = [M1netTest_acc1,M2netTest_acc1,M3netTest_acc1,M4netTest_acc1,M5netTest_acc1,\n",
    "                  M6netTest_acc1,M7netTest_acc1,M8netTest_acc1,M9netTest_acc1,M10netTest_acc1     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainAcc,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_TestAcc,color=\"orange\")\n",
    "plt.legend(['train_acc','test_acc'])\n",
    "plt.title('Accuracy VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
