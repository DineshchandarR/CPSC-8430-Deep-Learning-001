{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21873b4d910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=600, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M1, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 10) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(10, 5)\n",
    "        self.fc3 = nn.Linear(5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M2, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 15) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(15, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M3(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M3, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 30) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(30, 15)\n",
    "        self.fc3 = nn.Linear(15, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M4(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M4, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M5, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 90)\n",
    "        self.fc3 = nn.Linear(90, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M6(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M6, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M7(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M7, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 210)\n",
    "        self.fc3 = nn.Linear(210, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M8(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M8, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 80) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(80, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M9(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M9, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M10(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M10, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 300)\n",
    "        self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "max_epochs = 15\n",
    "learning_rate = 0.001\n",
    "kernel_size = 4\n",
    "num_epochs = 10\n",
    "dropout = 0.25\n",
    "#weight_decay_val = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs):\n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    not_converged =True\n",
    "    epoch = 0\n",
    "    while not_converged:\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print (f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                train_epoch.append(epoch)\n",
    "                train_losses.append(loss.item())\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Accuracy : {acc} %')\n",
    "                train_acc.append(acc)\n",
    "\n",
    "                if epoch == num_epochs:\n",
    "                        print(\"Max Epoch Reached\")\n",
    "                        not_converged = False\n",
    "                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n",
    "                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n",
    "                        print(\"Convergeance reached for loss:\",train_losses[-1])\n",
    "                        not_converged = False\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "def testFunc(model): \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        count = 0\n",
    "        for images, labels in test_loader:\n",
    "            prediction = model(images)\n",
    "            tLoss = loss_func(prediction, labels)\n",
    "            testLoss += tLoss\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            count += 1\n",
    "\n",
    "        testLoss /= count\n",
    "        netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network:{model} on the test images: {netTest_acc1} % & loss of the network:{testLoss:.4f}')\n",
    "        return netTest_acc1,testLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model1 Test\n",
      "Total no of parameters in Model 1: 6715\n",
      "Epoch [1/10], Step [100/100], Loss: 1.5043\n",
      "Epoch [1/10], Accuracy : 28.218333333333334 %\n",
      "Epoch [2/10], Step [100/100], Loss: 1.1512\n",
      "Epoch [2/10], Accuracy : 53.763333333333335 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.9208\n",
      "Epoch [3/10], Accuracy : 63.00666666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.9110\n",
      "Epoch [4/10], Accuracy : 67.67166666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.7832\n",
      "Epoch [5/10], Accuracy : 71.81333333333333 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.7320\n",
      "Epoch [6/10], Accuracy : 74.85833333333333 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.6674\n",
      "Epoch [7/10], Accuracy : 76.39666666666666 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.6463\n",
      "Epoch [8/10], Accuracy : 77.36166666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.6278\n",
      "Epoch [9/10], Accuracy : 77.69333333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.6525\n",
      "Epoch [10/10], Accuracy : 78.17666666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model2 Test\n",
      "Total no of parameters in Model 2: 8735\n",
      "Epoch [1/10], Step [100/100], Loss: 0.8897\n",
      "Epoch [1/10], Accuracy : 43.401666666666664 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.6562\n",
      "Epoch [2/10], Accuracy : 73.45 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.5217\n",
      "Epoch [3/10], Accuracy : 79.20166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.5069\n",
      "Epoch [4/10], Accuracy : 82.26833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.4313\n",
      "Epoch [5/10], Accuracy : 84.17 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.4366\n",
      "Epoch [6/10], Accuracy : 86.00666666666666 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.3380\n",
      "Epoch [7/10], Accuracy : 87.17666666666666 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.3973\n",
      "Epoch [8/10], Accuracy : 87.84 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.3283\n",
      "Epoch [9/10], Accuracy : 88.67666666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.3465\n",
      "Epoch [10/10], Accuracy : 88.75333333333333 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model3 Test\n",
      "Total no of parameters in Model 3: 13645\n",
      "Epoch [1/10], Step [100/100], Loss: 0.6374\n",
      "Epoch [1/10], Accuracy : 51.998333333333335 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.3817\n",
      "Epoch [2/10], Accuracy : 84.95666666666666 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.3035\n",
      "Epoch [3/10], Accuracy : 89.68333333333334 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.2297\n",
      "Epoch [4/10], Accuracy : 91.95833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.2063\n",
      "Epoch [5/10], Accuracy : 93.13 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1842\n",
      "Epoch [6/10], Accuracy : 93.79666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1746\n",
      "Epoch [7/10], Accuracy : 94.37 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1832\n",
      "Epoch [8/10], Accuracy : 94.79 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.2287\n",
      "Epoch [9/10], Accuracy : 95.15 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.1325\n",
      "Epoch [10/10], Accuracy : 95.40333333333334 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model4 Test\n",
      "Total no of parameters in Model 4: 22500\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4876\n",
      "Epoch [1/10], Accuracy : 60.611666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2445\n",
      "Epoch [2/10], Accuracy : 89.54333333333334 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.2197\n",
      "Epoch [3/10], Accuracy : 93.10833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1473\n",
      "Epoch [4/10], Accuracy : 94.49333333333334 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1271\n",
      "Epoch [5/10], Accuracy : 95.385 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1141\n",
      "Epoch [6/10], Accuracy : 95.82666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1147\n",
      "Epoch [7/10], Accuracy : 96.28166666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0940\n",
      "Epoch [8/10], Accuracy : 96.77166666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.1100\n",
      "Epoch [9/10], Accuracy : 96.91333333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0562\n",
      "Epoch [10/10], Accuracy : 97.22 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model5 Test\n",
      "Total no of parameters in Model 5: 24940\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3902\n",
      "Epoch [1/10], Accuracy : 65.745 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2277\n",
      "Epoch [2/10], Accuracy : 90.12 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1533\n",
      "Epoch [3/10], Accuracy : 93.57666666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1399\n",
      "Epoch [4/10], Accuracy : 95.10166666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1132\n",
      "Epoch [5/10], Accuracy : 95.955 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1132\n",
      "Epoch [6/10], Accuracy : 96.57666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0806\n",
      "Epoch [7/10], Accuracy : 96.85 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0688\n",
      "Epoch [8/10], Accuracy : 97.05 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0985\n",
      "Epoch [9/10], Accuracy : 97.19666666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0651\n",
      "Epoch [10/10], Accuracy : 97.52833333333334 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model6 Test\n",
      "Total no of parameters in Model 6: 31650\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3502\n",
      "Epoch [1/10], Accuracy : 69.11166666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2794\n",
      "Epoch [2/10], Accuracy : 91.83833333333334 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1256\n",
      "Epoch [3/10], Accuracy : 94.58833333333334 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1537\n",
      "Epoch [4/10], Accuracy : 95.83166666666666 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1189\n",
      "Epoch [5/10], Accuracy : 96.41166666666666 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1389\n",
      "Epoch [6/10], Accuracy : 96.86 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0761\n",
      "Epoch [7/10], Accuracy : 97.21 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0841\n",
      "Epoch [8/10], Accuracy : 97.375 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0539\n",
      "Epoch [9/10], Accuracy : 97.53666666666666 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0620\n",
      "Epoch [10/10], Accuracy : 97.67666666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model7 Test\n",
      "Total no of parameters in Model 7: 32260\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4332\n",
      "Epoch [1/10], Accuracy : 67.48166666666667 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2656\n",
      "Epoch [2/10], Accuracy : 91.325 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1559\n",
      "Epoch [3/10], Accuracy : 94.45333333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1205\n",
      "Epoch [4/10], Accuracy : 95.62833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0901\n",
      "Epoch [5/10], Accuracy : 96.43166666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1181\n",
      "Epoch [6/10], Accuracy : 96.805 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0660\n",
      "Epoch [7/10], Accuracy : 97.135 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0831\n",
      "Epoch [8/10], Accuracy : 97.385 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0937\n",
      "Epoch [9/10], Accuracy : 97.54166666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0547\n",
      "Epoch [10/10], Accuracy : 97.69166666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model8 Test\n",
      "Total no of parameters in Model 8: 33630\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3483\n",
      "Epoch [1/10], Accuracy : 67.95 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2302\n",
      "Epoch [2/10], Accuracy : 91.85166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1485\n",
      "Epoch [3/10], Accuracy : 94.885 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1216\n",
      "Epoch [4/10], Accuracy : 95.825 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1119\n",
      "Epoch [5/10], Accuracy : 96.46 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1244\n",
      "Epoch [6/10], Accuracy : 96.97333333333333 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0816\n",
      "Epoch [7/10], Accuracy : 97.25833333333334 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0624\n",
      "Epoch [8/10], Accuracy : 97.54666666666667 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0615\n",
      "Epoch [9/10], Accuracy : 97.67333333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0943\n",
      "Epoch [10/10], Accuracy : 97.89 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model9 Test\n",
      "Total no of parameters in Model 9: 34700\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3544\n",
      "Epoch [1/10], Accuracy : 71.56666666666666 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1620\n",
      "Epoch [2/10], Accuracy : 92.10333333333334 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1360\n",
      "Epoch [3/10], Accuracy : 94.96333333333334 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.0926\n",
      "Epoch [4/10], Accuracy : 96.03833333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0778\n",
      "Epoch [5/10], Accuracy : 96.79 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1386\n",
      "Epoch [6/10], Accuracy : 97.06666666666666 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0411\n",
      "Epoch [7/10], Accuracy : 97.40833333333333 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0841\n",
      "Epoch [8/10], Accuracy : 97.6 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0559\n",
      "Epoch [9/10], Accuracy : 97.76166666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0441\n",
      "Epoch [10/10], Accuracy : 97.885 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model10 Test\n",
      "Total no of parameters in Model 10: 37750\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3124\n",
      "Epoch [1/10], Accuracy : 71.52833333333334 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2142\n",
      "Epoch [2/10], Accuracy : 91.88666666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1489\n",
      "Epoch [3/10], Accuracy : 94.445 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1360\n",
      "Epoch [4/10], Accuracy : 95.66 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1131\n",
      "Epoch [5/10], Accuracy : 96.195 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1057\n",
      "Epoch [6/10], Accuracy : 96.80166666666666 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1084\n",
      "Epoch [7/10], Accuracy : 97.13166666666666 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0676\n",
      "Epoch [8/10], Accuracy : 97.37 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0932\n",
      "Epoch [9/10], Accuracy : 97.53833333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0727\n",
      "Epoch [10/10], Accuracy : 97.62833333333333 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel1 Test\")\n",
    "torch.manual_seed(1)\n",
    "\n",
    "m1 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m1.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m1_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 1:', m1_TotalPrams)\n",
    "\n",
    "M1train_epoch,M1train_losses,M1train_acc = trainFunc(m1,num_epochs)\n",
    "\n",
    "print(\"\\nModel2 Test\")\n",
    "torch.manual_seed(1)\n",
    "m2 = M2()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m2_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 2:', m2_TotalPrams)\n",
    "\n",
    "M2train_epoch,M2train_losses,M2train_acc = trainFunc(m2,num_epochs)\n",
    "\n",
    "print(\"\\nModel3 Test\")\n",
    "torch.manual_seed(1)\n",
    "m3 = M3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m3_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 3:', m3_TotalPrams)\n",
    "M3train_epoch,M3train_losses,M3train_acc = trainFunc(m3,num_epochs)\n",
    "\n",
    "print(\"\\nModel4 Test\")\n",
    "torch.manual_seed(1)\n",
    "m4 = M4()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m4.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m4_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 4:', m4_TotalPrams)\n",
    "M4train_epoch,M4train_losses,M4train_acc = trainFunc(m4,num_epochs)\n",
    "\n",
    "print(\"\\nModel5 Test\")\n",
    "torch.manual_seed(1)\n",
    "m5 = M5()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m5.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m5_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 5:', m5_TotalPrams)\n",
    "M5train_epoch,M5train_losses,M5train_acc = trainFunc(m5,num_epochs)\n",
    "\n",
    "print(\"\\nModel6 Test\")\n",
    "torch.manual_seed(1)\n",
    "m6 = M6()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m6.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m6.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m6_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 6:', m6_TotalPrams)\n",
    "M6train_epoch,M6train_losses,M6train_acc = trainFunc(m6,num_epochs)\n",
    "\n",
    "print(\"\\nModel7 Test\")\n",
    "torch.manual_seed(1)\n",
    "m7 = M7()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m7.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m7.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m7_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 7:', m7_TotalPrams)\n",
    "M7train_epoch,M7train_losses,M7train_acc = trainFunc(m7,num_epochs)\n",
    "\n",
    "print(\"\\nModel8 Test\")\n",
    "torch.manual_seed(1)\n",
    "m8 = M8()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m8.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m8.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m8_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 8:', m8_TotalPrams)\n",
    "M8train_epoch,M8train_losses,M8train_acc = trainFunc(m8,num_epochs)\n",
    "\n",
    "print(\"\\nModel9 Test\")\n",
    "torch.manual_seed(1)\n",
    "m9 = M9()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m9.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m9.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m9_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 9:', m9_TotalPrams)\n",
    "M9train_epoch,M9train_losses,M9train_acc = trainFunc(m9,num_epochs)\n",
    "\n",
    "print(\"\\nModel10 Test\")\n",
    "torch.manual_seed(1)\n",
    "m10 = M10()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m10.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m10.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m10_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 10:', m10_TotalPrams)\n",
    "M10train_epoch,M10train_losses,M10train_acc = trainFunc(m10,num_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:M1(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc3): Linear(in_features=5, out_features=10, bias=True)\n",
      ") on the test images: 94.91 % & loss of the network:0.2342\n",
      "Accuracy of the network:M2(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=15, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=15, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
      ") on the test images: 96.62 % & loss of the network:0.1157\n",
      "Accuracy of the network:M3(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=30, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=30, out_features=15, bias=True)\n",
      "  (fc3): Linear(in_features=15, out_features=10, bias=True)\n",
      ") on the test images: 97.53 % & loss of the network:0.0744\n",
      "Accuracy of the network:M4(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
      ") on the test images: 98.03 % & loss of the network:0.0596\n",
      "Accuracy of the network:M5(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=90, bias=True)\n",
      "  (fc3): Linear(in_features=90, out_features=10, bias=True)\n",
      ") on the test images: 98.4 % & loss of the network:0.0510\n",
      "Accuracy of the network:M6(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ") on the test images: 98.44 % & loss of the network:0.0462\n",
      "Accuracy of the network:M7(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=210, bias=True)\n",
      "  (fc3): Linear(in_features=210, out_features=10, bias=True)\n",
      ") on the test images: 98.54 % & loss of the network:0.0444\n",
      "Accuracy of the network:M8(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=80, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
      ") on the test images: 98.57 % & loss of the network:0.0445\n",
      "Accuracy of the network:M9(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=250, bias=True)\n",
      "  (fc3): Linear(in_features=250, out_features=10, bias=True)\n",
      ") on the test images: 98.64 % & loss of the network:0.0414\n",
      "Accuracy of the network:M10(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=10, bias=True)\n",
      ") on the test images: 98.52 % & loss of the network:0.0483\n"
     ]
    }
   ],
   "source": [
    "M1netTest_acc1,M1testLoss = testFunc(m1)\n",
    "M2netTest_acc1,M2testLoss = testFunc(m2)\n",
    "M3netTest_acc1,M3testLoss = testFunc(m3)\n",
    "M4netTest_acc1,M4testLoss = testFunc(m4)\n",
    "M5netTest_acc1,M5testLoss = testFunc(m5)\n",
    "M6netTest_acc1,M6testLoss = testFunc(m6)\n",
    "M7netTest_acc1,M7testLoss = testFunc(m7)\n",
    "M8netTest_acc1,M8testLoss = testFunc(m8)\n",
    "M9netTest_acc1,M9testLoss = testFunc(m9)\n",
    "M10netTest_acc1,M10testLoss = testFunc(m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss vs param\n",
    "model_TrainLoss = [np.min(M1train_losses),np.min(M2train_losses),\n",
    "              np.min(M3train_losses),np.min(M4train_losses),\n",
    "              np.min(M5train_losses),np.min(M6train_losses),\n",
    "              np.min(M7train_losses),np.min(M8train_losses),\n",
    "              np.min(M9train_losses),np.min(M10train_losses)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_Testloss = [M1testLoss,M2testLoss,M3testLoss,M4testLoss,M5testLoss,\n",
    "                  M6testLoss,M7testLoss,M8testLoss,M9testLoss,M10testLoss     \n",
    "                ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "       0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "       0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.0,0.6,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TrainLoss Vs Param plot\n",
    "f = plt.figure()\n",
    "f.set_figwidth(10)\n",
    "f.set_figheight(5)\n",
    "plt.scatter(model_Tparams,model_TrainLoss,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_Testloss,color=\"orange\")\n",
    "#plt.yticks(np.array(np.linspace(0.0,0.6,10)),model_Tparams)\n",
    "plt.legend(['train_loss','test_loss'])\n",
    "plt.title('Train Loss VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TestLoss Vs Param plot\n",
    "# f = plt.figure()\n",
    "# f.set_figwidth(10)\n",
    "# f.set_figheight(5)\n",
    "# #plt.scatter(model_Tparams,model_TrainLoss,color=\"blue\")\n",
    "# plt.scatter(model_Tparams,model_Testloss,color=\"orange\")\n",
    "# #plt.yticks(np.array(np.linspace(0.0,0.6,10)),model_Tparams)\n",
    "# plt.legend(['test_loss'])\n",
    "# plt.title('Test Loss VS Parameters')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.2342),\n",
       " tensor(0.1157),\n",
       " tensor(0.0744),\n",
       " tensor(0.0596),\n",
       " tensor(0.0510),\n",
       " tensor(0.0462),\n",
       " tensor(0.0444),\n",
       " tensor(0.0445),\n",
       " tensor(0.0414),\n",
       " tensor(0.0483)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Acc vs param\n",
    "model_TrainAcc = [np.max(M1train_acc),np.max(M2train_acc),\n",
    "              np.max(M3train_acc),np.max(M4train_acc),\n",
    "              np.max(M5train_acc),np.max(M6train_acc),\n",
    "              np.max(M7train_acc),np.max(M8train_acc),\n",
    "              np.max(M9train_acc),np.max(M10train_acc)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_TestAcc = [M1netTest_acc1,M2netTest_acc1,M3netTest_acc1,M4netTest_acc1,M5netTest_acc1,\n",
    "                  M6netTest_acc1,M7netTest_acc1,M8netTest_acc1,M9netTest_acc1,M10netTest_acc1     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainAcc,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_TestAcc,color=\"orange\")\n",
    "plt.legend(['train_acc','test_acc'])\n",
    "plt.title('Accuracy VS Parameters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[94.91, 96.62, 97.53, 98.03, 98.4, 98.44, 98.54, 98.57, 98.64, 98.52]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_TestAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
