{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5ad7f7870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=600, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M1(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 15) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(15, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M2, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 30) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(30, 15)\n",
    "        self.fc3 = nn.Linear(15, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M3(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M3, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 10) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(10, 5)\n",
    "        self.fc3 = nn.Linear(5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M4(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M4, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M5, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 80) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(80, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M6(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M6, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 90)\n",
    "        self.fc3 = nn.Linear(90, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M7(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M7, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M8(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M8, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 210)\n",
    "        self.fc3 = nn.Linear(210, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M9(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M9, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M10(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(M10, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size) #1st Convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   #pool_size=2, strides=2 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size) #2nd Convolution\n",
    "        self.fc1 = nn.Linear(320, 50) #((I/P - Filter + 2*Pad)/Stride)+1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(50, 300)\n",
    "        self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 320)            #Flattening \n",
    "        x = F.relu(self.fc1(x))        #Fully Connected NN   \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc2(x))        #Fully Connected NN           \n",
    "        x = self.fc3(x)                #O/P Layer       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "max_epochs = 15\n",
    "learning_rate = 0.001\n",
    "kernel_size = 4\n",
    "num_epochs = 10\n",
    "dropout = 0.25\n",
    "#weight_decay_val = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs):\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    not_converged =True\n",
    "    epoch = 0\n",
    "    while not_converged:\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print (f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                train_epoch.append(epoch)\n",
    "                train_losses.append(loss.item())\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Accuracy : {acc} %')\n",
    "                train_acc.append(acc)\n",
    "\n",
    "                if epoch == num_epochs:\n",
    "                        print(\"Max Epoch Reached\")\n",
    "                        not_converged = False\n",
    "                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n",
    "                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n",
    "                        print(\"Convergeance reached for loss:\",loss_arr[-1])\n",
    "                        not_converged = False\n",
    "                        \n",
    "    return train_epoch,train_losses,train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "def testFunc(model): \n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        for images, labels in test_loader:\n",
    "            prediction = model(images)\n",
    "            tLoss = loss_func(prediction, labels)\n",
    "            testLoss += tLoss\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        testLoss /= len(test_loader.dataset)\n",
    "        netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network:{model} on the test images: {netTest_acc1} % & loss of the network:{testLoss:.4f}')\n",
    "        return netTest_acc1,testLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model1 Test\n",
      "Total no of parameters in Model 1: 8735\n",
      "Epoch [1/10], Step [100/100], Loss: 1.0094\n",
      "Epoch [1/10], Accuracy : 43.236666666666665 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.6393\n",
      "Epoch [2/10], Accuracy : 71.99166666666666 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.5007\n",
      "Epoch [3/10], Accuracy : 79.465 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.4720\n",
      "Epoch [4/10], Accuracy : 82.62166666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.3860\n",
      "Epoch [5/10], Accuracy : 85.38 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.4243\n",
      "Epoch [6/10], Accuracy : 86.91833333333334 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.3136\n",
      "Epoch [7/10], Accuracy : 87.58833333333334 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.3258\n",
      "Epoch [8/10], Accuracy : 88.47166666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.2900\n",
      "Epoch [9/10], Accuracy : 88.82833333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.3230\n",
      "Epoch [10/10], Accuracy : 89.65166666666667 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel1 Test\")\n",
    "m1 = M1()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m1.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m1_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 1:', m1_TotalPrams)\n",
    "M1train_epoch,M1train_losses,M1train_acc = trainFunc(m1,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model2 Test\n",
      "Total no of parameters in Model 2: 13645\n",
      "Epoch [1/10], Step [100/100], Loss: 0.6708\n",
      "Epoch [1/10], Accuracy : 48.88333333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.4446\n",
      "Epoch [2/10], Accuracy : 83.78166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.3131\n",
      "Epoch [3/10], Accuracy : 89.18166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.2834\n",
      "Epoch [4/10], Accuracy : 91.36666666666666 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.2141\n",
      "Epoch [5/10], Accuracy : 92.61666666666666 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.2270\n",
      "Epoch [6/10], Accuracy : 93.22833333333334 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1886\n",
      "Epoch [7/10], Accuracy : 93.83666666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1544\n",
      "Epoch [8/10], Accuracy : 94.22166666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.2037\n",
      "Epoch [9/10], Accuracy : 94.55333333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.1602\n",
      "Epoch [10/10], Accuracy : 94.885 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model3 Test\n",
      "Total no of parameters in Model 3: 6715\n",
      "Epoch [1/10], Step [100/100], Loss: 1.6004\n",
      "Epoch [1/10], Accuracy : 25.18166666666667 %\n",
      "Epoch [2/10], Step [100/100], Loss: 1.2566\n",
      "Epoch [2/10], Accuracy : 52.08166666666666 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.9198\n",
      "Epoch [3/10], Accuracy : 64.90333333333334 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.7881\n",
      "Epoch [4/10], Accuracy : 69.295 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.8001\n",
      "Epoch [5/10], Accuracy : 70.655 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.7531\n",
      "Epoch [6/10], Accuracy : 72.86666666666666 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.6590\n",
      "Epoch [7/10], Accuracy : 74.295 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.6853\n",
      "Epoch [8/10], Accuracy : 75.615 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.5964\n",
      "Epoch [9/10], Accuracy : 76.395 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.5930\n",
      "Epoch [10/10], Accuracy : 77.315 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model4 Test\n",
      "Total no of parameters in Model 4: 22500\n",
      "Epoch [1/10], Step [100/100], Loss: 0.5314\n",
      "Epoch [1/10], Accuracy : 59.54833333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2196\n",
      "Epoch [2/10], Accuracy : 90.69 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1528\n",
      "Epoch [3/10], Accuracy : 94.12833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1701\n",
      "Epoch [4/10], Accuracy : 95.22833333333334 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1563\n",
      "Epoch [5/10], Accuracy : 95.91333333333333 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1255\n",
      "Epoch [6/10], Accuracy : 96.47666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1285\n",
      "Epoch [7/10], Accuracy : 96.72166666666666 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1132\n",
      "Epoch [8/10], Accuracy : 96.92 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0892\n",
      "Epoch [9/10], Accuracy : 97.30333333333333 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0837\n",
      "Epoch [10/10], Accuracy : 97.43166666666667 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model5 Test\n",
      "Total no of parameters in Model 5: 33630\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4123\n",
      "Epoch [1/10], Accuracy : 60.39666666666667 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2205\n",
      "Epoch [2/10], Accuracy : 91.20833333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1563\n",
      "Epoch [3/10], Accuracy : 94.80166666666666 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1214\n",
      "Epoch [4/10], Accuracy : 95.91666666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1136\n",
      "Epoch [5/10], Accuracy : 96.665 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0728\n",
      "Epoch [6/10], Accuracy : 96.94 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0632\n",
      "Epoch [7/10], Accuracy : 97.315 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0930\n",
      "Epoch [8/10], Accuracy : 97.545 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0877\n",
      "Epoch [9/10], Accuracy : 97.785 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0443\n",
      "Epoch [10/10], Accuracy : 97.85 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model6 Test\n",
      "Total no of parameters in Model 6: 24940\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3637\n",
      "Epoch [1/10], Accuracy : 64.595 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2332\n",
      "Epoch [2/10], Accuracy : 90.425 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1881\n",
      "Epoch [3/10], Accuracy : 93.785 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1315\n",
      "Epoch [4/10], Accuracy : 95.26166666666667 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1212\n",
      "Epoch [5/10], Accuracy : 96.00666666666666 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1404\n",
      "Epoch [6/10], Accuracy : 96.57833333333333 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1161\n",
      "Epoch [7/10], Accuracy : 96.91166666666666 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0714\n",
      "Epoch [8/10], Accuracy : 97.27333333333333 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0820\n",
      "Epoch [9/10], Accuracy : 97.51166666666667 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0774\n",
      "Epoch [10/10], Accuracy : 97.64666666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model7 Test\n",
      "Total no of parameters in Model 7: 31650\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3304\n",
      "Epoch [1/10], Accuracy : 68.25833333333334 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1649\n",
      "Epoch [2/10], Accuracy : 92.06333333333333 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1461\n",
      "Epoch [3/10], Accuracy : 94.96833333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1387\n",
      "Epoch [4/10], Accuracy : 96.02333333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0828\n",
      "Epoch [5/10], Accuracy : 96.62166666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0793\n",
      "Epoch [6/10], Accuracy : 96.975 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0981\n",
      "Epoch [7/10], Accuracy : 97.24666666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0710\n",
      "Epoch [8/10], Accuracy : 97.49166666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0509\n",
      "Epoch [9/10], Accuracy : 97.71 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0456\n",
      "Epoch [10/10], Accuracy : 97.77166666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model8 Test\n",
      "Total no of parameters in Model 8: 32260\n",
      "Epoch [1/10], Step [100/100], Loss: 0.4453\n",
      "Epoch [1/10], Accuracy : 67.34833333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.2444\n",
      "Epoch [2/10], Accuracy : 91.37666666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1240\n",
      "Epoch [3/10], Accuracy : 94.39 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1097\n",
      "Epoch [4/10], Accuracy : 95.63833333333334 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0871\n",
      "Epoch [5/10], Accuracy : 96.27166666666666 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1132\n",
      "Epoch [6/10], Accuracy : 96.65333333333334 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.1238\n",
      "Epoch [7/10], Accuracy : 97.00833333333334 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0914\n",
      "Epoch [8/10], Accuracy : 97.34666666666666 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0769\n",
      "Epoch [9/10], Accuracy : 97.545 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0599\n",
      "Epoch [10/10], Accuracy : 97.66333333333333 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model9 Test\n",
      "Total no of parameters in Model 9: 34700\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3370\n",
      "Epoch [1/10], Accuracy : 65.78833333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1998\n",
      "Epoch [2/10], Accuracy : 91.635 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1480\n",
      "Epoch [3/10], Accuracy : 94.70166666666667 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1482\n",
      "Epoch [4/10], Accuracy : 95.69333333333333 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.1115\n",
      "Epoch [5/10], Accuracy : 96.30666666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.1006\n",
      "Epoch [6/10], Accuracy : 96.82333333333334 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0950\n",
      "Epoch [7/10], Accuracy : 96.96 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.1142\n",
      "Epoch [8/10], Accuracy : 97.09333333333333 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0894\n",
      "Epoch [9/10], Accuracy : 97.355 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0744\n",
      "Epoch [10/10], Accuracy : 97.56666666666666 %\n",
      "Max Epoch Reached\n",
      "\n",
      "Model10 Test\n",
      "Total no of parameters in Model 10: 37750\n",
      "Epoch [1/10], Step [100/100], Loss: 0.3574\n",
      "Epoch [1/10], Accuracy : 67.42333333333333 %\n",
      "Epoch [2/10], Step [100/100], Loss: 0.1581\n",
      "Epoch [2/10], Accuracy : 92.26166666666667 %\n",
      "Epoch [3/10], Step [100/100], Loss: 0.1418\n",
      "Epoch [3/10], Accuracy : 94.91333333333333 %\n",
      "Epoch [4/10], Step [100/100], Loss: 0.1378\n",
      "Epoch [4/10], Accuracy : 96.07333333333334 %\n",
      "Epoch [5/10], Step [100/100], Loss: 0.0860\n",
      "Epoch [5/10], Accuracy : 96.72666666666667 %\n",
      "Epoch [6/10], Step [100/100], Loss: 0.0754\n",
      "Epoch [6/10], Accuracy : 97.13666666666667 %\n",
      "Epoch [7/10], Step [100/100], Loss: 0.0866\n",
      "Epoch [7/10], Accuracy : 97.37666666666667 %\n",
      "Epoch [8/10], Step [100/100], Loss: 0.0906\n",
      "Epoch [8/10], Accuracy : 97.625 %\n",
      "Epoch [9/10], Step [100/100], Loss: 0.0690\n",
      "Epoch [9/10], Accuracy : 97.725 %\n",
      "Epoch [10/10], Step [100/100], Loss: 0.0887\n",
      "Epoch [10/10], Accuracy : 97.88833333333334 %\n",
      "Max Epoch Reached\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel2 Test\")\n",
    "m2 = M2()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m2.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m2_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 2:', m2_TotalPrams)\n",
    "\n",
    "M2train_epoch,M2train_losses,M2train_acc = trainFunc(m2,num_epochs)\n",
    "\n",
    "print(\"\\nModel3 Test\")\n",
    "m3 = M3()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m3.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m3_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 3:', m3_TotalPrams)\n",
    "M3train_epoch,M3train_losses,M3train_acc = trainFunc(m3,num_epochs)\n",
    "\n",
    "print(\"\\nModel4 Test\")\n",
    "m4 = M4()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m4.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m4_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 4:', m4_TotalPrams)\n",
    "M4train_epoch,M4train_losses,M4train_acc = trainFunc(m4,num_epochs)\n",
    "print(\"\\nModel5 Test\")\n",
    "m5 = M5()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m5.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m5_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 5:', m5_TotalPrams)\n",
    "M5train_epoch,M5train_losses,M5train_acc = trainFunc(m5,num_epochs)\n",
    "\n",
    "print(\"\\nModel6 Test\")\n",
    "m6 = M6()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m6.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m6.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m6_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 6:', m6_TotalPrams)\n",
    "M6train_epoch,M6train_losses,M6train_acc = trainFunc(m6,num_epochs)\n",
    "\n",
    "print(\"\\nModel7 Test\")\n",
    "m7 = M7()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m7.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m7.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m7_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 7:', m7_TotalPrams)\n",
    "M7train_epoch,M7train_losses,M7train_acc = trainFunc(m7,num_epochs)\n",
    "\n",
    "print(\"\\nModel8 Test\")\n",
    "m8 = M8()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m8.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m8.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m8_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 8:', m8_TotalPrams)\n",
    "M8train_epoch,M8train_losses,M8train_acc = trainFunc(m8,num_epochs)\n",
    "\n",
    "print(\"\\nModel9 Test\")\n",
    "m9 = M9()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m9.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m9.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m9_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 9:', m9_TotalPrams)\n",
    "M9train_epoch,M9train_losses,M9train_acc = trainFunc(m9,num_epochs)\n",
    "\n",
    "print(\"\\nModel10 Test\")\n",
    "m10 = M10()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m10.parameters(), lr=learning_rate) #, weight_decay = weight_decay_val)\n",
    "\n",
    "a=[]\n",
    "for i in m10.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "m10_TotalPrams = np.sum(a)\n",
    "print('Total no of parameters in Model 10:', m10_TotalPrams)\n",
    "M10train_epoch,M10train_losses,M10train_acc = trainFunc(m10,num_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:M1(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=15, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=15, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
      ") on the test images: 90.13 % & loss of the network:0.0029\n",
      "Accuracy of the network:M2(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=30, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=30, out_features=15, bias=True)\n",
      "  (fc3): Linear(in_features=15, out_features=10, bias=True)\n",
      ") on the test images: 95.36 % & loss of the network:0.0016\n",
      "Accuracy of the network:M3(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc3): Linear(in_features=5, out_features=10, bias=True)\n",
      ") on the test images: 78.24 % & loss of the network:0.0061\n",
      "Accuracy of the network:M4(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
      ") on the test images: 97.39 % & loss of the network:0.0008\n",
      "Accuracy of the network:M5(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=80, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
      ") on the test images: 98.0 % & loss of the network:0.0007\n",
      "Accuracy of the network:M6(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=90, bias=True)\n",
      "  (fc3): Linear(in_features=90, out_features=10, bias=True)\n",
      ") on the test images: 97.74 % & loss of the network:0.0008\n",
      "Accuracy of the network:M7(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ") on the test images: 98.03 % & loss of the network:0.0006\n",
      "Accuracy of the network:M8(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=210, bias=True)\n",
      "  (fc3): Linear(in_features=210, out_features=10, bias=True)\n",
      ") on the test images: 97.75 % & loss of the network:0.0007\n",
      "Accuracy of the network:M9(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=250, bias=True)\n",
      "  (fc3): Linear(in_features=250, out_features=10, bias=True)\n",
      ") on the test images: 97.78 % & loss of the network:0.0007\n",
      "Accuracy of the network:M10(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=10, bias=True)\n",
      ") on the test images: 97.77 % & loss of the network:0.0007\n"
     ]
    }
   ],
   "source": [
    "M1netTest_acc1,M1testLoss = testFunc(m1)\n",
    "M2netTest_acc1,M2testLoss = testFunc(m2)\n",
    "M3netTest_acc1,M3testLoss = testFunc(m3)\n",
    "M4netTest_acc1,M4testLoss = testFunc(m4)\n",
    "M5netTest_acc1,M5testLoss = testFunc(m5)\n",
    "M6netTest_acc1,M6testLoss = testFunc(m6)\n",
    "M7netTest_acc1,M7testLoss = testFunc(m7)\n",
    "M8netTest_acc1,M8testLoss = testFunc(m8)\n",
    "M9netTest_acc1,M9testLoss = testFunc(m9)\n",
    "M10netTest_acc1,M10testLoss = testFunc(m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss vs param\n",
    "model_TrainLoss = [np.min(M1train_losses),np.min(M2train_losses),\n",
    "              np.min(M3train_losses),np.min(M4train_losses),\n",
    "              np.min(M5train_losses),np.min(M6train_losses),\n",
    "              np.min(M7train_losses),np.min(M8train_losses),\n",
    "              np.min(M9train_losses),np.min(M10train_losses)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_Testloss = [M1testLoss,M2testLoss,M3testLoss,M4testLoss,M5testLoss,\n",
    "                  M6testLoss,M7testLoss,M8testLoss,M9testLoss,M10testLoss     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainLoss,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_Testloss,color=\"orange\")\n",
    "plt.legend(['train_loss','test_loss'])\n",
    "plt.title('Loss VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0029),\n",
       " tensor(0.0016),\n",
       " tensor(0.0061),\n",
       " tensor(0.0008),\n",
       " tensor(0.0007),\n",
       " tensor(0.0008),\n",
       " tensor(0.0006),\n",
       " tensor(0.0007),\n",
       " tensor(0.0007),\n",
       " tensor(0.0007)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Acc vs param\n",
    "model_TrainAcc = [np.max(M1train_acc),np.max(M2train_acc),\n",
    "              np.max(M3train_acc),np.max(M4train_acc),\n",
    "              np.max(M5train_acc),np.max(M6train_acc),\n",
    "              np.max(M7train_acc),np.max(M8train_acc),\n",
    "              np.max(M9train_acc),np.max(M10train_acc)      \n",
    "            ]\n",
    "model_Tparams = [m1_TotalPrams,m2_TotalPrams,m3_TotalPrams,\n",
    "                m4_TotalPrams,m5_TotalPrams,m6_TotalPrams,\n",
    "                m7_TotalPrams,m8_TotalPrams,m9_TotalPrams,\n",
    "                m10_TotalPrams\n",
    "                ]\n",
    "model_TestAcc = [M1netTest_acc1,M2netTest_acc1,M3netTest_acc1,M4netTest_acc1,M5netTest_acc1,\n",
    "                  M6netTest_acc1,M7netTest_acc1,M8netTest_acc1,M9netTest_acc1,M10netTest_acc1     \n",
    "                ]\n",
    "plt.scatter(model_Tparams,model_TrainAcc,color=\"blue\")\n",
    "plt.scatter(model_Tparams,model_TestAcc,color=\"orange\")\n",
    "plt.legend(['train_acc','test_acc'])\n",
    "plt.title('Accuracy VS Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
