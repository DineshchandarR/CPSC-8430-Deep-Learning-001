{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader func\n",
    "def train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def test_loader(batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten as one dimension\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "      \n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs,train_batch_size,status_interval):\n",
    "    model.train()\n",
    "    print('strated')\n",
    "    train_load = train_loader(train_batch_size)\n",
    "    n_total_steps = len(train_load)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    epoch = 0\n",
    "    modelParamWgt={}\n",
    "    trainAvgLossArr = []\n",
    "    trainAvgAccArr = []\n",
    "    firstParaWgt = {}\n",
    "    for epoch in range (num_epochs):\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        lossSum =0\n",
    "        totalacc=0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_load):  \n",
    "            #if (i+1)% 60 == 0 : print(i+1)\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "\n",
    "            images.requires_grad = True\n",
    "\n",
    "            loss = loss_func(prediction, labels)\n",
    "            lossSum += loss.detach().numpy()\n",
    "\n",
    "            # Backward and optimize\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "            totalacc += acc\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            train_epoch.append(epoch)\n",
    "            \n",
    "            # #Weight Collection\n",
    "            # if epoch % 3 == 0:\n",
    "            #     for name, parameter in model.named_parameters():\n",
    "            #         #print(name)\n",
    "            #         if'weight' in name:\n",
    "            #             modelParamWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "            #             print(modelParamWgt)\n",
    "\n",
    "            #Print Status\n",
    "            if (i+1) % status_interval == 0:\n",
    "                print (f'Train O/P: Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}',end= '\\r',flush = True)\n",
    "        \n",
    "        #Weight Collection\n",
    "        for name, parameter in model.named_parameters():\n",
    "            #print(name)\n",
    "            if'weight' in name:\n",
    "                modelParamWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "                #print(modelParamWgt)       \n",
    "\n",
    "        #1st Layer collection\n",
    "        for name, parameter in model.named_parameters():\n",
    "            if'fc1' in name and 'weight' in name:\n",
    "                firstParaWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "                #print(firstParaWgt)\n",
    "                        \n",
    "        epochLoss = lossSum/(i+1)\n",
    "        epochAcc = totalacc/(i+1)\n",
    "        #print(\"Train Avg loss:\",trainAvgLoss)\n",
    "        trainAvgLossArr.append(epochLoss)    \n",
    "        trainAvgAccArr.append(epochAcc)\n",
    "                       \n",
    "    return train_epoch,train_losses,train_acc,trainAvgLossArr,trainAvgAccArr, modelParamWgt,firstParaWgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFunction(model,loss_func,test_batch_size): \n",
    "    test_load = test_loader(test_batch_size)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        count = 0\n",
    "        for images, labels in test_load:\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            prediction = model(images)\n",
    "            testLoss += loss_func(prediction,labels).item()\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            count += 1\n",
    "    netTest_loss = testLoss/count\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {netTest_acc1}% & Test Loss: {netTest_loss}',end= '\\r',flush = True)\n",
    "    return netTest_acc1, netTest_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaOps(paramDF,itr):\n",
    "    pcaOperation =  PCA(n_components=2)\n",
    "\n",
    "    # scale = StandardScaler()\n",
    "\n",
    "    # sData = scale.fit_transform(paramDF)\n",
    "\n",
    "    pcaVal = pcaOperation.fit_transform(paramDF)\n",
    "\n",
    "    itrData = np.full((pcaVal.shape[0],1),itr)\n",
    "\n",
    "    #pcaDf = pd.DataFrame(data = pcaVal, columns = ['x','y'])\n",
    "\n",
    "    pcaDf = pd.DataFrame(np.append(pcaVal,itrData,axis=1),columns=['x','y','Itr No.'])\n",
    "\n",
    "    return pcaDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters:418060\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "tempModel = DNN()\n",
    "for i in tempModel.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print(f'Total no of parameters:{np.sum(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0\n",
      "strated\n",
      "Time: 1y of the network on the test images: 98.15% & Test Loss: 0.06571345457290591\n",
      "strated\n",
      "Time: 2y of the network on the test images: 98.39% & Test Loss: 0.05560417826252888\n",
      "strated\n",
      "Time: 3y of the network on the test images: 98.35% & Test Loss: 0.05886246938711338\n",
      "strated\n",
      "Time: 4y of the network on the test images: 97.93% & Test Loss: 0.07012845489807659\n",
      "strated\n",
      "Time: 5y of the network on the test images: 97.85% & Test Loss: 0.07307451506909274\n",
      "strated\n",
      "Time: 6y of the network on the test images: 98.26% & Test Loss: 0.05940908971188946\n",
      "strated\n",
      "Time: 7y of the network on the test images: 98.41% & Test Loss: 0.060176715889319894\n",
      "strated\n",
      "Accuracy of the network on the test images: 98.01% & Test Loss: 0.06994593331075522\r"
     ]
    }
   ],
   "source": [
    "#2nd Approach\n",
    "\n",
    "max_epochs = 45\n",
    "all_df = pd.DataFrame()\n",
    "columns=[\"x\",\"y\",\"Times\"]\n",
    "trainAllacc={}\n",
    "testAllacc={}\n",
    "trainAllloss={}\n",
    "testAllloss={}\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "status_interval = 50\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "firstLayer = pd.DataFrame()\n",
    "\n",
    "for count in range(8):\n",
    "    print(\"Time: \"+str(count))\n",
    "    M = DNN()\n",
    "    optimizer = torch.optim.Adam(M.parameters(),lr = 0.0004,weight_decay=1e-4)\n",
    "    model_name1 = \"Times: \"+str(count)    \n",
    "    train_epoch,train_losses,train_acc,trainAvgLoss,trainAvgAccArr, modelParamWgt,firstParamWgt = trainFunc(M,max_epochs,train_batch_size,status_interval)\n",
    "    testAcc, testLoss = testFunction(M,loss_func,test_batch_size)\n",
    "\n",
    "    temp_df = pd.DataFrame(modelParamWgt).transpose()\n",
    "    all_df = all_df.append(temp_df)\n",
    "    \n",
    "    firstdf = pd.DataFrame(firstParamWgt).transpose()\n",
    "    firstLayer = firstLayer.append(firstdf)\n",
    "\n",
    "    testAllacc[count] = testAcc\n",
    "    trainAllloss[count] = trainAvgLoss\n",
    "    testAllloss[count] = testLoss\n",
    "    trainAllacc[count] = trainAvgAccArr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAccArr = []\n",
    "for key,values in enumerate(trainAllacc):\n",
    "    trainAccArr.append(trainAllacc[key])\n",
    "trainLossArr = []\n",
    "for key,values in enumerate(trainAllloss):\n",
    "    trainLossArr.append(trainAllloss[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042618</td>\n",
       "      <td>-0.079695</td>\n",
       "      <td>-0.132603</td>\n",
       "      <td>0.141391</td>\n",
       "      <td>0.094155</td>\n",
       "      <td>0.054628</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>-0.030862</td>\n",
       "      <td>-0.158486</td>\n",
       "      <td>-0.119306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154751</td>\n",
       "      <td>0.158411</td>\n",
       "      <td>-0.036216</td>\n",
       "      <td>-0.097887</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.127541</td>\n",
       "      <td>-0.029437</td>\n",
       "      <td>-0.061857</td>\n",
       "      <td>-0.150454</td>\n",
       "      <td>0.154191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041319</td>\n",
       "      <td>-0.080421</td>\n",
       "      <td>-0.143216</td>\n",
       "      <td>0.144437</td>\n",
       "      <td>0.101398</td>\n",
       "      <td>0.058654</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>-0.033759</td>\n",
       "      <td>-0.170310</td>\n",
       "      <td>-0.117109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179258</td>\n",
       "      <td>0.172713</td>\n",
       "      <td>-0.041149</td>\n",
       "      <td>-0.103423</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>-0.023020</td>\n",
       "      <td>-0.064493</td>\n",
       "      <td>-0.183525</td>\n",
       "      <td>0.160374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041121</td>\n",
       "      <td>-0.080265</td>\n",
       "      <td>-0.149682</td>\n",
       "      <td>0.148158</td>\n",
       "      <td>0.109886</td>\n",
       "      <td>0.063953</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>-0.035206</td>\n",
       "      <td>-0.180905</td>\n",
       "      <td>-0.116528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200783</td>\n",
       "      <td>0.183362</td>\n",
       "      <td>-0.045359</td>\n",
       "      <td>-0.103007</td>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.140751</td>\n",
       "      <td>-0.022543</td>\n",
       "      <td>-0.068790</td>\n",
       "      <td>-0.203034</td>\n",
       "      <td>0.167511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042162</td>\n",
       "      <td>-0.080711</td>\n",
       "      <td>-0.155917</td>\n",
       "      <td>0.152442</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.070296</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>-0.036748</td>\n",
       "      <td>-0.191647</td>\n",
       "      <td>-0.117012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224434</td>\n",
       "      <td>0.192368</td>\n",
       "      <td>-0.046921</td>\n",
       "      <td>-0.103830</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>0.146098</td>\n",
       "      <td>-0.024131</td>\n",
       "      <td>-0.075173</td>\n",
       "      <td>-0.221941</td>\n",
       "      <td>0.172559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041383</td>\n",
       "      <td>-0.084851</td>\n",
       "      <td>-0.158548</td>\n",
       "      <td>0.158070</td>\n",
       "      <td>0.126218</td>\n",
       "      <td>0.076666</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>-0.040403</td>\n",
       "      <td>-0.199173</td>\n",
       "      <td>-0.119974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242280</td>\n",
       "      <td>0.202686</td>\n",
       "      <td>-0.048809</td>\n",
       "      <td>-0.103187</td>\n",
       "      <td>0.056859</td>\n",
       "      <td>0.153733</td>\n",
       "      <td>-0.025345</td>\n",
       "      <td>-0.077760</td>\n",
       "      <td>-0.234927</td>\n",
       "      <td>0.179485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.245006</td>\n",
       "      <td>-0.093931</td>\n",
       "      <td>-0.642359</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.209081</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>-0.054702</td>\n",
       "      <td>0.125115</td>\n",
       "      <td>-0.124855</td>\n",
       "      <td>-0.425702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581995</td>\n",
       "      <td>-0.367888</td>\n",
       "      <td>-0.032187</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.155051</td>\n",
       "      <td>0.237162</td>\n",
       "      <td>0.284512</td>\n",
       "      <td>0.223758</td>\n",
       "      <td>0.430833</td>\n",
       "      <td>-0.061535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.244407</td>\n",
       "      <td>-0.091947</td>\n",
       "      <td>-0.647931</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>-0.213222</td>\n",
       "      <td>0.225568</td>\n",
       "      <td>-0.059998</td>\n",
       "      <td>0.123835</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.438059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586832</td>\n",
       "      <td>-0.370308</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.155783</td>\n",
       "      <td>0.238150</td>\n",
       "      <td>0.283469</td>\n",
       "      <td>0.226987</td>\n",
       "      <td>0.434644</td>\n",
       "      <td>-0.059281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.247426</td>\n",
       "      <td>-0.090802</td>\n",
       "      <td>-0.649212</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>-0.213417</td>\n",
       "      <td>0.227919</td>\n",
       "      <td>-0.059403</td>\n",
       "      <td>0.126348</td>\n",
       "      <td>-0.124107</td>\n",
       "      <td>-0.436659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592056</td>\n",
       "      <td>-0.376634</td>\n",
       "      <td>-0.031054</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.157099</td>\n",
       "      <td>0.241640</td>\n",
       "      <td>0.286286</td>\n",
       "      <td>0.231499</td>\n",
       "      <td>0.437476</td>\n",
       "      <td>-0.058549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.249781</td>\n",
       "      <td>-0.091469</td>\n",
       "      <td>-0.656418</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>-0.216347</td>\n",
       "      <td>0.230840</td>\n",
       "      <td>-0.057102</td>\n",
       "      <td>0.127689</td>\n",
       "      <td>-0.128858</td>\n",
       "      <td>-0.437290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600138</td>\n",
       "      <td>-0.376636</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.156763</td>\n",
       "      <td>0.247334</td>\n",
       "      <td>0.290197</td>\n",
       "      <td>0.234991</td>\n",
       "      <td>0.443446</td>\n",
       "      <td>-0.059895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.253308</td>\n",
       "      <td>-0.089558</td>\n",
       "      <td>-0.661606</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>-0.218548</td>\n",
       "      <td>0.234552</td>\n",
       "      <td>-0.056316</td>\n",
       "      <td>0.131630</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>-0.441763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609997</td>\n",
       "      <td>-0.380594</td>\n",
       "      <td>-0.028273</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.158461</td>\n",
       "      <td>0.251779</td>\n",
       "      <td>0.293527</td>\n",
       "      <td>0.238530</td>\n",
       "      <td>0.447380</td>\n",
       "      <td>-0.060212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "1   0.042618 -0.079695 -0.132603  0.141391  0.094155  0.054628  0.019973   \n",
       "2   0.041319 -0.080421 -0.143216  0.144437  0.101398  0.058654  0.018079   \n",
       "3   0.041121 -0.080265 -0.149682  0.148158  0.109886  0.063953  0.016780   \n",
       "4   0.042162 -0.080711 -0.155917  0.152442  0.117728  0.070296  0.015665   \n",
       "5   0.041383 -0.084851 -0.158548  0.158070  0.126218  0.076666  0.013749   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "41  0.245006 -0.093931 -0.642359  0.007472 -0.209081  0.222224 -0.054702   \n",
       "42  0.244407 -0.091947 -0.647931  0.004750 -0.213222  0.225568 -0.059998   \n",
       "43  0.247426 -0.090802 -0.649212  0.005899 -0.213417  0.227919 -0.059403   \n",
       "44  0.249781 -0.091469 -0.656418  0.003991 -0.216347  0.230840 -0.057102   \n",
       "45  0.253308 -0.089558 -0.661606  0.004146 -0.218548  0.234552 -0.056316   \n",
       "\n",
       "         7         8         9    ...       490       491       492       493  \\\n",
       "1  -0.030862 -0.158486 -0.119306  ... -0.154751  0.158411 -0.036216 -0.097887   \n",
       "2  -0.033759 -0.170310 -0.117109  ... -0.179258  0.172713 -0.041149 -0.103423   \n",
       "3  -0.035206 -0.180905 -0.116528  ... -0.200783  0.183362 -0.045359 -0.103007   \n",
       "4  -0.036748 -0.191647 -0.117012  ... -0.224434  0.192368 -0.046921 -0.103830   \n",
       "5  -0.040403 -0.199173 -0.119974  ... -0.242280  0.202686 -0.048809 -0.103187   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "41  0.125115 -0.124855 -0.425702  ... -0.581995 -0.367888 -0.032187  0.000030   \n",
       "42  0.123835 -0.124822 -0.438059  ... -0.586832 -0.370308 -0.031056  0.000019   \n",
       "43  0.126348 -0.124107 -0.436659  ... -0.592056 -0.376634 -0.031054  0.000010   \n",
       "44  0.127689 -0.128858 -0.437290  ... -0.600138 -0.376636 -0.028595  0.000004   \n",
       "45  0.131630 -0.128677 -0.441763  ... -0.609997 -0.380594 -0.028273  0.000001   \n",
       "\n",
       "         494       495       496       497       498       499  \n",
       "1   0.058883  0.127541 -0.029437 -0.061857 -0.150454  0.154191  \n",
       "2   0.056786  0.133813 -0.023020 -0.064493 -0.183525  0.160374  \n",
       "3   0.057056  0.140751 -0.022543 -0.068790 -0.203034  0.167511  \n",
       "4   0.056168  0.146098 -0.024131 -0.075173 -0.221941  0.172559  \n",
       "5   0.056859  0.153733 -0.025345 -0.077760 -0.234927  0.179485  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "41 -0.155051  0.237162  0.284512  0.223758  0.430833 -0.061535  \n",
       "42 -0.155783  0.238150  0.283469  0.226987  0.434644 -0.059281  \n",
       "43 -0.157099  0.241640  0.286286  0.231499  0.437476 -0.058549  \n",
       "44 -0.156763  0.247334  0.290197  0.234991  0.443446 -0.059895  \n",
       "45 -0.158461  0.251779  0.293527  0.238530  0.447380 -0.060212  \n",
       "\n",
       "[360 rows x 500 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Loss:(360,) & Shape of Acc: (360,)\n"
     ]
    }
   ],
   "source": [
    "train_acc_df = pd.DataFrame(trainAccArr)\n",
    "train_acc_data = np.array(train_acc_df).flatten()\n",
    "\n",
    "train_loss_df = pd.DataFrame(trainLossArr)\n",
    "train_loss_data = np.array(train_loss_df).flatten()\n",
    "\n",
    "print(f'Shape of Loss:{np.shape(train_loss_data)} & Shape of Acc: {np.shape(train_acc_data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6    \\\n",
      "1   0.042618 -0.079695 -0.132603  0.141391  0.094155  0.054628  0.019973   \n",
      "2   0.041319 -0.080421 -0.143216  0.144437  0.101398  0.058654  0.018079   \n",
      "3   0.041121 -0.080265 -0.149682  0.148158  0.109886  0.063953  0.016780   \n",
      "4   0.042162 -0.080711 -0.155917  0.152442  0.117728  0.070296  0.015665   \n",
      "5   0.041383 -0.084851 -0.158548  0.158070  0.126218  0.076666  0.013749   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "41  0.245006 -0.093931 -0.642359  0.007472 -0.209081  0.222224 -0.054702   \n",
      "42  0.244407 -0.091947 -0.647931  0.004750 -0.213222  0.225568 -0.059998   \n",
      "43  0.247426 -0.090802 -0.649212  0.005899 -0.213417  0.227919 -0.059403   \n",
      "44  0.249781 -0.091469 -0.656418  0.003991 -0.216347  0.230840 -0.057102   \n",
      "45  0.253308 -0.089558 -0.661606  0.004146 -0.218548  0.234552 -0.056316   \n",
      "\n",
      "         7         8         9    ...       490       491       492       493  \\\n",
      "1  -0.030862 -0.158486 -0.119306  ... -0.154751  0.158411 -0.036216 -0.097887   \n",
      "2  -0.033759 -0.170310 -0.117109  ... -0.179258  0.172713 -0.041149 -0.103423   \n",
      "3  -0.035206 -0.180905 -0.116528  ... -0.200783  0.183362 -0.045359 -0.103007   \n",
      "4  -0.036748 -0.191647 -0.117012  ... -0.224434  0.192368 -0.046921 -0.103830   \n",
      "5  -0.040403 -0.199173 -0.119974  ... -0.242280  0.202686 -0.048809 -0.103187   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "41  0.125115 -0.124855 -0.425702  ... -0.581995 -0.367888 -0.032187  0.000030   \n",
      "42  0.123835 -0.124822 -0.438059  ... -0.586832 -0.370308 -0.031056  0.000019   \n",
      "43  0.126348 -0.124107 -0.436659  ... -0.592056 -0.376634 -0.031054  0.000010   \n",
      "44  0.127689 -0.128858 -0.437290  ... -0.600138 -0.376636 -0.028595  0.000004   \n",
      "45  0.131630 -0.128677 -0.441763  ... -0.609997 -0.380594 -0.028273  0.000001   \n",
      "\n",
      "         494       495       496       497       498       499  \n",
      "1   0.058883  0.127541 -0.029437 -0.061857 -0.150454  0.154191  \n",
      "2   0.056786  0.133813 -0.023020 -0.064493 -0.183525  0.160374  \n",
      "3   0.057056  0.140751 -0.022543 -0.068790 -0.203034  0.167511  \n",
      "4   0.056168  0.146098 -0.024131 -0.075173 -0.221941  0.172559  \n",
      "5   0.056859  0.153733 -0.025345 -0.077760 -0.234927  0.179485  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "41 -0.155051  0.237162  0.284512  0.223758  0.430833 -0.061535  \n",
      "42 -0.155783  0.238150  0.283469  0.226987  0.434644 -0.059281  \n",
      "43 -0.157099  0.241640  0.286286  0.231499  0.437476 -0.058549  \n",
      "44 -0.156763  0.247334  0.290197  0.234991  0.443446 -0.059895  \n",
      "45 -0.158461  0.251779  0.293527  0.238530  0.447380 -0.060212  \n",
      "\n",
      "[360 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "t1 = all_df\n",
    "print(pd.DataFrame(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792088</td>\n",
       "      <td>-0.557065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.578038</td>\n",
       "      <td>0.444748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843467</td>\n",
       "      <td>-0.601319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.257312</td>\n",
       "      <td>0.183480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896298</td>\n",
       "      <td>-0.639789</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96.100438</td>\n",
       "      <td>0.129397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.944598</td>\n",
       "      <td>-0.675886</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>97.008230</td>\n",
       "      <td>0.097625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986807</td>\n",
       "      <td>-0.712796</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>97.765769</td>\n",
       "      <td>0.077439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-2.464384</td>\n",
       "      <td>-1.621047</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>99.888067</td>\n",
       "      <td>0.006831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>-2.498115</td>\n",
       "      <td>-1.642499</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>99.859960</td>\n",
       "      <td>0.006573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>-2.519750</td>\n",
       "      <td>-1.658389</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>99.990055</td>\n",
       "      <td>0.003443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-2.548760</td>\n",
       "      <td>-1.679154</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>99.935236</td>\n",
       "      <td>0.006455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-2.577870</td>\n",
       "      <td>-1.700748</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>99.859180</td>\n",
       "      <td>0.005941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y  Epoch  Iteration        Acc      Loss\n",
       "0    0.792088 -0.557065      0          0  80.578038  0.444748\n",
       "1    0.843467 -0.601319      1          0  94.257312  0.183480\n",
       "2    0.896298 -0.639789      2          0  96.100438  0.129397\n",
       "3    0.944598 -0.675886      3          0  97.008230  0.097625\n",
       "4    0.986807 -0.712796      4          0  97.765769  0.077439\n",
       "..        ...       ...    ...        ...        ...       ...\n",
       "355 -2.464384 -1.621047     40          7  99.888067  0.006831\n",
       "356 -2.498115 -1.642499     41          7  99.859960  0.006573\n",
       "357 -2.519750 -1.658389     42          7  99.990055  0.003443\n",
       "358 -2.548760 -1.679154     43          7  99.935236  0.006455\n",
       "359 -2.577870 -1.700748     44          7  99.859180  0.005941\n",
       "\n",
       "[360 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.array(t1)\n",
    "pca = PCA(n_components=2)\n",
    "new_data = pca.fit_transform(t1)\n",
    "# scaling=StandardScaler()\n",
    "# scaled_data = scaling.fit_transform(new_data)\n",
    "\n",
    "allEpochDf = pd.DataFrame(new_data,columns=['x','y'])\n",
    "\n",
    "eps_each_time = [i for i in range(max_epochs)] * 8\n",
    "times = np.repeat([i for i in range(8)],max_epochs)\n",
    "\n",
    "allEpochDf['Epoch']=eps_each_time\n",
    "allEpochDf['Iteration']=(times)\n",
    "allEpochDf[\"Acc\"] = train_acc_data\n",
    "allEpochDf[\"Loss\"] = train_loss_data\n",
    "\n",
    "allEpochDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896298</td>\n",
       "      <td>-0.639789</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96.100438</td>\n",
       "      <td>0.129397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.029687</td>\n",
       "      <td>-0.747516</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>98.092301</td>\n",
       "      <td>0.063141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.151567</td>\n",
       "      <td>-0.849165</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>98.960027</td>\n",
       "      <td>0.038365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.271260</td>\n",
       "      <td>-0.949687</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>99.456995</td>\n",
       "      <td>0.023880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.390270</td>\n",
       "      <td>-1.045675</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>99.731173</td>\n",
       "      <td>0.016444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-2.212260</td>\n",
       "      <td>-1.457263</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>99.922615</td>\n",
       "      <td>0.006271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-2.309711</td>\n",
       "      <td>-1.518677</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>99.903324</td>\n",
       "      <td>0.008503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-2.397899</td>\n",
       "      <td>-1.584403</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>99.901840</td>\n",
       "      <td>0.006257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-2.498115</td>\n",
       "      <td>-1.642499</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>99.859960</td>\n",
       "      <td>0.006573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-2.577870</td>\n",
       "      <td>-1.700748</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>99.859180</td>\n",
       "      <td>0.005941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y  Epoch  Iteration        Acc      Loss\n",
       "0    0.896298 -0.639789      2          0  96.100438  0.129397\n",
       "1    1.029687 -0.747516      5          0  98.092301  0.063141\n",
       "2    1.151567 -0.849165      8          0  98.960027  0.038365\n",
       "3    1.271260 -0.949687     11          0  99.456995  0.023880\n",
       "4    1.390270 -1.045675     14          0  99.731173  0.016444\n",
       "..        ...       ...    ...        ...        ...       ...\n",
       "115 -2.212260 -1.457263     32          7  99.922615  0.006271\n",
       "116 -2.309711 -1.518677     35          7  99.903324  0.008503\n",
       "117 -2.397899 -1.584403     38          7  99.901840  0.006257\n",
       "118 -2.498115 -1.642499     41          7  99.859960  0.006573\n",
       "119 -2.577870 -1.700748     44          7  99.859180  0.005941\n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch3Df = allEpochDf.loc[(allEpochDf['Epoch']+1)%3 == 0]\n",
    "epoch3Df = epoch3Df.reset_index(drop=True)\n",
    "epoch3Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(epoch3Df.Acc)\n",
    "mv = []\n",
    "for i in range(len(test)):\n",
    "    mv.append(str(int(test[i])))\n",
    "len(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ['red','blue','purple','green','yellow','brown','black','grey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#figure(figsize=(6, 5), dpi=800)\n",
    "for i in range(len(mv)):\n",
    "    m = mv[i]\n",
    "    # colors = epoch3Df ['Iteration'][i]\n",
    "    c = epoch3Df['Iteration'][i]\n",
    "    plt.scatter(epoch3Df['x'][i],epoch3Df['y'][i],marker=f'${m}$',color = cmap[c])\n",
    "    plt.title(\"PCA for model\",color=\"g\")\n",
    "\n",
    "\n",
    "plt.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/plots/PCA_1Copy.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=700,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792088</td>\n",
       "      <td>-0.557065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.578038</td>\n",
       "      <td>0.444748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.516267</td>\n",
       "      <td>0.753354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.667475</td>\n",
       "      <td>0.435208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.804321</td>\n",
       "      <td>-0.407642</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>77.102827</td>\n",
       "      <td>0.439516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375406</td>\n",
       "      <td>0.832277</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>78.119713</td>\n",
       "      <td>0.441358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.066203</td>\n",
       "      <td>1.540160</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.543449</td>\n",
       "      <td>0.435514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.592574</td>\n",
       "      <td>-0.748622</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>78.380482</td>\n",
       "      <td>0.440093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.399504</td>\n",
       "      <td>-0.759309</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>80.226310</td>\n",
       "      <td>0.428526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.732534</td>\n",
       "      <td>-0.478265</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>79.404420</td>\n",
       "      <td>0.443256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  Epoch  Iteration        Acc      Loss\n",
       "0  0.792088 -0.557065      0          0  80.578038  0.444748\n",
       "1  1.516267  0.753354      0          1  79.667475  0.435208\n",
       "2 -0.804321 -0.407642      0          2  77.102827  0.439516\n",
       "3  0.375406  0.832277      0          3  78.119713  0.441358\n",
       "4 -1.066203  1.540160      0          4  79.543449  0.435514\n",
       "5  0.592574 -0.748622      0          5  78.380482  0.440093\n",
       "6 -0.399504 -0.759309      0          6  80.226310  0.428526\n",
       "7 -0.732534 -0.478265      0          7  79.404420  0.443256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch1stEpoch= allEpochDf.loc[(allEpochDf['Epoch']+1) == 1]\n",
    "epoch1stEpoch = epoch1stEpoch.reset_index(drop=True)\n",
    "epoch1stEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(epoch1stEpoch.Acc)\n",
    "fl = []\n",
    "for i in range(len(test)):\n",
    "    fl.append(str(int(test[i])))\n",
    "len(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(fl)):\n",
    "    m = fl[i]\n",
    "    c = epoch3Df['Iteration'][i]\n",
    "    plt.scatter(epoch1stEpoch['x'][i],epoch1stEpoch['y'][i],marker=f'${m}$',color = cmap[c])\n",
    "    plt.title(\"PCA for Layer1\",color=\"g\")\n",
    "\n",
    "plt.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/plots/PCA_Layer1.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=700,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tF = firstdf\n",
    "\n",
    "tF = np.array(tF)\n",
    "pca = PCA(n_components=2)\n",
    "new_data2 = pca.fit_transform(tF)\n",
    "\n",
    "firstLayDf = pd.DataFrame(new_data2,columns=['x','y'])\n",
    "\n",
    "eps_each_time = [i for i in range(max_epochs)] * 8\n",
    "times = np.repeat([i for i in range(8)],max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(firstLayDf['x'],firstLayDf['y'])\n",
    "plt.title(\"PCA for Layer1\",color=\"g\")\n",
    "\n",
    "plt.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/plots/PCA_Layer1_2.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=700,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
