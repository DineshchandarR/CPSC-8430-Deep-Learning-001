{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 60000 \n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader func\n",
    "def train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def test_loader(batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten as one dimension\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "      \n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def trainFunc(model,num_epochs,train_batch_size,status_interval):\n",
    "    model.train()\n",
    "    print('strated')\n",
    "    train_load = train_loader(train_batch_size)\n",
    "    n_total_steps = len(train_load)\n",
    "    train_losses = []\n",
    "    train_epoch = []\n",
    "    train_acc = []\n",
    "    epoch = 0\n",
    "    modelParamWgt={}\n",
    "    trainAvgLossArr = []\n",
    "    trainAvgAccArr = []\n",
    "    firstParaWgt = {}\n",
    "    for epoch in range (num_epochs):\n",
    "        epoch += 1\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        lossSum =0\n",
    "        totalacc=0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_load):  \n",
    "            #if (i+1)% 60 == 0 : print(i+1)\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = model(images)\n",
    "\n",
    "            images.requires_grad = True\n",
    "\n",
    "            loss = loss_func(prediction, labels)\n",
    "            lossSum += loss.detach().numpy()\n",
    "\n",
    "            # Backward and optimize\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "            totalacc += acc\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            train_epoch.append(epoch)\n",
    "            \n",
    "            # #Weight Collection\n",
    "            # if epoch % 3 == 0:\n",
    "            #     for name, parameter in model.named_parameters():\n",
    "            #         #print(name)\n",
    "            #         if'weight' in name:\n",
    "            #             modelParamWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "            #             print(modelParamWgt)\n",
    "\n",
    "            #Print Status\n",
    "            if (i+1) % status_interval == 0:\n",
    "                print (f'Train O/P: Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}',end= '\\r',flush = True)\n",
    "        \n",
    "        #Weight Collection\n",
    "        for name, parameter in model.named_parameters():\n",
    "            #print(name)\n",
    "            if'weight' in name:\n",
    "                modelParamWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "                #print(modelParamWgt)       \n",
    "\n",
    "        #1st Layer collection\n",
    "        for name, parameter in model.named_parameters():\n",
    "            if'fc1' in name and 'weight' in name:\n",
    "                firstParaWgt[epoch] = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "                #print(firstParaWgt)\n",
    "                        \n",
    "        epochLoss = lossSum/(i+1)\n",
    "        epochAcc = totalacc/(i+1)\n",
    "        #print(\"Train Avg loss:\",trainAvgLoss)\n",
    "        trainAvgLossArr.append(epochLoss)    \n",
    "        trainAvgAccArr.append(epochAcc)\n",
    "                       \n",
    "    return train_epoch,train_losses,train_acc,trainAvgLossArr,trainAvgAccArr, modelParamWgt,firstParaWgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFunction(model,loss_func,test_batch_size): \n",
    "    test_load = test_loader(test_batch_size)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        testLoss = 0\n",
    "        count = 0\n",
    "        for images, labels in test_load:\n",
    "            images, labels = Variable(images),Variable(labels)\n",
    "            \n",
    "            prediction = model(images)\n",
    "            testLoss += loss_func(prediction,labels).item()\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            count += 1\n",
    "    netTest_loss = testLoss/count\n",
    "    netTest_acc1 = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {netTest_acc1}% & Test Loss: {netTest_loss}',end= '\\r',flush = True)\n",
    "    return netTest_acc1, netTest_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaOps(paramDF,itr):\n",
    "    pcaOperation =  PCA(n_components=2)\n",
    "\n",
    "    # scale = StandardScaler()\n",
    "\n",
    "    # sData = scale.fit_transform(paramDF)\n",
    "\n",
    "    pcaVal = pcaOperation.fit_transform(paramDF)\n",
    "\n",
    "    itrData = np.full((pcaVal.shape[0],1),itr)\n",
    "\n",
    "    #pcaDf = pd.DataFrame(data = pcaVal, columns = ['x','y'])\n",
    "\n",
    "    pcaDf = pd.DataFrame(np.append(pcaVal,itrData,axis=1),columns=['x','y','Itr No.'])\n",
    "\n",
    "    return pcaDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of parameters:397510\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "tempModel = DNN()\n",
    "for i in tempModel.parameters():\n",
    "    a.append(torch.numel(i))\n",
    "print(f'Total no of parameters:{np.sum(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0\n",
      "strated\n",
      "Time: 1y of the network on the test images: 98.21% & Test Loss: 0.05452080353352358\n",
      "strated\n",
      "Time: 2y of the network on the test images: 98.1% & Test Loss: 0.056439700524060755\n",
      "strated\n",
      "Time: 3y of the network on the test images: 98.1% & Test Loss: 0.0586241150310525\n",
      "strated\n",
      "Time: 4y of the network on the test images: 98.17% & Test Loss: 0.056799113195665996\n",
      "strated\n",
      "Time: 5y of the network on the test images: 98.27% & Test Loss: 0.05349340910215687\n",
      "strated\n",
      "Time: 6y of the network on the test images: 98.19% & Test Loss: 0.05552020461494976\n",
      "strated\n",
      "Time: 7y of the network on the test images: 98.21% & Test Loss: 0.05433790982940991\n",
      "strated\n",
      "Accuracy of the network on the test images: 98.19% & Test Loss: 0.054662256325536875\r"
     ]
    }
   ],
   "source": [
    "#2nd Approach\n",
    "\n",
    "max_epochs = 45\n",
    "all_df = pd.DataFrame()\n",
    "columns=[\"x\",\"y\",\"Times\"]\n",
    "trainAllacc={}\n",
    "testAllacc={}\n",
    "trainAllloss={}\n",
    "testAllloss={}\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "status_interval = 50\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "firstLayer = pd.DataFrame()\n",
    "\n",
    "for count in range(8):\n",
    "    print(\"Time: \"+str(count))\n",
    "    M = DNN()\n",
    "    optimizer = torch.optim.Adam(M.parameters(),lr = 0.0004,weight_decay=1e-4)\n",
    "    model_name1 = \"Times: \"+str(count)    \n",
    "    train_epoch,train_losses,train_acc,trainAvgLoss,trainAvgAccArr, modelParamWgt,firstParamWgt = trainFunc(M,max_epochs,train_batch_size,status_interval)\n",
    "    testAcc, testLoss = testFunction(M,loss_func,test_batch_size)\n",
    "\n",
    "    temp_df = pd.DataFrame(modelParamWgt).transpose()\n",
    "    all_df = all_df.append(temp_df)\n",
    "    \n",
    "    firstdf = pd.DataFrame(firstParamWgt).transpose()\n",
    "    firstLayer = firstLayer.append(firstdf)\n",
    "\n",
    "    testAllacc[count] = testAcc\n",
    "    trainAllloss[count] = trainAvgLoss\n",
    "    testAllloss[count] = testLoss\n",
    "    trainAllacc[count] = trainAvgAccArr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAccArr = []\n",
    "for key,values in enumerate(trainAllacc):\n",
    "    trainAccArr.append(trainAllacc[key])\n",
    "trainLossArr = []\n",
    "for key,values in enumerate(trainAllloss):\n",
    "    trainLossArr.append(trainAllloss[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045037</td>\n",
       "      <td>-0.053748</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>-0.056903</td>\n",
       "      <td>-0.011714</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>0.028594</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>-0.010210</td>\n",
       "      <td>7.960875e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.051757</td>\n",
       "      <td>0.055158</td>\n",
       "      <td>0.051011</td>\n",
       "      <td>-0.098997</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>-0.081231</td>\n",
       "      <td>0.034692</td>\n",
       "      <td>-0.040185</td>\n",
       "      <td>0.054413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048256</td>\n",
       "      <td>-0.069295</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.062783</td>\n",
       "      <td>-0.023636</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.017892</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>8.910041e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038288</td>\n",
       "      <td>0.049943</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.054730</td>\n",
       "      <td>-0.133657</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>-0.115668</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>-0.042299</td>\n",
       "      <td>0.109224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047298</td>\n",
       "      <td>-0.079428</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.067299</td>\n",
       "      <td>-0.043646</td>\n",
       "      <td>0.028328</td>\n",
       "      <td>0.031538</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>9.186415e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040866</td>\n",
       "      <td>0.049503</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>0.059549</td>\n",
       "      <td>-0.166836</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>-0.148805</td>\n",
       "      <td>0.037485</td>\n",
       "      <td>-0.051611</td>\n",
       "      <td>0.134683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048715</td>\n",
       "      <td>-0.080267</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>-0.068319</td>\n",
       "      <td>-0.070426</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>0.035070</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>9.624135e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044609</td>\n",
       "      <td>0.051375</td>\n",
       "      <td>0.044877</td>\n",
       "      <td>0.061932</td>\n",
       "      <td>-0.187522</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>-0.171902</td>\n",
       "      <td>0.040299</td>\n",
       "      <td>-0.058145</td>\n",
       "      <td>0.149365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049277</td>\n",
       "      <td>-0.080222</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>-0.070754</td>\n",
       "      <td>-0.094084</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.038184</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.069004</td>\n",
       "      <td>1.006976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047274</td>\n",
       "      <td>0.054726</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>0.064618</td>\n",
       "      <td>-0.210041</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.042275</td>\n",
       "      <td>-0.064368</td>\n",
       "      <td>0.158447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.042768</td>\n",
       "      <td>0.072888</td>\n",
       "      <td>-0.069557</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.174918</td>\n",
       "      <td>0.129316</td>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.080710</td>\n",
       "      <td>7.713491e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277408</td>\n",
       "      <td>-0.881020</td>\n",
       "      <td>0.247084</td>\n",
       "      <td>0.050149</td>\n",
       "      <td>0.142251</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.143243</td>\n",
       "      <td>-0.794719</td>\n",
       "      <td>-0.241229</td>\n",
       "      <td>-0.378208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.043267</td>\n",
       "      <td>0.073023</td>\n",
       "      <td>-0.063145</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.176921</td>\n",
       "      <td>0.132379</td>\n",
       "      <td>-0.025895</td>\n",
       "      <td>0.080129</td>\n",
       "      <td>7.729863e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284170</td>\n",
       "      <td>-0.882690</td>\n",
       "      <td>0.245342</td>\n",
       "      <td>0.048163</td>\n",
       "      <td>0.139722</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.142308</td>\n",
       "      <td>-0.802619</td>\n",
       "      <td>-0.241914</td>\n",
       "      <td>-0.377495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.044363</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>-0.061573</td>\n",
       "      <td>0.031137</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.176545</td>\n",
       "      <td>0.131873</td>\n",
       "      <td>-0.032620</td>\n",
       "      <td>0.079201</td>\n",
       "      <td>1.272907e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281486</td>\n",
       "      <td>-0.889977</td>\n",
       "      <td>0.245780</td>\n",
       "      <td>0.047996</td>\n",
       "      <td>0.147490</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.141106</td>\n",
       "      <td>-0.803264</td>\n",
       "      <td>-0.243081</td>\n",
       "      <td>-0.381416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.046454</td>\n",
       "      <td>0.074540</td>\n",
       "      <td>-0.059790</td>\n",
       "      <td>0.030136</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.175691</td>\n",
       "      <td>0.135737</td>\n",
       "      <td>-0.029169</td>\n",
       "      <td>0.080103</td>\n",
       "      <td>1.459696e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281991</td>\n",
       "      <td>-0.900167</td>\n",
       "      <td>0.242733</td>\n",
       "      <td>0.047658</td>\n",
       "      <td>0.148025</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.140769</td>\n",
       "      <td>-0.809124</td>\n",
       "      <td>-0.241660</td>\n",
       "      <td>-0.388142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.046096</td>\n",
       "      <td>0.077850</td>\n",
       "      <td>-0.059339</td>\n",
       "      <td>0.027405</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>0.175776</td>\n",
       "      <td>0.138286</td>\n",
       "      <td>-0.033354</td>\n",
       "      <td>0.078048</td>\n",
       "      <td>1.793916e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281003</td>\n",
       "      <td>-0.905949</td>\n",
       "      <td>0.243169</td>\n",
       "      <td>0.046389</td>\n",
       "      <td>0.143784</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.144759</td>\n",
       "      <td>-0.806699</td>\n",
       "      <td>-0.237907</td>\n",
       "      <td>-0.388873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "1   0.045037 -0.053748 -0.004241 -0.056903 -0.011714  0.007826  0.028594   \n",
       "2   0.048256 -0.069295  0.000345 -0.062783 -0.023636  0.020850  0.031746   \n",
       "3   0.047298 -0.079428  0.006054 -0.067299 -0.043646  0.028328  0.031538   \n",
       "4   0.048715 -0.080267  0.014648 -0.068319 -0.070426  0.034017  0.035070   \n",
       "5   0.049277 -0.080222  0.013639 -0.070754 -0.094084  0.037014  0.038184   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "41  0.042768  0.072888 -0.069557  0.024206  0.022654  0.174918  0.129316   \n",
       "42  0.043267  0.073023 -0.063145  0.029047  0.019814  0.176921  0.132379   \n",
       "43  0.044363  0.076577 -0.061573  0.031137  0.016948  0.176545  0.131873   \n",
       "44  0.046454  0.074540 -0.059790  0.030136  0.011686  0.175691  0.135737   \n",
       "45  0.046096  0.077850 -0.059339  0.027405  0.012079  0.175776  0.138286   \n",
       "\n",
       "        7         8             9     ...      4990      4991      4992  \\\n",
       "1   0.018942 -0.010210  7.960875e-02  ...  0.026395  0.051757  0.055158   \n",
       "2   0.017892  0.009022  8.910041e-02  ...  0.038288  0.049943  0.052080   \n",
       "3   0.016004  0.029966  9.186415e-02  ...  0.040866  0.049503  0.047388   \n",
       "4   0.016092  0.053226  9.624135e-02  ...  0.044609  0.051375  0.044877   \n",
       "5   0.015835  0.069004  1.006976e-01  ...  0.047274  0.054726  0.044460   \n",
       "..       ...       ...           ...  ...       ...       ...       ...   \n",
       "41 -0.026282  0.080710  7.713491e-08  ... -0.277408 -0.881020  0.247084   \n",
       "42 -0.025895  0.080129  7.729863e-10  ... -0.284170 -0.882690  0.245342   \n",
       "43 -0.032620  0.079201  1.272907e-12  ... -0.281486 -0.889977  0.245780   \n",
       "44 -0.029169  0.080103  1.459696e-16  ... -0.281991 -0.900167  0.242733   \n",
       "45 -0.033354  0.078048  1.793916e-10  ... -0.281003 -0.905949  0.243169   \n",
       "\n",
       "        4993      4994      4995      4996      4997      4998      4999  \n",
       "1   0.051011 -0.098997  0.009302 -0.081231  0.034692 -0.040185  0.054413  \n",
       "2   0.054730 -0.133657  0.007775 -0.115668  0.036693 -0.042299  0.109224  \n",
       "3   0.059549 -0.166836  0.007045 -0.148805  0.037485 -0.051611  0.134683  \n",
       "4   0.061932 -0.187522  0.005409 -0.171902  0.040299 -0.058145  0.149365  \n",
       "5   0.064618 -0.210041  0.008488 -0.189119  0.042275 -0.064368  0.158447  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "41  0.050149  0.142251  0.001862  0.143243 -0.794719 -0.241229 -0.378208  \n",
       "42  0.048163  0.139722  0.000839  0.142308 -0.802619 -0.241914 -0.377495  \n",
       "43  0.047996  0.147490  0.000285  0.141106 -0.803264 -0.243081 -0.381416  \n",
       "44  0.047658  0.148025  0.000066  0.140769 -0.809124 -0.241660 -0.388142  \n",
       "45  0.046389  0.143784  0.000009  0.144759 -0.806699 -0.237907 -0.388873  \n",
       "\n",
       "[360 rows x 5000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Loss:(360,) & Shape of Acc: (360,)\n"
     ]
    }
   ],
   "source": [
    "train_acc_df = pd.DataFrame(trainAccArr)\n",
    "train_acc_data = np.array(train_acc_df).flatten()\n",
    "\n",
    "train_loss_df = pd.DataFrame(trainLossArr)\n",
    "train_loss_data = np.array(train_loss_df).flatten()\n",
    "\n",
    "print(f'Shape of Loss:{np.shape(train_loss_data)} & Shape of Acc: {np.shape(train_acc_data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6     \\\n",
      "1   0.045037 -0.053748 -0.004241 -0.056903 -0.011714  0.007826  0.028594   \n",
      "2   0.048256 -0.069295  0.000345 -0.062783 -0.023636  0.020850  0.031746   \n",
      "3   0.047298 -0.079428  0.006054 -0.067299 -0.043646  0.028328  0.031538   \n",
      "4   0.048715 -0.080267  0.014648 -0.068319 -0.070426  0.034017  0.035070   \n",
      "5   0.049277 -0.080222  0.013639 -0.070754 -0.094084  0.037014  0.038184   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "41  0.042768  0.072888 -0.069557  0.024206  0.022654  0.174918  0.129316   \n",
      "42  0.043267  0.073023 -0.063145  0.029047  0.019814  0.176921  0.132379   \n",
      "43  0.044363  0.076577 -0.061573  0.031137  0.016948  0.176545  0.131873   \n",
      "44  0.046454  0.074540 -0.059790  0.030136  0.011686  0.175691  0.135737   \n",
      "45  0.046096  0.077850 -0.059339  0.027405  0.012079  0.175776  0.138286   \n",
      "\n",
      "        7         8             9     ...      4990      4991      4992  \\\n",
      "1   0.018942 -0.010210  7.960875e-02  ...  0.026395  0.051757  0.055158   \n",
      "2   0.017892  0.009022  8.910041e-02  ...  0.038288  0.049943  0.052080   \n",
      "3   0.016004  0.029966  9.186415e-02  ...  0.040866  0.049503  0.047388   \n",
      "4   0.016092  0.053226  9.624135e-02  ...  0.044609  0.051375  0.044877   \n",
      "5   0.015835  0.069004  1.006976e-01  ...  0.047274  0.054726  0.044460   \n",
      "..       ...       ...           ...  ...       ...       ...       ...   \n",
      "41 -0.026282  0.080710  7.713491e-08  ... -0.277408 -0.881020  0.247084   \n",
      "42 -0.025895  0.080129  7.729863e-10  ... -0.284170 -0.882690  0.245342   \n",
      "43 -0.032620  0.079201  1.272907e-12  ... -0.281486 -0.889977  0.245780   \n",
      "44 -0.029169  0.080103  1.459696e-16  ... -0.281991 -0.900167  0.242733   \n",
      "45 -0.033354  0.078048  1.793916e-10  ... -0.281003 -0.905949  0.243169   \n",
      "\n",
      "        4993      4994      4995      4996      4997      4998      4999  \n",
      "1   0.051011 -0.098997  0.009302 -0.081231  0.034692 -0.040185  0.054413  \n",
      "2   0.054730 -0.133657  0.007775 -0.115668  0.036693 -0.042299  0.109224  \n",
      "3   0.059549 -0.166836  0.007045 -0.148805  0.037485 -0.051611  0.134683  \n",
      "4   0.061932 -0.187522  0.005409 -0.171902  0.040299 -0.058145  0.149365  \n",
      "5   0.064618 -0.210041  0.008488 -0.189119  0.042275 -0.064368  0.158447  \n",
      "..       ...       ...       ...       ...       ...       ...       ...  \n",
      "41  0.050149  0.142251  0.001862  0.143243 -0.794719 -0.241229 -0.378208  \n",
      "42  0.048163  0.139722  0.000839  0.142308 -0.802619 -0.241914 -0.377495  \n",
      "43  0.047996  0.147490  0.000285  0.141106 -0.803264 -0.243081 -0.381416  \n",
      "44  0.047658  0.148025  0.000066  0.140769 -0.809124 -0.241660 -0.388142  \n",
      "45  0.046389  0.143784  0.000009  0.144759 -0.806699 -0.237907 -0.388873  \n",
      "\n",
      "[360 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "t1 = all_df\n",
    "print(pd.DataFrame(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.614974</td>\n",
       "      <td>0.206166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.330069</td>\n",
       "      <td>0.414050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.071500</td>\n",
       "      <td>0.257423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.158724</td>\n",
       "      <td>0.189511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.454973</td>\n",
       "      <td>0.307018</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95.945951</td>\n",
       "      <td>0.136041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.780882</td>\n",
       "      <td>0.350229</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>97.135040</td>\n",
       "      <td>0.105064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.079306</td>\n",
       "      <td>0.391214</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>97.535435</td>\n",
       "      <td>0.085865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1.472539</td>\n",
       "      <td>7.327291</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>99.956323</td>\n",
       "      <td>0.009185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1.477313</td>\n",
       "      <td>7.342042</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>99.942344</td>\n",
       "      <td>0.009171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1.479453</td>\n",
       "      <td>7.362409</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>99.914591</td>\n",
       "      <td>0.010224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1.481344</td>\n",
       "      <td>7.372562</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>99.951180</td>\n",
       "      <td>0.008499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1.483580</td>\n",
       "      <td>7.390984</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>99.921656</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y  Epoch  Iteration        Acc      Loss\n",
       "0    1.614974  0.206166      0          0  83.330069  0.414050\n",
       "1    2.071500  0.257423      1          0  94.158724  0.189511\n",
       "2    2.454973  0.307018      2          0  95.945951  0.136041\n",
       "3    2.780882  0.350229      3          0  97.135040  0.105064\n",
       "4    3.079306  0.391214      4          0  97.535435  0.085865\n",
       "..        ...       ...    ...        ...        ...       ...\n",
       "355  1.472539  7.327291     40          7  99.956323  0.009185\n",
       "356  1.477313  7.342042     41          7  99.942344  0.009171\n",
       "357  1.479453  7.362409     42          7  99.914591  0.010224\n",
       "358  1.481344  7.372562     43          7  99.951180  0.008499\n",
       "359  1.483580  7.390984     44          7  99.921656  0.009600\n",
       "\n",
       "[360 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.array(t1)\n",
    "pca = PCA(n_components=2)\n",
    "new_data = pca.fit_transform(t1)\n",
    "# scaling=StandardScaler()\n",
    "# scaled_data = scaling.fit_transform(new_data)\n",
    "\n",
    "allEpochDf = pd.DataFrame(new_data,columns=['x','y'])\n",
    "\n",
    "eps_each_time = [i for i in range(max_epochs)] * 8\n",
    "times = np.repeat([i for i in range(8)],max_epochs)\n",
    "\n",
    "allEpochDf['Epoch']=eps_each_time\n",
    "allEpochDf['Iteration']=(times)\n",
    "allEpochDf[\"Acc\"] = train_acc_data\n",
    "allEpochDf[\"Loss\"] = train_loss_data\n",
    "\n",
    "allEpochDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.454975</td>\n",
       "      <td>0.306971</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95.945951</td>\n",
       "      <td>0.136041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.349288</td>\n",
       "      <td>0.429391</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>98.032613</td>\n",
       "      <td>0.071242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.069622</td>\n",
       "      <td>0.541522</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>98.882108</td>\n",
       "      <td>0.046062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.686709</td>\n",
       "      <td>0.634659</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>99.272098</td>\n",
       "      <td>0.032111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.211588</td>\n",
       "      <td>0.720628</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>99.581009</td>\n",
       "      <td>0.023657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.433176</td>\n",
       "      <td>7.078428</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>99.912351</td>\n",
       "      <td>0.010302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.460772</td>\n",
       "      <td>7.187140</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>99.903262</td>\n",
       "      <td>0.009717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.472961</td>\n",
       "      <td>7.278070</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>99.935092</td>\n",
       "      <td>0.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.477402</td>\n",
       "      <td>7.342155</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>99.942344</td>\n",
       "      <td>0.009171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.483669</td>\n",
       "      <td>7.391096</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>99.921656</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y  Epoch  Iteration        Acc      Loss\n",
       "0    2.454975  0.306971      2          0  95.945951  0.136041\n",
       "1    3.349288  0.429391      5          0  98.032613  0.071242\n",
       "2    4.069622  0.541522      8          0  98.882108  0.046062\n",
       "3    4.686709  0.634659     11          0  99.272098  0.032111\n",
       "4    5.211588  0.720628     14          0  99.581009  0.023657\n",
       "..        ...       ...    ...        ...        ...       ...\n",
       "115  1.433176  7.078428     32          7  99.912351  0.010302\n",
       "116  1.460772  7.187140     35          7  99.903262  0.009717\n",
       "117  1.472961  7.278070     38          7  99.935092  0.009758\n",
       "118  1.477402  7.342155     41          7  99.942344  0.009171\n",
       "119  1.483669  7.391096     44          7  99.921656  0.009600\n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch3Df = allEpochDf.loc[(allEpochDf['Epoch']+1)%3 == 0]\n",
    "epoch3Df = epoch3Df.reset_index(drop=True)\n",
    "epoch3Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(epoch3Df.Acc)\n",
    "mv = []\n",
    "for i in range(len(test)):\n",
    "    mv.append(str(int(test[i])))\n",
    "len(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ['red','blue','purple','green','yellow','brown','black','grey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(mv)):\n",
    "    m = mv[i]\n",
    "    # colors = epoch3Df ['Iteration'][i]\n",
    "    c = epoch3Df['Iteration'][i]\n",
    "    plt.scatter(epoch3Df['x'][i],epoch3Df['y'][i],marker=f'${m}$',color = cmap[c])\n",
    "    plt.title(\"PCA for model\",color=\"g\")\n",
    "\n",
    "\n",
    "plt.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/plots/PCA_1Copy.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=700,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.614974</td>\n",
       "      <td>0.206166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.330069</td>\n",
       "      <td>0.414050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.734126</td>\n",
       "      <td>-0.215128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.198791</td>\n",
       "      <td>0.414224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.946631</td>\n",
       "      <td>1.804389</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>82.424782</td>\n",
       "      <td>0.417762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.455073</td>\n",
       "      <td>-0.821092</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>82.988265</td>\n",
       "      <td>0.410153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.759072</td>\n",
       "      <td>-1.358337</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82.693366</td>\n",
       "      <td>0.417513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.548343</td>\n",
       "      <td>-0.768222</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>83.998883</td>\n",
       "      <td>0.410682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.783630</td>\n",
       "      <td>-0.342411</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>83.266180</td>\n",
       "      <td>0.411777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.393477</td>\n",
       "      <td>1.703477</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>81.752646</td>\n",
       "      <td>0.415491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  Epoch  Iteration        Acc      Loss\n",
       "0  1.614974  0.206166      0          0  83.330069  0.414050\n",
       "1 -0.734126 -0.215128      0          1  83.198791  0.414224\n",
       "2 -0.946631  1.804389      0          2  82.424782  0.417762\n",
       "3  1.455073 -0.821092      0          3  82.988265  0.410153\n",
       "4 -0.759072 -1.358337      0          4  82.693366  0.417513\n",
       "5 -1.548343 -0.768222      0          5  83.998883  0.410682\n",
       "6  0.783630 -0.342411      0          6  83.266180  0.411777\n",
       "7  0.393477  1.703477      0          7  81.752646  0.415491"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch1stEpoch= allEpochDf.loc[(allEpochDf['Epoch']+1) == 1]\n",
    "epoch1stEpoch = epoch1stEpoch.reset_index(drop=True)\n",
    "epoch1stEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(epoch1stEpoch.Acc)\n",
    "fl = []\n",
    "for i in range(len(test)):\n",
    "    fl.append(str(int(test[i])))\n",
    "len(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(fl)):\n",
    "    m = fl[i]\n",
    "    c = epoch3Df['Iteration'][i]\n",
    "    plt.scatter(epoch1stEpoch['x'][i],epoch1stEpoch['y'][i],marker=f'${m}$',color = cmap[c])\n",
    "    plt.title(\"PCA for Layer1\",color=\"g\")\n",
    "\n",
    "plt.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/plots/PCA_Layer1.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=700,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tF = firstdf\n",
    "\n",
    "tF = np.array(tF)\n",
    "pca = PCA(n_components=2)\n",
    "new_data2 = pca.fit_transform(tF)\n",
    "\n",
    "firstLayDf = pd.DataFrame(new_data2,columns=['x','y'])\n",
    "\n",
    "eps_each_time = [i for i in range(max_epochs)] * 8\n",
    "times = np.repeat([i for i in range(8)],max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(firstLayDf['x'],firstLayDf['y'])\n",
    "plt.title(\"PCA for Layer1\",color=\"g\")\n",
    "\n",
    "plt.savefig('D:/Clemson/COURSE/SEM-2/CPSC-8430 Deep Learning - 001/Homework/CPSC-8430-Deep-Learning-001/HW1/plots/PCA_Layer1_2.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=700,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d86b2f3ed665d691ce24c615a98bbc398f66743afc4d4e970e6f8b36fab2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPSC-8430-DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
